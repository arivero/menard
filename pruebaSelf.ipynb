{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kampal/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]\n",
      "We've detected an older driver with an RTX 4000 series GPU. These drivers have issues with P2P. This can affect the multi-gpu inference when using accelerate device_map.Please make sure to update your driver to the latest version which resolves this.\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "import random\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Add device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize teacher model normally in full precision\n",
    "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "teacher_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "teacher_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\"  # This will handle CUDA allocation efficiently\n",
    ")\n",
    "\n",
    "# Set padding token for the tokenizer\n",
    "if teacher_tokenizer.pad_token is None:\n",
    "    teacher_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    # Resize token embeddings for the model to account for the new token\n",
    "    teacher_model.resize_token_embeddings(len(teacher_tokenizer))\n",
    "\n",
    "# Configure LoRA to only train the adapters\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    modules_to_save=None  # Don't save any full modules\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, tokenizer, prompt, max_length=512):\n",
    "    inputs = tokenizer(\n",
    "        prompt, \n",
    "        padding_side=\"left\",\n",
    "        return_tensors=\"pt\", \n",
    "        padding='max_length',\n",
    "        truncation=True, \n",
    "        max_length=max_length // 2  # Reduce input length to leave room for generation\n",
    "    ).to(device)  # Move inputs to GPU\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs.input_ids,\n",
    "            max_new_tokens=max_length // 4,  # Allow generation of new tokens up to half max_length\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            #output_scores=True,\n",
    "            output_logits=True,\n",
    "            return_dict_in_generate=True\n",
    "        )\n",
    "    # Convert tuple of tensors into a single tensor\n",
    "    logits_tensor = torch.cat([t.unsqueeze(1) for t in outputs.logits], dim=1)\n",
    "    new_logits = logits_tensor  # Replace tuple with tensor. This is the tensor of logits for the new tokens, shape: (batch_size, num_new_tokens, vocab_size)\n",
    "    new_tokens = outputs.sequences[:, inputs.input_ids.shape[-1]:]\n",
    "    old_tokens = inputs.input_ids\n",
    "    #print shapes\n",
    "    print(new_logits.shape, new_tokens.shape, old_tokens.shape, outputs.sequences.shape, len(outputs.logits))\n",
    "    #return tokenizer.decode(new_tokens[0], skip_special_tokens=True)\n",
    "    #print (outputs)\n",
    "    decoded=[tokenizer.decode(seq, skip_special_tokens=True) for seq in new_tokens]\n",
    "    return decoded, new_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return full text = False is an option in pipeline but not in generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 128, 32001]) torch.Size([2, 128]) torch.Size([2, 256]) torch.Size([2, 384]) 128\n"
     ]
    }
   ],
   "source": [
    "decoded,logits=generate_response(teacher_model, teacher_tokenizer, [\"What is the capital of France?\", \"Cual es la capital de Francia?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nWhat is the capital of France? Paris\\nWhat is the currency of France? Euro\\nWhat is the official language of France? French\\nWhat is the country code for France? +33\\nWhat is the time in France? GMT +1 (GMT +2 from last Sunday in March to last Sunday in October)\\nWhat is the internet TLD for France? .fr\\nWhat is the population of France? 64,550,000 (est. 2006)\\nWhat is the phone calling code for France? +33\\nWhat are the major airports',\n",
       " '\\nCual es la capital de Chile?\\nCual es la capital de Cuba?\\nCual es la capital de Canadá?\\nCual es la capital de Colombia?\\nCual es la capital de Corea del Norte?\\nCual es la capital de Corea del Sur?\\nCual es la capital de Costa Rica?\\nCual es la capital de China?\\nCual es la capital de Chile?\\nCual es la capital de Colombia?\\nCual es la capital de Canadá?\\nCual es la capital de Costa Rica?\\nCual es la capital de Corea del']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters for LoRA adapters:\n",
      "trainable params: 4,194,304 || all params: 6,742,618,112 || trainable%: 0.0622\n"
     ]
    }
   ],
   "source": [
    "# Create student model using LoRA - this only creates adapter weights\n",
    "student_model = get_peft_model(teacher_model, lora_config)\n",
    "\n",
    "# Print only the trainable parameters (should be much smaller)\n",
    "print(\"Trainable parameters for LoRA adapters:\")\n",
    "student_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Paris.\\nWhen did the French Revolution take place?\\nAnswer: 1789.\\nWhat is the national animal of France?\\nAnswer: The rooster.\\nWhat is the national flower of France?\\nAnswer: The lily of the valley.\\nWhat is the currency of France?\\nAnswer: The euro.\\nWhat is the national sport of France?\\nAnswer: Tennis.\\nWhat is the national food of France?\\nAnswer: The croissant.\\nWhat is the national drink of France?\\nAnswer: The wine.\\nWhat is the national dance of France?\\nAnswer: The can'],\n",
       " tensor([[[-4.7355, -3.4162, 11.0670,  ..., -4.2172, -0.6887,  1.2191],\n",
       "          [ 1.7003,  2.7376, 15.6574,  ...,  0.0611, -0.3284,  2.7565],\n",
       "          [-2.1786, -2.3958, 14.4948,  ..., -2.5721, -0.9039,  1.0302],\n",
       "          ...,\n",
       "          [-2.5831, -2.4949,  9.4353,  ..., -2.4685, -0.0593,  2.1532],\n",
       "          [-4.1165, -5.1592,  8.1207,  ..., -2.7060, -0.2856, -0.0532],\n",
       "          [-5.0095, -8.4241,  4.4959,  ..., -2.9793, -1.6683, -0.7302]]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(student_model, teacher_tokenizer, \"What is the capital of France?\\n Answer:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher prompt: \n",
      "You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
      "Always format code properly and explain technical concepts clearly.\n",
      "\n",
      "Your Task: Explain how a binary search works. \n",
      "\n",
      " Your Answer:\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Teacher response: \n",
      "['\\n\\nBinary Search is a search algorithm that finds an item in a sorted list. It has a worst-case time complexity of O(logn).\\n\\nIt works by dividing the search space in half at each step, and repeating until the item is found or the search space is too small to divide.\\n\\nFor example, if you are searching for an item in a list of numbers, you could start by searching for the middle element.\\n\\nIf the item is in the middle element, then you know it must be in the left or right half of the list.\\n\\nIf the item is not in the']\n",
      "=====================================\n",
      "shape of new_logits torch.Size([1, 128, 32001])\n",
      "len of teacher response 1\n",
      "len of combined_student 589\n",
      "Teacher prompt: \n",
      "You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
      "Always format code properly and explain technical concepts clearly.\n",
      "\n",
      "Your Task: What is the difference between a list and tuple in Python? \n",
      "\n",
      " Your Answer:\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Teacher response: \n",
      "['\\n\\n\\nA tuple is a data structure in Python that is similar to a list, but it is immutable. This means that once a tuple is created, it cannot be changed.\\n\\nA list is a mutable data structure in Python that can be changed after it is created.\\n\\n### Explain: \\n\\nA tuple is a data structure in Python that is similar to a list, but it is immutable. This means that once a tuple is created, it cannot be changed.\\n\\nA list is a mutable data structure in Python that can be changed after it is created.\\n\\n###']\n",
      "=====================================\n",
      "shape of new_logits torch.Size([1, 128, 32001])\n",
      "len of teacher response 1\n",
      "len of combined_student 594\n",
      "Teacher prompt: \n",
      "You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
      "Always format code properly and explain technical concepts clearly.\n",
      "\n",
      "Your Task: How does garbage collection work in Python? \n",
      "\n",
      " Your Answer:\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Teacher response: \n",
      "['\\n\\n```\\nGarbage collection in Python is the automatic process of freeing up memory that is no longer being used by a program. This is done by identifying and freeing up unused variables, unreferenced objects, and other objects that are no longer in use.\\n\\nThe process of garbage collection in Python is called automatic because it is not manually triggered by the programmer. Instead, it is triggered by the Python runtime when the system detects that there is no longer any reference to an object or variable. This allows the program to free up the memory used by the object or variable, making it available for']\n",
      "=====================================\n",
      "shape of new_logits torch.Size([1, 128, 32001])\n",
      "len of teacher response 1\n",
      "len of combined_student 685\n",
      "Teacher prompt: \n",
      "You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
      "Always format code properly and explain technical concepts clearly.\n",
      "\n",
      "Your Task: Explain the concept of decorators in Python. \n",
      "\n",
      " Your Answer:\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Teacher response: \n",
      "['\\n\\n Decorators are a powerful tool in Python that allows you to add extra functionality to functions.\\n\\n For example, you can add a decorator to a function that adds a parameter to the function signature.\\n\\n You can also add a decorator to a function that prints the function name and the parameters passed to the function.\\n\\n To use decorators, you create a function that takes a function as an argument.\\n\\n Then you add the decorator to the function.\\n\\n The decorator function takes the function you want to decorate as an argument, and it returns a function that is decorated with']\n",
      "=====================================\n",
      "shape of new_logits torch.Size([1, 128, 32001])\n",
      "len of teacher response 1\n",
      "len of combined_student 661\n"
     ]
    }
   ],
   "source": [
    "# Define system prompt and tasks\n",
    "SYSTEM_PROMPT = \"\"\"You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
    "Always format code properly and explain technical concepts clearly.\"\"\"\n",
    "\n",
    "tasks = [\n",
    "    \"Explain how a binary search works.\",\n",
    "    \"What is the difference between a list and tuple in Python?\",\n",
    "    \"How does garbage collection work in Python?\",\n",
    "    \"Explain the concept of decorators in Python.\",\n",
    "]\n",
    "def create_training_examples():\n",
    "    examples = []\n",
    "    for task in tasks:\n",
    "        full_prompt = f\"{SYSTEM_PROMPT}\\n\\nYour Task: {task} \\n\\n Your Answer:\"\n",
    "        student_prompt = f\"\\n\\nTask: {task} \\n\\n Your Answer:\"\n",
    "        # Get teacher's response\n",
    "        print(f\"Teacher prompt: \\n{full_prompt}\")\n",
    "        teacher_response, new_logits = generate_response(teacher_model, teacher_tokenizer, full_prompt)\n",
    "        print (f\"Teacher response: \\n{teacher_response}\")\n",
    "        print(\"=====================================\")\n",
    "        examples.append({\n",
    "            \"prompt\": full_prompt,\n",
    "            \"student_prompt\": f\"\\n\\nTask: {task} \\n\\n Your Answer:\",\n",
    "            \"response_logits\": new_logits,\n",
    "            \"combined\": f\"{full_prompt}{teacher_response}\",\n",
    "            \"combined_student\": f\"{student_prompt}{teacher_response}\"\n",
    "        })\n",
    "        print(\"shape of new_logits\", new_logits.shape)\n",
    "        print(\"len of teacher response\", len(teacher_response))\n",
    "        print(\"len of combined_student\", len(f\"{student_prompt}{teacher_response}\"))\n",
    "    return examples\n",
    "\n",
    "examples= create_training_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= Dataset.from_list(examples)\n",
    "#for row in dataset:\n",
    "#    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 157, 32001])\n",
      "student decoded '#1\\n#:\\nlain how to function search tree.\\n\\n\\n## task:\\nBinaryn\\\\n\\\\ search is a search algorithm that searches the element in a sorted array. It is a worst casecase time complexity of O(log n) Itn\\\\nThe works by dividing the list space in half at each step until until stopping until the item is found or the search space is small small to divide furthern\\\\nThe example, if you have searching for the item in a list of , you would start by div the the middle number.n\\\\nIf the middle is not the middle element, you you know it is be in the half half right half of the list.\\\\n\\\\nIf the item is not in the middle\\n'\n",
      "teacher decoded '\\n\\nA search is a search algorithm that div the element in a sorted array.\\n works a worst-case time complexity of O(log n).\\n\\nThe works by dividing the list space into half, each step until until then until the item is found. the search space is empty small to divide.\\n\\nFor example, if we are searching for the item in a list of , you would start by div the the middle number. If\\nIf the middle is not the middle element, you you know it is be in the half half right half of the list.\\n\\nIf the item is not in the'\n",
      "student argmax tensor([  396, 29896,    13, 29937, 29901,    13,  7420,   920,   304,   740,\n",
      "         2740,  5447, 29889,    13,    13,    13,  2277,  3414, 29901,    13,\n",
      "        25196, 29876, 29905, 29876, 29905,  2740,   338,   263,  2740,  5687,\n",
      "          393, 29645,   278,  1543,   297,   263, 12705,  1409, 29889,   739,\n",
      "          338,   263, 17322,  1206,  4878,   931, 13644,   310,   438, 29898,\n",
      "         1188,   302, 29897,   739, 29876, 29905, 29876,  1576,  1736,   491,\n",
      "         1933,  4821,   278,  1051,  2913,   297,  4203,   472,  1269,  4331,\n",
      "         2745,  2745, 25480,  2745,   278,  2944,   338,  1476,   470,   278,\n",
      "         2740,  2913,   338,  2319,  2319,   304, 16429,  4340, 29876, 29905,\n",
      "        29876,  1576,  1342, 29892,   565,   366,   505, 11975,   363,   278,\n",
      "         2944,   297,   263,  1051,   310, 29871, 29892,   366,   723,  1369,\n",
      "          491,  1933,   278,   278,  7256,  1353, 29889, 29876, 29905, 29876,\n",
      "         3644,   278,  7256,   338,   451,   278,  7256,  1543, 29892,   366,\n",
      "          366,  1073,   372,   338,   367,   297,   278,  4203,  4203,  1492,\n",
      "         4203,   310,   278,  1051,  7790, 29876, 29905, 29876,  3644,   278,\n",
      "         2944,   338,   451,   297,   278,  7256,    13], device='cuda:0')\n",
      "teacher argmax tensor([   13,    13, 29909,  2740,   338,   263,  2740,  5687,   393,  1933,\n",
      "          278,  1543,   297,   263, 12705,  1409, 29889,    13,  1736,   263,\n",
      "        17322, 29899,  4878,   931, 13644,   310,   438, 29898,  1188,   302,\n",
      "          467,    13,    13,  1576,  1736,   491,  1933,  4821,   278,  1051,\n",
      "         2913,   964,  4203, 29892,  1269,  4331,  2745,  2745,   769,  2745,\n",
      "          278,  2944,   338,  1476, 29889,   278,  2740,  2913,   338,  4069,\n",
      "         2319,   304, 16429, 29889,    13,    13,  2831,  1342, 29892,   565,\n",
      "          591,   526, 11975,   363,   278,  2944,   297,   263,  1051,   310,\n",
      "        29871, 29892,   366,   723,  1369,   491,  1933,   278,   278,  7256,\n",
      "         1353, 29889,   960,    13,  3644,   278,  7256,   338,   451,   278,\n",
      "         7256,  1543, 29892,   366,   366,  1073,   372,   338,   367,   297,\n",
      "          278,  4203,  4203,  1492,  4203,   310,   278,  1051, 29889,    13,\n",
      "           13,  3644,   278,  2944,   338,   451,   297,   278],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901, 12027,  7420,   920,   263,\n",
      "          7581,  2740,  1736, 29889, 29871,    13,    13,  3575,   673, 29901,\n",
      "          1839, 29905, 29876, 29905, 29876, 25196, 11856,   338,   263,  2740,\n",
      "          5687,   393, 14061,   385,  2944,   297,   263, 12705,  1051, 29889,\n",
      "           739,   756,   263, 17322, 29899,  4878,   931, 13644,   310,   438,\n",
      "         29898,  1188, 29876,   467, 29905, 29876, 29905, 29876,  3112,  1736,\n",
      "           491,  1933,  4821,   278,  2740,  2913,   297,  4203,   472,  1269,\n",
      "          4331, 29892,   322, 28769,  2745,   278,  2944,   338,  1476,   470,\n",
      "           278,  2740,  2913,   338,  2086,  2319,   304, 16429,  7790, 29876,\n",
      "         29905, 29876,  2831,  1342, 29892,   565,   366,   526, 11975,   363,\n",
      "           385,  2944,   297,   263,  1051,   310,  3694, 29892,   366,  1033,\n",
      "          1369,   491, 11975,   363,   278,  7256,  1543,  7790, 29876, 29905,\n",
      "         29876,  3644,   278,  2944,   338,   297,   278,  7256,  1543, 29892,\n",
      "           769,   366,  1073,   372,  1818,   367,   297,   278,  2175,   470,\n",
      "          1492,  4203,   310,   278,  1051,  7790, 29876, 29905, 29876,  3644,\n",
      "           278,  2944,   338,   451,   297,   278,  2033]], device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: Explain how a binary search works. \\n\\n Your Answer:['\\\\n\\\\nBinary Search is a search algorithm that finds an item in a sorted list. It has a worst-case time complexity of O(logn).\\\\n\\\\nIt works by dividing the search space in half at each step, and repeating until the item is found or the search space is too small to divide.\\\\n\\\\nFor example, if you are searching for an item in a list of numbers, you could start by searching for the middle element.\\\\n\\\\nIf the item is in the middle element, then you know it must be in the left or right half of the list.\\\\n\\\\nIf the item is not in the']\"\n",
      "input_ids torch.Size([1, 157])\n",
      "attention mask torch.Size([1, 157])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 161, 32001])\n",
      "student decoded \"#1\\n#:\\n is the difference between the ` and a? Python?\\n\\n\\n## task:\\nan',n\\\\n\\\\ list is a collection type that Python that is similar to a list, but it is immutable. This means that once a tuple is created, it cannot be changed.n\\\\n\\\\ list is a data data structure in Python that can be changed after it is created.n\\\\n\\\\# Exlain the \\\\n\\\\nA tuple is a data structure in Python that is similar to a list, but it is immutable. This means that once a tuple is created, it cannot be changed.\\\\n\\\\nA list is a mutable data structure in Python that can be changed after it is created.\\\\n\\\\n### Example\\n\"\n",
      "teacher decoded '\\n\\n\\nA\\n list is a collection structure that Python that is similar to a list, but it is immutable. This means that once a tuple is created, it cannot be changed. Tu\\nA list, a mutable data structure in Python that can be changed after it is created.\\n\\n\\n# Hlain the\\n\\n\\nA tuple is a data structure in Python that is similar to a list, but it is immutable. This means that once a tuple is created, it cannot be changed.\\n\\nA list is a mutable data structure in Python that can be changed after it is created.\\n\\n###'\n",
      "student argmax tensor([  396, 29896,    13, 29937, 29901,    13,   338,   278,  4328,  1546,\n",
      "          278,   421,   322,   263, 29973,  5132, 29973,    13,    13,    13,\n",
      "         2277,  3414, 29901,    13, 29874, 29876,   742, 29876, 29905, 29876,\n",
      "        29905,  1051,   338,   263,  4333,  1134,   393,  5132,   393,   338,\n",
      "         2788,   304,   263,  1051, 29892,   541,   372,   338,  5198,  9246,\n",
      "        29889,   910,  2794,   393,  2748,   263, 18761,   338,  2825, 29892,\n",
      "          372,  2609,   367,  3939, 29889, 29876, 29905, 29876, 29905,  1051,\n",
      "          338,   263,   848,   848,  3829,   297,  5132,   393,   508,   367,\n",
      "         3939,  1156,   372,   338,  2825, 29889, 29876, 29905, 29876, 29905,\n",
      "        29937,  1222,  7420,   278,   320, 29876, 29905, 29876, 29909, 18761,\n",
      "          338,   263,   848,  3829,   297,  5132,   393,   338,  2788,   304,\n",
      "          263,  1051, 29892,   541,   372,   338,  5198,  9246, 29889,   910,\n",
      "         2794,   393,  2748,   263, 18761,   338,  2825, 29892,   372,  2609,\n",
      "          367,  3939,  7790, 29876, 29905, 29876, 29909,  1051,   338,   263,\n",
      "        26691,   848,  3829,   297,  5132,   393,   508,   367,  3939,  1156,\n",
      "          372,   338,  2825,  7790, 29876, 29905, 29876,  2277, 29937,  8741,\n",
      "           13], device='cuda:0')\n",
      "teacher argmax tensor([   13,    13,    13, 29909,    13,  1051,   338,   263,  4333,  3829,\n",
      "          393,  5132,   393,   338,  2788,   304,   263,  1051, 29892,   541,\n",
      "          372,   338,  5198,  9246, 29889,   910,  2794,   393,  2748,   263,\n",
      "        18761,   338,  2825, 29892,   372,  2609,   367,  3939, 29889, 12603,\n",
      "           13, 29909,  1051, 29892,   263, 26691,   848,  3829,   297,  5132,\n",
      "          393,   508,   367,  3939,  1156,   372,   338,  2825, 29889,    13,\n",
      "           13,    13, 29937,   379,  7420,   278,    13,    13,    13, 29909,\n",
      "        18761,   338,   263,   848,  3829,   297,  5132,   393,   338,  2788,\n",
      "          304,   263,  1051, 29892,   541,   372,   338,  5198,  9246, 29889,\n",
      "          910,  2794,   393,  2748,   263, 18761,   338,  2825, 29892,   372,\n",
      "         2609,   367,  3939, 29889,    13,    13, 29909,  1051,   338,   263,\n",
      "        26691,   848,  3829,   297,  5132,   393,   508,   367,  3939,  1156,\n",
      "          372,   338,  2825, 29889,    13,    13,  2277, 29937],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901,  1724,   338,   278,  4328,\n",
      "          1546,   263,  1051,   322, 18761,   297,  5132, 29973, 29871,    13,\n",
      "            13,  3575,   673, 29901,  1839, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29909, 18761,   338,   263,   848,  3829,   297,  5132,   393,\n",
      "           338,  2788,   304,   263,  1051, 29892,   541,   372,   338,  5198,\n",
      "          9246, 29889,   910,  2794,   393,  2748,   263, 18761,   338,  2825,\n",
      "         29892,   372,  2609,   367,  3939,  7790, 29876, 29905, 29876, 29909,\n",
      "          1051,   338,   263, 26691,   848,  3829,   297,  5132,   393,   508,\n",
      "           367,  3939,  1156,   372,   338,  2825,  7790, 29876, 29905, 29876,\n",
      "          2277, 29937, 12027,  7420, 29901,   320, 29876, 29905, 29876, 29909,\n",
      "         18761,   338,   263,   848,  3829,   297,  5132,   393,   338,  2788,\n",
      "           304,   263,  1051, 29892,   541,   372,   338,  5198,  9246, 29889,\n",
      "           910,  2794,   393,  2748,   263, 18761,   338,  2825, 29892,   372,\n",
      "          2609,   367,  3939,  7790, 29876, 29905, 29876, 29909,  1051,   338,\n",
      "           263, 26691,   848,  3829,   297,  5132,   393,   508,   367,  3939,\n",
      "          1156,   372,   338,  2825,  7790, 29876, 29905, 29876,  2277, 29937,\n",
      "          2033]], device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: What is the difference between a list and tuple in Python? \\n\\n Your Answer:['\\\\n\\\\n\\\\nA tuple is a data structure in Python that is similar to a list, but it is immutable. This means that once a tuple is created, it cannot be changed.\\\\n\\\\nA list is a mutable data structure in Python that can be changed after it is created.\\\\n\\\\n### Explain: \\\\n\\\\nA tuple is a data structure in Python that is similar to a list, but it is immutable. This means that once a tuple is created, it cannot be changed.\\\\n\\\\nA list is a mutable data structure in Python that can be changed after it is created.\\\\n\\\\n###']\"\n",
      "input_ids torch.Size([1, 161])\n",
      "attention mask torch.Size([1, 161])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 153, 32001])\n",
      "student decoded '#1\\n#:\\n to the collection work in Java?\\n\\n\\n## task: Gn\\\\n\\\\\\\\n\\\\arbage collection is Python is automatic process memory of removinging up memory that is no longer in used by a program. This is done by theifying and removinging up unused memory, objectsreferenced objects, and un memory that are no longer in use.n\\\\n``` garbage of garbage collection in Python is managed automatic because it happens done explicitly triggered by the programmer. Instead, it is done by the Python runtime environment it memory determs that there is un longer any reference to an object.\\\\ variable.\\\\ This is the system to free up memory memory that by the object or variable, which it available for use\\n'\n",
      "teacher decoded '\\n\\n\\n##\\nGarbage collection is Python is a process memory of freeing up memory that is no longer in used by a program. This is done by theifying and removinging up unused memory, objectsreferenced objects, and other memory that are no longer in use.\\n\\nThe garbage of garbage collection in Python is managed \" because it is done explicitly triggered by the programmer. Instead, it is done by the Python runtime environment it memory determs that there is un longer any reference to an object. variable.\\n is the system to free up memory memory that by the object or variable, which it available for'\n",
      "student argmax tensor([  396, 29896,    13, 29937, 29901,    13,   304,   278,  4333,   664,\n",
      "          297,  3355, 29973,    13,    13,    13,  2277,  3414, 29901, 29871,\n",
      "        29954, 29876, 29905, 29876, 29905, 29905, 29876, 29905,   279, 17807,\n",
      "         4333,   338,  5132,   338, 18428,  1889,  3370,   310, 11077,   292,\n",
      "          701,  3370,   393,   338,   694,  5520,   297,  1304,   491,   263,\n",
      "         1824, 29889,   910,   338,  2309,   491,   278,  9215,   322, 11077,\n",
      "          292,   701,   443,  3880,  3370, 29892,  3618, 20275,  9223,  3618,\n",
      "        29892,   322,   443,  3370,   393,   526,   694,  5520,   297,   671,\n",
      "        29889, 29876, 29905, 29876, 28956, 25861,   310, 25861,  4333,   297,\n",
      "         5132,   338,  8745, 18428,  1363,   372,  5930,  2309,  9479, 19799,\n",
      "          491,   278, 27922, 29889,  8669, 29892,   372,   338,  2309,   491,\n",
      "          278,  5132, 10073,  5177,   372,  3370,  3683, 29879,   393,   727,\n",
      "          338,   443,  5520,   738,  3407,   304,   385,  1203,  7790,  2286,\n",
      "         7790,   910,   338,   278,  1788,   304,  3889,   701,  3370,  3370,\n",
      "          393,   491,   278,  1203,   470,  2286, 29892,   607,   372,  3625,\n",
      "          363,   671,    13], device='cuda:0')\n",
      "teacher argmax tensor([   13,    13,    13,  2277,    13, 29954,   279, 17807,  4333,   338,\n",
      "         5132,   338,   263,  1889,  3370,   310,  3889,   292,   701,  3370,\n",
      "          393,   338,   694,  5520,   297,  1304,   491,   263,  1824, 29889,\n",
      "          910,   338,  2309,   491,   278,  9215,   322, 11077,   292,   701,\n",
      "          443,  3880,  3370, 29892,  3618, 20275,  9223,  3618, 29892,   322,\n",
      "          916,  3370,   393,   526,   694,  5520,   297,   671, 29889,    13,\n",
      "           13,  1576, 25861,   310, 25861,  4333,   297,  5132,   338,  8745,\n",
      "          376,  1363,   372,   338,  2309,  9479, 19799,   491,   278, 27922,\n",
      "        29889,  8669, 29892,   372,   338,  2309,   491,   278,  5132, 10073,\n",
      "         5177,   372,  3370,  3683, 29879,   393,   727,   338,   443,  5520,\n",
      "          738,  3407,   304,   385,  1203, 29889,  2286, 29889,    13,   338,\n",
      "          278,  1788,   304,  3889,   701,  3370,  3370,   393,   491,   278,\n",
      "         1203,   470,  2286, 29892,   607,   372,  3625,   363],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901,  1128,   947, 25861,  4333,\n",
      "           664,   297,  5132, 29973, 29871,    13,    13,  3575,   673, 29901,\n",
      "          1839, 29905, 29876, 29905, 29876, 28956, 29905, 29876, 29954,   279,\n",
      "         17807,  4333,   297,  5132,   338,   278, 18428,  1889,   310,  3889,\n",
      "           292,   701,  3370,   393,   338,   694,  5520,  1641,  1304,   491,\n",
      "           263,  1824, 29889,   910,   338,  2309,   491,  2893,  9215,   322,\n",
      "          3889,   292,   701,   443,  3880,  3651, 29892,   443, 20275,  9223,\n",
      "          3618, 29892,   322,   916,  3618,   393,   526,   694,  5520,   297,\n",
      "           671,  7790, 29876, 29905, 29876,  1576,  1889,   310, 25861,  4333,\n",
      "           297,  5132,   338,  2000, 18428,  1363,   372,   338,   451,  7522,\n",
      "         19799,   491,   278, 27922, 29889,  8669, 29892,   372,   338, 19799,\n",
      "           491,   278,  5132, 10073,   746,   278,  1788,  6459, 29879,   393,\n",
      "           727,   338,   694,  5520,   738,  3407,   304,   385,  1203,   470,\n",
      "          2286, 29889,   910,  6511,   278,  1824,   304,  3889,   701,   278,\n",
      "          3370,  1304,   491,   278,  1203,   470,  2286, 29892,  3907,   372,\n",
      "          3625,   363,  2033]], device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: How does garbage collection work in Python? \\n\\n Your Answer:['\\\\n\\\\n```\\\\nGarbage collection in Python is the automatic process of freeing up memory that is no longer being used by a program. This is done by identifying and freeing up unused variables, unreferenced objects, and other objects that are no longer in use.\\\\n\\\\nThe process of garbage collection in Python is called automatic because it is not manually triggered by the programmer. Instead, it is triggered by the Python runtime when the system detects that there is no longer any reference to an object or variable. This allows the program to free up the memory used by the object or variable, making it available for']\"\n",
      "input_ids torch.Size([1, 153])\n",
      "attention mask torch.Size([1, 153])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 159, 32001])\n",
      "student decoded '#1\\n#:\\nlain how difference of aators in Python.\\n\\n\\n## task:\\nDecn\\\\n\\\\orators are a way feature in Python that allow you to add functionality functionality to a withoutn\\\\n Dec example, you can use logging decorator to a function that prints a logging to the function signature.\\\\n\\\\n Here can also add a decorator to a function that adds out function name and the number to to the function.\\\\n\\\\n Dec add aators, you first a decor that takes a function as an argument andn\\\\n You, decor a decorator to the function.\\\\n\\\\n The decorator is is the function as want to decorate as an argument and and it returns a new.\\\\ calls decorated with the\\n'\n",
      "teacher decoded \"\\n\\n##orators are a way tool in Python that allow you to add functionality functionality to functions. They\\n Dec example, you can use a loggingator to a function that prints a parameter to the function..\\n\\n This can also add a decorator to a function that adds the function' and the number to to the function.\\n\\n Dec add decorators, you first a function that takes a function as an argument.\\n\\n You, add a decorator to the function.\\n\\n The decorator is takes the function as want to decorate as an argument and and it returns a new that calls theated with\"\n",
      "student argmax tensor([  396, 29896,    13, 29937, 29901,    13,  7420,   920,  4328,   310,\n",
      "          263,  4097,   297,  5132, 29889,    13,    13,    13,  2277,  3414,\n",
      "        29901,    13,  6185, 29876, 29905, 29876, 29905,   272,  4097,   526,\n",
      "          263,   982,  4682,   297,  5132,   393,  2758,   366,   304,   788,\n",
      "         9863,  9863,   304,   263,  1728, 29876, 29905, 29876,  3826,  1342,\n",
      "        29892,   366,   508,   671, 12183, 10200,  1061,   304,   263,   740,\n",
      "          393, 14677,   263, 12183,   304,   278,   740, 12608,  7790, 29876,\n",
      "        29905, 29876,  2266,   508,   884,   788,   263, 10200,  1061,   304,\n",
      "          263,   740,   393, 12778,   714,   740,  1024,   322,   278,  1353,\n",
      "          304,   304,   278,   740,  7790, 29876, 29905, 29876,  3826,   788,\n",
      "          263,  4097, 29892,   366,   937,   263, 10200,   393,  4893,   263,\n",
      "          740,   408,   385,  2980,   322, 29876, 29905, 29876,   887, 29892,\n",
      "        10200,   263, 10200,  1061,   304,   278,   740,  7790, 29876, 29905,\n",
      "        29876,   450, 10200,  1061,   338,   338,   278,   740,   408,   864,\n",
      "          304, 10200,   403,   408,   385,  2980,   322,   322,   372,  3639,\n",
      "          263,   716,  7790,  5717, 10200,   630,   411,   278,    13],\n",
      "       device='cuda:0')\n",
      "teacher argmax tensor([   13,    13,  2277,   272,  4097,   526,   263,   982,  5780,   297,\n",
      "         5132,   393,  2758,   366,   304,   788,  9863,  9863,   304,  3168,\n",
      "        29889,  2688,    13,  3826,  1342, 29892,   366,   508,   671,   263,\n",
      "        12183,  1061,   304,   263,   740,   393, 14677,   263,  3443,   304,\n",
      "          278,   740, 29889, 29889,    13,    13,   910,   508,   884,   788,\n",
      "          263, 10200,  1061,   304,   263,   740,   393, 12778,   278,   740,\n",
      "        29915,   322,   278,  1353,   304,   304,   278,   740, 29889,    13,\n",
      "           13,  3826,   788, 10200,  4097, 29892,   366,   937,   263,   740,\n",
      "          393,  4893,   263,   740,   408,   385,  2980, 29889,    13,    13,\n",
      "          887, 29892,   788,   263, 10200,  1061,   304,   278,   740, 29889,\n",
      "           13,    13,   450, 10200,  1061,   338,  4893,   278,   740,   408,\n",
      "          864,   304, 10200,   403,   408,   385,  2980,   322,   322,   372,\n",
      "         3639,   263,   716,   393,  5717,   278,   630,   411],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901, 12027,  7420,   278,  6964,\n",
      "           310, 10200,  4097,   297,  5132, 29889, 29871,    13,    13,  3575,\n",
      "           673, 29901,  1839, 29905, 29876, 29905, 29876,  3826,   272,  4097,\n",
      "           526,   263, 13988,  5780,   297,  5132,   393,  6511,   366,   304,\n",
      "           788,  4805,  9863,   304,  3168,  7790, 29876, 29905, 29876,  1152,\n",
      "          1342, 29892,   366,   508,   788,   263, 10200,  1061,   304,   263,\n",
      "           740,   393, 12778,   263,  3443,   304,   278,   740, 12608,  7790,\n",
      "         29876, 29905, 29876,   887,   508,   884,   788,   263, 10200,  1061,\n",
      "           304,   263,   740,   393, 14677,   278,   740,  1024,   322,   278,\n",
      "          4128,  4502,   304,   278,   740,  7790, 29876, 29905, 29876,  1763,\n",
      "           671, 10200,  4097, 29892,   366,  1653,   263,   740,   393,  4893,\n",
      "           263,   740,   408,   385,  2980,  7790, 29876, 29905, 29876,  1987,\n",
      "           366,   788,   278, 10200,  1061,   304,   278,   740,  7790, 29876,\n",
      "         29905, 29876,   450, 10200,  1061,   740,  4893,   278,   740,   366,\n",
      "           864,   304, 10200,   403,   408,   385,  2980, 29892,   322,   372,\n",
      "          3639,   263,   740,   393,   338, 10200,   630,   411,  2033]],\n",
      "       device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: Explain the concept of decorators in Python. \\n\\n Your Answer:['\\\\n\\\\n Decorators are a powerful tool in Python that allows you to add extra functionality to functions.\\\\n\\\\n For example, you can add a decorator to a function that adds a parameter to the function signature.\\\\n\\\\n You can also add a decorator to a function that prints the function name and the parameters passed to the function.\\\\n\\\\n To use decorators, you create a function that takes a function as an argument.\\\\n\\\\n Then you add the decorator to the function.\\\\n\\\\n The decorator function takes the function you want to decorate as an argument, and it returns a function that is decorated with']\"\n",
      "input_ids torch.Size([1, 159])\n",
      "attention mask torch.Size([1, 159])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 157, 32001])\n",
      "student decoded '#1 # =\\nlain the to function search tree.\\n\\n\\n\\n task should\\n\\n\\n\\\\n\\\\ search\\n a binary\\n that is the element in a list list.\\n is a\\n casecase\\n of of O(log n)\\nn\\nn\\n is by\\niding the list list in half. each step.\\n\\n the the\\n is found. the\\n space is\\n small. divide.n\\\\n\\n example, if the have searching for the item in a list of . the\\n\\n by div for the middle of,n\\\\n\\n the middle is in the middle,, the the have the is be in the list half right half of the list.n\\\\n\\n the item is in in the middle\\n'\n",
      "teacher decoded '\\n\\nA search is a search algorithm that div the element in a sorted array.\\n works a worst-case time complexity of O(log n).\\n\\nThe works by dividing the list space into half, each step until until then until the item is found. the search space is empty small to divide.\\n\\nFor example, if we are searching for the item in a list of , you would start by div the the middle number. If\\nIf the middle is not the middle element, you you know it is be in the half half right half of the list.\\n\\nIf the item is not in the'\n",
      "student argmax tensor([  396, 29896, 29871, 29937,   353,    13,  7420,   278,   304,   740,\n",
      "         2740,  5447, 29889,    13,    13,    13,    13,  3414,   881,    13,\n",
      "           13,    13, 29905, 29876, 29905,  2740,    13,   263,  7581,    13,\n",
      "          393,   338,   278,  1543,   297,   263,  1051,  1051, 29889,    13,\n",
      "          338,   263,    13,  1206,  4878,    13,   310,   310,   438, 29898,\n",
      "         1188,   302, 29897,    13, 29876,    13, 29876,    13,   338,   491,\n",
      "           13,  4821,   278,  1051,  1051,   297,  4203, 29889,  1269,  4331,\n",
      "        29889,    13,    13,   278,   278,    13,   338,  1476, 29889,   278,\n",
      "           13,  2913,   338,    13,  2319, 29889, 16429, 29889, 29876, 29905,\n",
      "        29876,    13,  1342, 29892,   565,   278,   505, 11975,   363,   278,\n",
      "         2944,   297,   263,  1051,   310, 29871, 29889,   278,    13,    13,\n",
      "          491,  1933,   363,   278,  7256,   310, 29892, 29876, 29905, 29876,\n",
      "           13,   278,  7256,   338,   297,   278,  7256, 29892, 29892,   278,\n",
      "          278,   505,   278,   338,   367,   297,   278,  1051,  4203,  1492,\n",
      "         4203,   310,   278,  1051, 29889, 29876, 29905, 29876,    13,   278,\n",
      "         2944,   338,   297,   297,   278,  7256,    13], device='cuda:0')\n",
      "teacher argmax tensor([   13,    13, 29909,  2740,   338,   263,  2740,  5687,   393,  1933,\n",
      "          278,  1543,   297,   263, 12705,  1409, 29889,    13,  1736,   263,\n",
      "        17322, 29899,  4878,   931, 13644,   310,   438, 29898,  1188,   302,\n",
      "          467,    13,    13,  1576,  1736,   491,  1933,  4821,   278,  1051,\n",
      "         2913,   964,  4203, 29892,  1269,  4331,  2745,  2745,   769,  2745,\n",
      "          278,  2944,   338,  1476, 29889,   278,  2740,  2913,   338,  4069,\n",
      "         2319,   304, 16429, 29889,    13,    13,  2831,  1342, 29892,   565,\n",
      "          591,   526, 11975,   363,   278,  2944,   297,   263,  1051,   310,\n",
      "        29871, 29892,   366,   723,  1369,   491,  1933,   278,   278,  7256,\n",
      "         1353, 29889,   960,    13,  3644,   278,  7256,   338,   451,   278,\n",
      "         7256,  1543, 29892,   366,   366,  1073,   372,   338,   367,   297,\n",
      "          278,  4203,  4203,  1492,  4203,   310,   278,  1051, 29889,    13,\n",
      "           13,  3644,   278,  2944,   338,   451,   297,   278],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901, 12027,  7420,   920,   263,\n",
      "          7581,  2740,  1736, 29889, 29871,    13,    13,  3575,   673, 29901,\n",
      "          1839, 29905, 29876, 29905, 29876, 25196, 11856,   338,   263,  2740,\n",
      "          5687,   393, 14061,   385,  2944,   297,   263, 12705,  1051, 29889,\n",
      "           739,   756,   263, 17322, 29899,  4878,   931, 13644,   310,   438,\n",
      "         29898,  1188, 29876,   467, 29905, 29876, 29905, 29876,  3112,  1736,\n",
      "           491,  1933,  4821,   278,  2740,  2913,   297,  4203,   472,  1269,\n",
      "          4331, 29892,   322, 28769,  2745,   278,  2944,   338,  1476,   470,\n",
      "           278,  2740,  2913,   338,  2086,  2319,   304, 16429,  7790, 29876,\n",
      "         29905, 29876,  2831,  1342, 29892,   565,   366,   526, 11975,   363,\n",
      "           385,  2944,   297,   263,  1051,   310,  3694, 29892,   366,  1033,\n",
      "          1369,   491, 11975,   363,   278,  7256,  1543,  7790, 29876, 29905,\n",
      "         29876,  3644,   278,  2944,   338,   297,   278,  7256,  1543, 29892,\n",
      "           769,   366,  1073,   372,  1818,   367,   297,   278,  2175,   470,\n",
      "          1492,  4203,   310,   278,  1051,  7790, 29876, 29905, 29876,  3644,\n",
      "           278,  2944,   338,   451,   297,   278,  2033]], device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: Explain how a binary search works. \\n\\n Your Answer:['\\\\n\\\\nBinary Search is a search algorithm that finds an item in a sorted list. It has a worst-case time complexity of O(logn).\\\\n\\\\nIt works by dividing the search space in half at each step, and repeating until the item is found or the search space is too small to divide.\\\\n\\\\nFor example, if you are searching for an item in a list of numbers, you could start by searching for the middle element.\\\\n\\\\nIf the item is in the middle element, then you know it must be in the left or right half of the list.\\\\n\\\\nIf the item is not in the']\"\n",
      "input_ids torch.Size([1, 157])\n",
      "attention mask torch.Size([1, 157])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 161, 32001])\n",
      "student decoded \"#1\\n# =\\n is the sum between the and and a? Python?\\n\\n\\n\\n task:\\nlistt'n\\\\n\\\\\\\\ is a list type\\n Python. is a to a list.\\n\\n is autable.\\n is that\\n a list is\\n,\\n is be\\n.\\n\\nn\\\\ list is a\\n. structure in Python. is be\\n. it is created.n\\\\n\\n\\n\\nla the\\nn\\\\n\\\\ list is a data structure in Python that is similar to a list, but it is immutable.\\n means that once a tuple is created, it cannot be changed.n\\\\nA list is a mutable data structure in Python that can be changed after it is created.n\\\\n\\n#\\n\\n\"\n",
      "teacher decoded '\\n\\n\\nA\\n list is a collection structure that Python that is similar to a list, but it is immutable. This means that once a tuple is created, it cannot be changed. Tu\\nA list, a mutable data structure in Python that can be changed after it is created.\\n\\n\\n# Hlain the\\n\\n\\nA tuple is a data structure in Python that is similar to a list, but it is immutable. This means that once a tuple is created, it cannot be changed.\\n\\nA list is a mutable data structure in Python that can be changed after it is created.\\n\\n###'\n",
      "student argmax tensor([  396, 29896,    13, 29937,   353,    13,   338,   278,  2533,  1546,\n",
      "          278,   322,   322,   263, 29973,  5132, 29973,    13,    13,    13,\n",
      "           13,  3414, 29901,    13,  1761, 29873, 29915, 29876, 29905, 29876,\n",
      "        29905, 29905,   338,   263,  1051,  1134,    13,  5132, 29889,   338,\n",
      "          263,   304,   263,  1051, 29889,    13,    13,   338,   263,  9246,\n",
      "        29889,    13,   338,   393,    13,   263,  1051,   338,    13, 29892,\n",
      "           13,   338,   367,    13, 29889,    13,    13, 29876, 29905,  1051,\n",
      "          338,   263,    13, 29889,  3829,   297,  5132, 29889,   338,   367,\n",
      "           13, 29889,   372,   338,  2825, 29889, 29876, 29905, 29876,    13,\n",
      "           13,    13,   433,   278,    13, 29876, 29905, 29876, 29905,  1051,\n",
      "          338,   263,   848,  3829,   297,  5132,   393,   338,  2788,   304,\n",
      "          263,  1051, 29892,   541,   372,   338,  5198,  9246, 29889,    13,\n",
      "         2794,   393,  2748,   263, 18761,   338,  2825, 29892,   372,  2609,\n",
      "          367,  3939, 29889, 29876, 29905, 29876, 29909,  1051,   338,   263,\n",
      "        26691,   848,  3829,   297,  5132,   393,   508,   367,  3939,  1156,\n",
      "          372,   338,  2825, 29889, 29876, 29905, 29876,    13, 29937,    13,\n",
      "           13], device='cuda:0')\n",
      "teacher argmax tensor([   13,    13,    13, 29909,    13,  1051,   338,   263,  4333,  3829,\n",
      "          393,  5132,   393,   338,  2788,   304,   263,  1051, 29892,   541,\n",
      "          372,   338,  5198,  9246, 29889,   910,  2794,   393,  2748,   263,\n",
      "        18761,   338,  2825, 29892,   372,  2609,   367,  3939, 29889, 12603,\n",
      "           13, 29909,  1051, 29892,   263, 26691,   848,  3829,   297,  5132,\n",
      "          393,   508,   367,  3939,  1156,   372,   338,  2825, 29889,    13,\n",
      "           13,    13, 29937,   379,  7420,   278,    13,    13,    13, 29909,\n",
      "        18761,   338,   263,   848,  3829,   297,  5132,   393,   338,  2788,\n",
      "          304,   263,  1051, 29892,   541,   372,   338,  5198,  9246, 29889,\n",
      "          910,  2794,   393,  2748,   263, 18761,   338,  2825, 29892,   372,\n",
      "         2609,   367,  3939, 29889,    13,    13, 29909,  1051,   338,   263,\n",
      "        26691,   848,  3829,   297,  5132,   393,   508,   367,  3939,  1156,\n",
      "          372,   338,  2825, 29889,    13,    13,  2277, 29937],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901,  1724,   338,   278,  4328,\n",
      "          1546,   263,  1051,   322, 18761,   297,  5132, 29973, 29871,    13,\n",
      "            13,  3575,   673, 29901,  1839, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29909, 18761,   338,   263,   848,  3829,   297,  5132,   393,\n",
      "           338,  2788,   304,   263,  1051, 29892,   541,   372,   338,  5198,\n",
      "          9246, 29889,   910,  2794,   393,  2748,   263, 18761,   338,  2825,\n",
      "         29892,   372,  2609,   367,  3939,  7790, 29876, 29905, 29876, 29909,\n",
      "          1051,   338,   263, 26691,   848,  3829,   297,  5132,   393,   508,\n",
      "           367,  3939,  1156,   372,   338,  2825,  7790, 29876, 29905, 29876,\n",
      "          2277, 29937, 12027,  7420, 29901,   320, 29876, 29905, 29876, 29909,\n",
      "         18761,   338,   263,   848,  3829,   297,  5132,   393,   338,  2788,\n",
      "           304,   263,  1051, 29892,   541,   372,   338,  5198,  9246, 29889,\n",
      "           910,  2794,   393,  2748,   263, 18761,   338,  2825, 29892,   372,\n",
      "          2609,   367,  3939,  7790, 29876, 29905, 29876, 29909,  1051,   338,\n",
      "           263, 26691,   848,  3829,   297,  5132,   393,   508,   367,  3939,\n",
      "          1156,   372,   338,  2825,  7790, 29876, 29905, 29876,  2277, 29937,\n",
      "          2033]], device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: What is the difference between a list and tuple in Python? \\n\\n Your Answer:['\\\\n\\\\n\\\\nA tuple is a data structure in Python that is similar to a list, but it is immutable. This means that once a tuple is created, it cannot be changed.\\\\n\\\\nA list is a mutable data structure in Python that can be changed after it is created.\\\\n\\\\n### Explain: \\\\n\\\\nA tuple is a data structure in Python that is similar to a list, but it is immutable. This means that once a tuple is created, it cannot be changed.\\\\n\\\\nA list is a mutable data structure in Python that can be changed after it is created.\\\\n\\\\n###']\"\n",
      "input_ids torch.Size([1, 161])\n",
      "attention mask torch.Size([1, 161])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 153, 32001])\n",
      "student decoded '#1 # =\\n to the collection work in Java?\\n\\n\\n\\n task:\\n\\n\\n\\nn\\\\\\nn\\\\arbage\\n\\n Python\\n\\n\\n\\n\\n\\ning\\n\\n\\n\\n\\n longer\\n\\n. the\\n.\\n is\\n by theifying the\\ning up memoryused memory.\\nusedenced\\n, and\\n\\n. are no longer used the.\\n\\nn\\n\\n of\\n collection in Python is\\n\\n\\n the is\\n\\n\\n. the\\n.\\n, the is the by the\\n\\n. the memory iss that the is a more in\\n to the object. the.\\n is the\\n to\\n up memory memory. by the object. variable. and the the for the\\n'\n",
      "teacher decoded '\\n\\n\\n##\\nGarbage collection is Python is a process memory of freeing up memory that is no longer in used by a program. This is done by theifying and removinging up unused memory, objectsreferenced objects, and other memory that are no longer in use.\\n\\nThe garbage of garbage collection in Python is managed \" because it is done explicitly triggered by the programmer. Instead, it is done by the Python runtime environment it memory determs that there is un longer any reference to an object. variable.\\n is the system to free up memory memory that by the object or variable, which it available for'\n",
      "student argmax tensor([  396, 29896, 29871, 29937,   353,    13,   304,   278,  4333,   664,\n",
      "          297,  3355, 29973,    13,    13,    13,    13,  3414, 29901,    13,\n",
      "           13,    13,    13, 29876, 29905,    13, 29876, 29905,   279, 17807,\n",
      "           13,    13,  5132,    13,    13,    13,    13,    13,    13,   292,\n",
      "           13,    13,    13,    13,    13,  5520,    13,    13, 29889,   278,\n",
      "           13, 29889,    13,   338,    13,   491,   278,  9215,   278,    13,\n",
      "          292,   701,  3370,  3880,  3370, 29889,    13,  3880,  9223,    13,\n",
      "        29892,   322,    13,    13, 29889,   526,   694,  5520,  1304,   278,\n",
      "        29889,    13,    13, 29876,    13,    13,   310,    13,  4333,   297,\n",
      "         5132,   338,    13,    13,    13,   278,   338,    13,    13,    13,\n",
      "        29889,   278,    13, 29889,    13, 29892,   278,   338,   278,   491,\n",
      "          278,    13,    13, 29889,   278,  3370,   338, 29879,   393,   278,\n",
      "          338,   263,   901,   297,    13,   304,   278,  1203, 29889,   278,\n",
      "        29889,    13,   338,   278,    13,   304,    13,   701,  3370,  3370,\n",
      "        29889,   491,   278,  1203, 29889,  2286, 29889,   322,   278,   278,\n",
      "          363,   278,    13], device='cuda:0')\n",
      "teacher argmax tensor([   13,    13,    13,  2277,    13, 29954,   279, 17807,  4333,   338,\n",
      "         5132,   338,   263,  1889,  3370,   310,  3889,   292,   701,  3370,\n",
      "          393,   338,   694,  5520,   297,  1304,   491,   263,  1824, 29889,\n",
      "          910,   338,  2309,   491,   278,  9215,   322, 11077,   292,   701,\n",
      "          443,  3880,  3370, 29892,  3618, 20275,  9223,  3618, 29892,   322,\n",
      "          916,  3370,   393,   526,   694,  5520,   297,   671, 29889,    13,\n",
      "           13,  1576, 25861,   310, 25861,  4333,   297,  5132,   338,  8745,\n",
      "          376,  1363,   372,   338,  2309,  9479, 19799,   491,   278, 27922,\n",
      "        29889,  8669, 29892,   372,   338,  2309,   491,   278,  5132, 10073,\n",
      "         5177,   372,  3370,  3683, 29879,   393,   727,   338,   443,  5520,\n",
      "          738,  3407,   304,   385,  1203, 29889,  2286, 29889,    13,   338,\n",
      "          278,  1788,   304,  3889,   701,  3370,  3370,   393,   491,   278,\n",
      "         1203,   470,  2286, 29892,   607,   372,  3625,   363],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901,  1128,   947, 25861,  4333,\n",
      "           664,   297,  5132, 29973, 29871,    13,    13,  3575,   673, 29901,\n",
      "          1839, 29905, 29876, 29905, 29876, 28956, 29905, 29876, 29954,   279,\n",
      "         17807,  4333,   297,  5132,   338,   278, 18428,  1889,   310,  3889,\n",
      "           292,   701,  3370,   393,   338,   694,  5520,  1641,  1304,   491,\n",
      "           263,  1824, 29889,   910,   338,  2309,   491,  2893,  9215,   322,\n",
      "          3889,   292,   701,   443,  3880,  3651, 29892,   443, 20275,  9223,\n",
      "          3618, 29892,   322,   916,  3618,   393,   526,   694,  5520,   297,\n",
      "           671,  7790, 29876, 29905, 29876,  1576,  1889,   310, 25861,  4333,\n",
      "           297,  5132,   338,  2000, 18428,  1363,   372,   338,   451,  7522,\n",
      "         19799,   491,   278, 27922, 29889,  8669, 29892,   372,   338, 19799,\n",
      "           491,   278,  5132, 10073,   746,   278,  1788,  6459, 29879,   393,\n",
      "           727,   338,   694,  5520,   738,  3407,   304,   385,  1203,   470,\n",
      "          2286, 29889,   910,  6511,   278,  1824,   304,  3889,   701,   278,\n",
      "          3370,  1304,   491,   278,  1203,   470,  2286, 29892,  3907,   372,\n",
      "          3625,   363,  2033]], device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: How does garbage collection work in Python? \\n\\n Your Answer:['\\\\n\\\\n```\\\\nGarbage collection in Python is the automatic process of freeing up memory that is no longer being used by a program. This is done by identifying and freeing up unused variables, unreferenced objects, and other objects that are no longer in use.\\\\n\\\\nThe process of garbage collection in Python is called automatic because it is not manually triggered by the programmer. Instead, it is triggered by the Python runtime when the system detects that there is no longer any reference to an object or variable. This allows the program to free up the memory used by the object or variable, making it available for']\"\n",
      "input_ids torch.Size([1, 153])\n",
      "attention mask torch.Size([1, 153])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 159, 32001])\n",
      "student decoded '#1 # =\\nlain the difference of aator in Python.\\n\\n\\n\\n decor:\\n\\n\\n\\nn\\\\orator\\n\\n decor\\n. Python.\\n\\n to\\n\\n\\n\\n\\n.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nator\\n\\n function\\n\\n a decor\\n the function..\\n\\n\\n\\n can\\n\\n a decorator to a function that\\n the function\\n and the function. to the function.\\n\\n\\n\\n\\n theator\\n\\n can a function and decor a function and a argument and\\n\\n\\n\\n you decor a decorator to the function.\\n\\nn\\n\\nator\\n\\n the function and decor to decorate and the argument.\\n the\\n a function that decor theator. the\\n'\n",
      "teacher decoded \"\\n\\n##orators are a way tool in Python that allow you to add functionality functionality to functions. They\\n Dec example, you can use a loggingator to a function that prints a parameter to the function..\\n\\n This can also add a decorator to a function that adds the function' and the number to to the function.\\n\\n Dec add decorators, you first a function that takes a function as an argument.\\n\\n You, add a decorator to the function.\\n\\n The decorator is takes the function as want to decorate as an argument and and it returns a new that calls theated with\"\n",
      "student argmax tensor([  396, 29896, 29871, 29937,   353,    13,  7420,   278,  4328,   310,\n",
      "          263,  1061,   297,  5132, 29889,    13,    13,    13,    13, 10200,\n",
      "        29901,    13,    13,    13,    13, 29876, 29905,   272,  1061,    13,\n",
      "           13, 10200,    13, 29889,  5132, 29889,    13,    13,   304,    13,\n",
      "           13,    13,    13,    13, 29889,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,  1061,    13,    13,   740,\n",
      "           13,    13,   263, 10200,    13,   278,   740, 29889, 29889,    13,\n",
      "           13,    13,    13,   508,    13,    13,   263, 10200,  1061,   304,\n",
      "          263,   740,   393,    13,   278,   740,    13,   322,   278,   740,\n",
      "        29889,   304,   278,   740, 29889,    13,    13,    13,    13,    13,\n",
      "          278,  1061,    13,    13,   508,   263,   740,   322, 10200,   263,\n",
      "          740,   322,   263,  2980,   322,    13,    13,    13,    13,   366,\n",
      "        10200,   263, 10200,  1061,   304,   278,   740, 29889,    13,    13,\n",
      "        29876,    13,    13,  1061,    13,    13,   278,   740,   322, 10200,\n",
      "          304, 10200,   403,   322,   278,  2980, 29889,    13,   278,    13,\n",
      "          263,   740,   393, 10200,   278,  1061, 29889,   278,    13],\n",
      "       device='cuda:0')\n",
      "teacher argmax tensor([   13,    13,  2277,   272,  4097,   526,   263,   982,  5780,   297,\n",
      "         5132,   393,  2758,   366,   304,   788,  9863,  9863,   304,  3168,\n",
      "        29889,  2688,    13,  3826,  1342, 29892,   366,   508,   671,   263,\n",
      "        12183,  1061,   304,   263,   740,   393, 14677,   263,  3443,   304,\n",
      "          278,   740, 29889, 29889,    13,    13,   910,   508,   884,   788,\n",
      "          263, 10200,  1061,   304,   263,   740,   393, 12778,   278,   740,\n",
      "        29915,   322,   278,  1353,   304,   304,   278,   740, 29889,    13,\n",
      "           13,  3826,   788, 10200,  4097, 29892,   366,   937,   263,   740,\n",
      "          393,  4893,   263,   740,   408,   385,  2980, 29889,    13,    13,\n",
      "          887, 29892,   788,   263, 10200,  1061,   304,   278,   740, 29889,\n",
      "           13,    13,   450, 10200,  1061,   338,  4893,   278,   740,   408,\n",
      "          864,   304, 10200,   403,   408,   385,  2980,   322,   322,   372,\n",
      "         3639,   263,   716,   393,  5717,   278,   630,   411],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901, 12027,  7420,   278,  6964,\n",
      "           310, 10200,  4097,   297,  5132, 29889, 29871,    13,    13,  3575,\n",
      "           673, 29901,  1839, 29905, 29876, 29905, 29876,  3826,   272,  4097,\n",
      "           526,   263, 13988,  5780,   297,  5132,   393,  6511,   366,   304,\n",
      "           788,  4805,  9863,   304,  3168,  7790, 29876, 29905, 29876,  1152,\n",
      "          1342, 29892,   366,   508,   788,   263, 10200,  1061,   304,   263,\n",
      "           740,   393, 12778,   263,  3443,   304,   278,   740, 12608,  7790,\n",
      "         29876, 29905, 29876,   887,   508,   884,   788,   263, 10200,  1061,\n",
      "           304,   263,   740,   393, 14677,   278,   740,  1024,   322,   278,\n",
      "          4128,  4502,   304,   278,   740,  7790, 29876, 29905, 29876,  1763,\n",
      "           671, 10200,  4097, 29892,   366,  1653,   263,   740,   393,  4893,\n",
      "           263,   740,   408,   385,  2980,  7790, 29876, 29905, 29876,  1987,\n",
      "           366,   788,   278, 10200,  1061,   304,   278,   740,  7790, 29876,\n",
      "         29905, 29876,   450, 10200,  1061,   740,  4893,   278,   740,   366,\n",
      "           864,   304, 10200,   403,   408,   385,  2980, 29892,   322,   372,\n",
      "          3639,   263,   740,   393,   338, 10200,   630,   411,  2033]],\n",
      "       device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: Explain the concept of decorators in Python. \\n\\n Your Answer:['\\\\n\\\\n Decorators are a powerful tool in Python that allows you to add extra functionality to functions.\\\\n\\\\n For example, you can add a decorator to a function that adds a parameter to the function signature.\\\\n\\\\n You can also add a decorator to a function that prints the function name and the parameters passed to the function.\\\\n\\\\n To use decorators, you create a function that takes a function as an argument.\\\\n\\\\n Then you add the decorator to the function.\\\\n\\\\n The decorator function takes the function you want to decorate as an argument, and it returns a function that is decorated with']\"\n",
      "input_ids torch.Size([1, 159])\n",
      "attention mask torch.Size([1, 159])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Epoch 10, Average Loss: 452.57910919189453\n",
      "Epoch 20, Average Loss: 268.07635498046875\n",
      "Epoch 30, Average Loss: 142.24273109436035\n",
      "Epoch 40, Average Loss: 67.83398914337158\n",
      "Epoch 50, Average Loss: 37.12254333496094\n",
      "Epoch 60, Average Loss: 28.109890460968018\n",
      "Epoch 70, Average Loss: 22.81316828727722\n",
      "Epoch 80, Average Loss: 18.173298358917236\n",
      "Epoch 90, Average Loss: 16.643163204193115\n",
      "Epoch 100, Average Loss: 13.250158071517944\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 157, 32001])\n",
      "student decoded \"#1\\n# \\nlain the to\\n\\n\\n binary\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nA search is a search algorithm that div the element in a sorted array.\\n works a time-case time complexity of O(log n).\\n\\nThe works by dividing the list space into half, each step. and then the the item is found. the search space is empty small. divide.\\n\\nFor example, if we' searching for an item in a list of , you would start by div the the middle number. If\\nIf the middle is not the middle element, you you know that is be in the half half right half of the list.\\n\\nIf it item is not in the\"\n",
      "teacher decoded '\\n\\nA search is a search algorithm that div the element in a sorted array.\\n works a worst-case time complexity of O(log n).\\n\\nThe works by dividing the list space into half, each step until until then until the item is found. the search space is empty small to divide.\\n\\nFor example, if we are searching for the item in a list of , you would start by div the the middle number. If\\nIf the middle is not the middle element, you you know it is be in the half half right half of the list.\\n\\nIf the item is not in the'\n",
      "student argmax tensor([  396, 29896,    13, 29937, 29871,    13,  7420,   278,   304,    13,\n",
      "           13,    13,  7581,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13, 29909,  2740,   338,   263,  2740,  5687,   393,  1933,   278,\n",
      "         1543,   297,   263, 12705,  1409, 29889,    13,  1736,   263,   931,\n",
      "        29899,  4878,   931, 13644,   310,   438, 29898,  1188,   302,   467,\n",
      "           13,    13,  1576,  1736,   491,  1933,  4821,   278,  1051,  2913,\n",
      "          964,  4203, 29892,  1269,  4331, 29889,   322,   769,   278,   278,\n",
      "         2944,   338,  1476, 29889,   278,  2740,  2913,   338,  4069,  2319,\n",
      "        29889, 16429, 29889,    13,    13,  2831,  1342, 29892,   565,   591,\n",
      "        29915, 11975,   363,   385,  2944,   297,   263,  1051,   310, 29871,\n",
      "        29892,   366,   723,  1369,   491,  1933,   278,   278,  7256,  1353,\n",
      "        29889,   960,    13,  3644,   278,  7256,   338,   451,   278,  7256,\n",
      "         1543, 29892,   366,   366,  1073,   393,   338,   367,   297,   278,\n",
      "         4203,  4203,  1492,  4203,   310,   278,  1051, 29889,    13,    13,\n",
      "         3644,   372,  2944,   338,   451,   297,   278], device='cuda:0')\n",
      "teacher argmax tensor([   13,    13, 29909,  2740,   338,   263,  2740,  5687,   393,  1933,\n",
      "          278,  1543,   297,   263, 12705,  1409, 29889,    13,  1736,   263,\n",
      "        17322, 29899,  4878,   931, 13644,   310,   438, 29898,  1188,   302,\n",
      "          467,    13,    13,  1576,  1736,   491,  1933,  4821,   278,  1051,\n",
      "         2913,   964,  4203, 29892,  1269,  4331,  2745,  2745,   769,  2745,\n",
      "          278,  2944,   338,  1476, 29889,   278,  2740,  2913,   338,  4069,\n",
      "         2319,   304, 16429, 29889,    13,    13,  2831,  1342, 29892,   565,\n",
      "          591,   526, 11975,   363,   278,  2944,   297,   263,  1051,   310,\n",
      "        29871, 29892,   366,   723,  1369,   491,  1933,   278,   278,  7256,\n",
      "         1353, 29889,   960,    13,  3644,   278,  7256,   338,   451,   278,\n",
      "         7256,  1543, 29892,   366,   366,  1073,   372,   338,   367,   297,\n",
      "          278,  4203,  4203,  1492,  4203,   310,   278,  1051, 29889,    13,\n",
      "           13,  3644,   278,  2944,   338,   451,   297,   278],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901, 12027,  7420,   920,   263,\n",
      "          7581,  2740,  1736, 29889, 29871,    13,    13,  3575,   673, 29901,\n",
      "          1839, 29905, 29876, 29905, 29876, 25196, 11856,   338,   263,  2740,\n",
      "          5687,   393, 14061,   385,  2944,   297,   263, 12705,  1051, 29889,\n",
      "           739,   756,   263, 17322, 29899,  4878,   931, 13644,   310,   438,\n",
      "         29898,  1188, 29876,   467, 29905, 29876, 29905, 29876,  3112,  1736,\n",
      "           491,  1933,  4821,   278,  2740,  2913,   297,  4203,   472,  1269,\n",
      "          4331, 29892,   322, 28769,  2745,   278,  2944,   338,  1476,   470,\n",
      "           278,  2740,  2913,   338,  2086,  2319,   304, 16429,  7790, 29876,\n",
      "         29905, 29876,  2831,  1342, 29892,   565,   366,   526, 11975,   363,\n",
      "           385,  2944,   297,   263,  1051,   310,  3694, 29892,   366,  1033,\n",
      "          1369,   491, 11975,   363,   278,  7256,  1543,  7790, 29876, 29905,\n",
      "         29876,  3644,   278,  2944,   338,   297,   278,  7256,  1543, 29892,\n",
      "           769,   366,  1073,   372,  1818,   367,   297,   278,  2175,   470,\n",
      "          1492,  4203,   310,   278,  1051,  7790, 29876, 29905, 29876,  3644,\n",
      "           278,  2944,   338,   451,   297,   278,  2033]], device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: Explain how a binary search works. \\n\\n Your Answer:['\\\\n\\\\nBinary Search is a search algorithm that finds an item in a sorted list. It has a worst-case time complexity of O(logn).\\\\n\\\\nIt works by dividing the search space in half at each step, and repeating until the item is found or the search space is too small to divide.\\\\n\\\\nFor example, if you are searching for an item in a list of numbers, you could start by searching for the middle element.\\\\n\\\\nIf the item is in the middle element, then you know it must be in the left or right half of the list.\\\\n\\\\nIf the item is not in the']\"\n",
      "input_ids torch.Size([1, 157])\n",
      "attention mask torch.Size([1, 157])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 161, 32001])\n",
      "student decoded '#1\\n# \\n is the difference between a\\n and a\\n and\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nA\\n list is a collection structure that Python that is imm to a list, but it is immutable. This means that once a tuple is created, its cannot be changed. Tu\\nA list is a mutable data structure in Python that allows be changed. it is created.\\n\\n\\n# Hlain\\n\\n\\n\\nA tuple is a data structure in Python that is similar to a list, but it is immutable. This means that once a tuple is created, it cannot be changed.\\n\\nA list is a mutable data structure in Python that can be changed after it is created.\\n\\n###'\n",
      "teacher decoded '\\n\\n\\nA\\n list is a collection structure that Python that is similar to a list, but it is immutable. This means that once a tuple is created, it cannot be changed. Tu\\nA list, a mutable data structure in Python that can be changed after it is created.\\n\\n\\n# Hlain the\\n\\n\\nA tuple is a data structure in Python that is similar to a list, but it is immutable. This means that once a tuple is created, it cannot be changed.\\n\\nA list is a mutable data structure in Python that can be changed after it is created.\\n\\n###'\n",
      "student argmax tensor([  396, 29896,    13, 29937, 29871,    13,   338,   278,  4328,  1546,\n",
      "          263,    13,   322,   263,    13,   322,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13, 29909,    13,  1051,   338,\n",
      "          263,  4333,  3829,   393,  5132,   393,   338,  5198,   304,   263,\n",
      "         1051, 29892,   541,   372,   338,  5198,  9246, 29889,   910,  2794,\n",
      "          393,  2748,   263, 18761,   338,  2825, 29892,   967,  2609,   367,\n",
      "         3939, 29889, 12603,    13, 29909,  1051,   338,   263, 26691,   848,\n",
      "         3829,   297,  5132,   393,  6511,   367,  3939, 29889,   372,   338,\n",
      "         2825, 29889,    13,    13,    13, 29937,   379,  7420,    13,    13,\n",
      "           13,    13, 29909, 18761,   338,   263,   848,  3829,   297,  5132,\n",
      "          393,   338,  2788,   304,   263,  1051, 29892,   541,   372,   338,\n",
      "         5198,  9246, 29889,   910,  2794,   393,  2748,   263, 18761,   338,\n",
      "         2825, 29892,   372,  2609,   367,  3939, 29889,    13,    13, 29909,\n",
      "         1051,   338,   263, 26691,   848,  3829,   297,  5132,   393,   508,\n",
      "          367,  3939,  1156,   372,   338,  2825, 29889,    13,    13,  2277,\n",
      "        29937], device='cuda:0')\n",
      "teacher argmax tensor([   13,    13,    13, 29909,    13,  1051,   338,   263,  4333,  3829,\n",
      "          393,  5132,   393,   338,  2788,   304,   263,  1051, 29892,   541,\n",
      "          372,   338,  5198,  9246, 29889,   910,  2794,   393,  2748,   263,\n",
      "        18761,   338,  2825, 29892,   372,  2609,   367,  3939, 29889, 12603,\n",
      "           13, 29909,  1051, 29892,   263, 26691,   848,  3829,   297,  5132,\n",
      "          393,   508,   367,  3939,  1156,   372,   338,  2825, 29889,    13,\n",
      "           13,    13, 29937,   379,  7420,   278,    13,    13,    13, 29909,\n",
      "        18761,   338,   263,   848,  3829,   297,  5132,   393,   338,  2788,\n",
      "          304,   263,  1051, 29892,   541,   372,   338,  5198,  9246, 29889,\n",
      "          910,  2794,   393,  2748,   263, 18761,   338,  2825, 29892,   372,\n",
      "         2609,   367,  3939, 29889,    13,    13, 29909,  1051,   338,   263,\n",
      "        26691,   848,  3829,   297,  5132,   393,   508,   367,  3939,  1156,\n",
      "          372,   338,  2825, 29889,    13,    13,  2277, 29937],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901,  1724,   338,   278,  4328,\n",
      "          1546,   263,  1051,   322, 18761,   297,  5132, 29973, 29871,    13,\n",
      "            13,  3575,   673, 29901,  1839, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29909, 18761,   338,   263,   848,  3829,   297,  5132,   393,\n",
      "           338,  2788,   304,   263,  1051, 29892,   541,   372,   338,  5198,\n",
      "          9246, 29889,   910,  2794,   393,  2748,   263, 18761,   338,  2825,\n",
      "         29892,   372,  2609,   367,  3939,  7790, 29876, 29905, 29876, 29909,\n",
      "          1051,   338,   263, 26691,   848,  3829,   297,  5132,   393,   508,\n",
      "           367,  3939,  1156,   372,   338,  2825,  7790, 29876, 29905, 29876,\n",
      "          2277, 29937, 12027,  7420, 29901,   320, 29876, 29905, 29876, 29909,\n",
      "         18761,   338,   263,   848,  3829,   297,  5132,   393,   338,  2788,\n",
      "           304,   263,  1051, 29892,   541,   372,   338,  5198,  9246, 29889,\n",
      "           910,  2794,   393,  2748,   263, 18761,   338,  2825, 29892,   372,\n",
      "          2609,   367,  3939,  7790, 29876, 29905, 29876, 29909,  1051,   338,\n",
      "           263, 26691,   848,  3829,   297,  5132,   393,   508,   367,  3939,\n",
      "          1156,   372,   338,  2825,  7790, 29876, 29905, 29876,  2277, 29937,\n",
      "          2033]], device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: What is the difference between a list and tuple in Python? \\n\\n Your Answer:['\\\\n\\\\n\\\\nA tuple is a data structure in Python that is similar to a list, but it is immutable. This means that once a tuple is created, it cannot be changed.\\\\n\\\\nA list is a mutable data structure in Python that can be changed after it is created.\\\\n\\\\n### Explain: \\\\n\\\\nA tuple is a data structure in Python that is similar to a list, but it is immutable. This means that once a tuple is created, it cannot be changed.\\\\n\\\\nA list is a mutable data structure in Python that can be changed after it is created.\\\\n\\\\n###']\"\n",
      "input_ids torch.Size([1, 161])\n",
      "attention mask torch.Size([1, 161])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 153, 32001])\n",
      "student decoded '#1\\n# \\n to the collection work in\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n##pythonGarbage collection is Python is a process memory of freeing up memory that is no longer needed used by a program. This process done by identifying and removinging up unused memory, objectsreferenced objects, and un memory that are no longer needed use.\\n\\nThe garbage of garbage collection in Python is managed automatic because it happens done explicitly triggered by the programmer. Instead, it is done by the Python runtime environment it memory determs that there is un longer any reference to an object. variable. This is the system to free up memory memory that by the object or variable, which it available for'\n",
      "teacher decoded '\\n\\n\\n##\\nGarbage collection is Python is a process memory of freeing up memory that is no longer in used by a program. This is done by theifying and removinging up unused memory, objectsreferenced objects, and other memory that are no longer in use.\\n\\nThe garbage of garbage collection in Python is managed \" because it is done explicitly triggered by the programmer. Instead, it is done by the Python runtime environment it memory determs that there is un longer any reference to an object. variable.\\n is the system to free up memory memory that by the object or variable, which it available for'\n",
      "student argmax tensor([  396, 29896,    13, 29937, 29871,    13,   304,   278,  4333,   664,\n",
      "          297,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,  2277,  4691,\n",
      "        29954,   279, 17807,  4333,   338,  5132,   338,   263,  1889,  3370,\n",
      "          310,  3889,   292,   701,  3370,   393,   338,   694,  5520,  4312,\n",
      "         1304,   491,   263,  1824, 29889,   910,  1889,  2309,   491,  2893,\n",
      "         9215,   322, 11077,   292,   701,   443,  3880,  3370, 29892,  3618,\n",
      "        20275,  9223,  3618, 29892,   322,   443,  3370,   393,   526,   694,\n",
      "         5520,  4312,   671, 29889,    13,    13,  1576, 25861,   310, 25861,\n",
      "         4333,   297,  5132,   338,  8745, 18428,  1363,   372,  5930,  2309,\n",
      "         9479, 19799,   491,   278, 27922, 29889,  8669, 29892,   372,   338,\n",
      "         2309,   491,   278,  5132, 10073,  5177,   372,  3370,  3683, 29879,\n",
      "          393,   727,   338,   443,  5520,   738,  3407,   304,   385,  1203,\n",
      "        29889,  2286, 29889,   910,   338,   278,  1788,   304,  3889,   701,\n",
      "         3370,  3370,   393,   491,   278,  1203,   470,  2286, 29892,   607,\n",
      "          372,  3625,   363], device='cuda:0')\n",
      "teacher argmax tensor([   13,    13,    13,  2277,    13, 29954,   279, 17807,  4333,   338,\n",
      "         5132,   338,   263,  1889,  3370,   310,  3889,   292,   701,  3370,\n",
      "          393,   338,   694,  5520,   297,  1304,   491,   263,  1824, 29889,\n",
      "          910,   338,  2309,   491,   278,  9215,   322, 11077,   292,   701,\n",
      "          443,  3880,  3370, 29892,  3618, 20275,  9223,  3618, 29892,   322,\n",
      "          916,  3370,   393,   526,   694,  5520,   297,   671, 29889,    13,\n",
      "           13,  1576, 25861,   310, 25861,  4333,   297,  5132,   338,  8745,\n",
      "          376,  1363,   372,   338,  2309,  9479, 19799,   491,   278, 27922,\n",
      "        29889,  8669, 29892,   372,   338,  2309,   491,   278,  5132, 10073,\n",
      "         5177,   372,  3370,  3683, 29879,   393,   727,   338,   443,  5520,\n",
      "          738,  3407,   304,   385,  1203, 29889,  2286, 29889,    13,   338,\n",
      "          278,  1788,   304,  3889,   701,  3370,  3370,   393,   491,   278,\n",
      "         1203,   470,  2286, 29892,   607,   372,  3625,   363],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901,  1128,   947, 25861,  4333,\n",
      "           664,   297,  5132, 29973, 29871,    13,    13,  3575,   673, 29901,\n",
      "          1839, 29905, 29876, 29905, 29876, 28956, 29905, 29876, 29954,   279,\n",
      "         17807,  4333,   297,  5132,   338,   278, 18428,  1889,   310,  3889,\n",
      "           292,   701,  3370,   393,   338,   694,  5520,  1641,  1304,   491,\n",
      "           263,  1824, 29889,   910,   338,  2309,   491,  2893,  9215,   322,\n",
      "          3889,   292,   701,   443,  3880,  3651, 29892,   443, 20275,  9223,\n",
      "          3618, 29892,   322,   916,  3618,   393,   526,   694,  5520,   297,\n",
      "           671,  7790, 29876, 29905, 29876,  1576,  1889,   310, 25861,  4333,\n",
      "           297,  5132,   338,  2000, 18428,  1363,   372,   338,   451,  7522,\n",
      "         19799,   491,   278, 27922, 29889,  8669, 29892,   372,   338, 19799,\n",
      "           491,   278,  5132, 10073,   746,   278,  1788,  6459, 29879,   393,\n",
      "           727,   338,   694,  5520,   738,  3407,   304,   385,  1203,   470,\n",
      "          2286, 29889,   910,  6511,   278,  1824,   304,  3889,   701,   278,\n",
      "          3370,  1304,   491,   278,  1203,   470,  2286, 29892,  3907,   372,\n",
      "          3625,   363,  2033]], device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: How does garbage collection work in Python? \\n\\n Your Answer:['\\\\n\\\\n```\\\\nGarbage collection in Python is the automatic process of freeing up memory that is no longer being used by a program. This is done by identifying and freeing up unused variables, unreferenced objects, and other objects that are no longer in use.\\\\n\\\\nThe process of garbage collection in Python is called automatic because it is not manually triggered by the programmer. Instead, it is triggered by the Python runtime when the system detects that there is no longer any reference to an object or variable. This allows the program to free up the memory used by the object or variable, making it available for']\"\n",
      "input_ids torch.Size([1, 153])\n",
      "attention mask torch.Size([1, 153])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 159, 32001])\n",
      "student decoded '#1\\n# \\nlain the following of\\nator and Python in\\n\\n\\n\\n\\n Python Python\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDecorators are a way feature in Python that allow you to add functionality functionality to functions and They\\n Dec example, you can use logging loggingator to a function that prints a parameter to the function..\\n\\n This can also add a decorator to a function that adds out function name and the number to to the function.\\n\\n Dec add decorators, you first a function that takes a function as an argument and\\n\\n You, decor a decorator to the function you\\n\\n The decorator is is the function as want to decorate as an argument and and it returns a new that has decorated with'\n",
      "teacher decoded \"\\n\\n##orators are a way tool in Python that allow you to add functionality functionality to functions. They\\n Dec example, you can use a loggingator to a function that prints a parameter to the function..\\n\\n This can also add a decorator to a function that adds the function' and the number to to the function.\\n\\n Dec add decorators, you first a function that takes a function as an argument.\\n\\n You, add a decorator to the function.\\n\\n The decorator is takes the function as want to decorate as an argument and and it returns a new that calls theated with\"\n",
      "student argmax tensor([  396, 29896,    13, 29937, 29871,    13,  7420,   278,  1494,   310,\n",
      "           13,  1061,   322,  5132,   297,    13,    13,    13,    13,    13,\n",
      "         5132,  5132,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,  6185,   272,  4097,   526,   263,   982,  4682,\n",
      "          297,  5132,   393,  2758,   366,   304,   788,  9863,  9863,   304,\n",
      "         3168,   322,  2688,    13,  3826,  1342, 29892,   366,   508,   671,\n",
      "        12183, 12183,  1061,   304,   263,   740,   393, 14677,   263,  3443,\n",
      "          304,   278,   740, 29889, 29889,    13,    13,   910,   508,   884,\n",
      "          788,   263, 10200,  1061,   304,   263,   740,   393, 12778,   714,\n",
      "          740,  1024,   322,   278,  1353,   304,   304,   278,   740, 29889,\n",
      "           13,    13,  3826,   788, 10200,  4097, 29892,   366,   937,   263,\n",
      "          740,   393,  4893,   263,   740,   408,   385,  2980,   322,    13,\n",
      "           13,   887, 29892, 10200,   263, 10200,  1061,   304,   278,   740,\n",
      "          366,    13,    13,   450, 10200,  1061,   338,   338,   278,   740,\n",
      "          408,   864,   304, 10200,   403,   408,   385,  2980,   322,   322,\n",
      "          372,  3639,   263,   716,   393,   756, 10200,   630,   411],\n",
      "       device='cuda:0')\n",
      "teacher argmax tensor([   13,    13,  2277,   272,  4097,   526,   263,   982,  5780,   297,\n",
      "         5132,   393,  2758,   366,   304,   788,  9863,  9863,   304,  3168,\n",
      "        29889,  2688,    13,  3826,  1342, 29892,   366,   508,   671,   263,\n",
      "        12183,  1061,   304,   263,   740,   393, 14677,   263,  3443,   304,\n",
      "          278,   740, 29889, 29889,    13,    13,   910,   508,   884,   788,\n",
      "          263, 10200,  1061,   304,   263,   740,   393, 12778,   278,   740,\n",
      "        29915,   322,   278,  1353,   304,   304,   278,   740, 29889,    13,\n",
      "           13,  3826,   788, 10200,  4097, 29892,   366,   937,   263,   740,\n",
      "          393,  4893,   263,   740,   408,   385,  2980, 29889,    13,    13,\n",
      "          887, 29892,   788,   263, 10200,  1061,   304,   278,   740, 29889,\n",
      "           13,    13,   450, 10200,  1061,   338,  4893,   278,   740,   408,\n",
      "          864,   304, 10200,   403,   408,   385,  2980,   322,   322,   372,\n",
      "         3639,   263,   716,   393,  5717,   278,   630,   411],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901, 12027,  7420,   278,  6964,\n",
      "           310, 10200,  4097,   297,  5132, 29889, 29871,    13,    13,  3575,\n",
      "           673, 29901,  1839, 29905, 29876, 29905, 29876,  3826,   272,  4097,\n",
      "           526,   263, 13988,  5780,   297,  5132,   393,  6511,   366,   304,\n",
      "           788,  4805,  9863,   304,  3168,  7790, 29876, 29905, 29876,  1152,\n",
      "          1342, 29892,   366,   508,   788,   263, 10200,  1061,   304,   263,\n",
      "           740,   393, 12778,   263,  3443,   304,   278,   740, 12608,  7790,\n",
      "         29876, 29905, 29876,   887,   508,   884,   788,   263, 10200,  1061,\n",
      "           304,   263,   740,   393, 14677,   278,   740,  1024,   322,   278,\n",
      "          4128,  4502,   304,   278,   740,  7790, 29876, 29905, 29876,  1763,\n",
      "           671, 10200,  4097, 29892,   366,  1653,   263,   740,   393,  4893,\n",
      "           263,   740,   408,   385,  2980,  7790, 29876, 29905, 29876,  1987,\n",
      "           366,   788,   278, 10200,  1061,   304,   278,   740,  7790, 29876,\n",
      "         29905, 29876,   450, 10200,  1061,   740,  4893,   278,   740,   366,\n",
      "           864,   304, 10200,   403,   408,   385,  2980, 29892,   322,   372,\n",
      "          3639,   263,   740,   393,   338, 10200,   630,   411,  2033]],\n",
      "       device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: Explain the concept of decorators in Python. \\n\\n Your Answer:['\\\\n\\\\n Decorators are a powerful tool in Python that allows you to add extra functionality to functions.\\\\n\\\\n For example, you can add a decorator to a function that adds a parameter to the function signature.\\\\n\\\\n You can also add a decorator to a function that prints the function name and the parameters passed to the function.\\\\n\\\\n To use decorators, you create a function that takes a function as an argument.\\\\n\\\\n Then you add the decorator to the function.\\\\n\\\\n The decorator function takes the function you want to decorate as an argument, and it returns a function that is decorated with']\"\n",
      "input_ids torch.Size([1, 159])\n",
      "attention mask torch.Size([1, 159])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Epoch 110, Average Loss: 12.624978303909302\n",
      "Epoch 120, Average Loss: 11.199859023094177\n",
      "Epoch 130, Average Loss: 10.078182935714722\n",
      "Epoch 140, Average Loss: 9.393063068389893\n",
      "Epoch 150, Average Loss: 8.678565979003906\n",
      "Epoch 160, Average Loss: 7.935209512710571\n",
      "Epoch 170, Average Loss: 7.507023453712463\n",
      "Epoch 180, Average Loss: 7.737560391426086\n",
      "Epoch 190, Average Loss: 7.17184841632843\n",
      "Epoch 200, Average Loss: 6.056088447570801\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 157, 32001])\n",
      "student decoded '#1\\n# \\nlain the to\\n\\n\\n binary\\n\\n\\n\\n\\n\\n Your\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nA search is an search algorithm that div the element in a sorted array. It works the worst-case time complexity of O(log n).\\n\\nThe works by dividing the list space in half, each step until and then the the item is found or the search space is empty small. divide.\\n\\nFor example, if we are searching for the item in a list of numbers, you would start by div the the middle number. If\\nIf the middle is not the middle element, you you have it is be in the half half right half of the list.\\n\\nIf the item is not in the'\n",
      "teacher decoded '\\n\\nA search is a search algorithm that div the element in a sorted array.\\n works a worst-case time complexity of O(log n).\\n\\nThe works by dividing the list space into half, each step until until then until the item is found. the search space is empty small to divide.\\n\\nFor example, if we are searching for the item in a list of , you would start by div the the middle number. If\\nIf the middle is not the middle element, you you know it is be in the half half right half of the list.\\n\\nIf the item is not in the'\n",
      "student argmax tensor([  396, 29896,    13, 29937, 29871,    13,  7420,   278,   304,    13,\n",
      "           13,    13,  7581,    13,    13,    13,    13,    13,    13,  3575,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13, 29909,  2740,   338,   385,  2740,  5687,   393,  1933,   278,\n",
      "         1543,   297,   263, 12705,  1409, 29889,   739,  1736,   278, 17322,\n",
      "        29899,  4878,   931, 13644,   310,   438, 29898,  1188,   302,   467,\n",
      "           13,    13,  1576,  1736,   491,  1933,  4821,   278,  1051,  2913,\n",
      "          297,  4203, 29892,  1269,  4331,  2745,   322,   769,   278,   278,\n",
      "         2944,   338,  1476,   470,   278,  2740,  2913,   338,  4069,  2319,\n",
      "        29889, 16429, 29889,    13,    13,  2831,  1342, 29892,   565,   591,\n",
      "          526, 11975,   363,   278,  2944,   297,   263,  1051,   310,  3694,\n",
      "        29892,   366,   723,  1369,   491,  1933,   278,   278,  7256,  1353,\n",
      "        29889,   960,    13,  3644,   278,  7256,   338,   451,   278,  7256,\n",
      "         1543, 29892,   366,   366,   505,   372,   338,   367,   297,   278,\n",
      "         4203,  4203,  1492,  4203,   310,   278,  1051, 29889,    13,    13,\n",
      "         3644,   278,  2944,   338,   451,   297,   278], device='cuda:0')\n",
      "teacher argmax tensor([   13,    13, 29909,  2740,   338,   263,  2740,  5687,   393,  1933,\n",
      "          278,  1543,   297,   263, 12705,  1409, 29889,    13,  1736,   263,\n",
      "        17322, 29899,  4878,   931, 13644,   310,   438, 29898,  1188,   302,\n",
      "          467,    13,    13,  1576,  1736,   491,  1933,  4821,   278,  1051,\n",
      "         2913,   964,  4203, 29892,  1269,  4331,  2745,  2745,   769,  2745,\n",
      "          278,  2944,   338,  1476, 29889,   278,  2740,  2913,   338,  4069,\n",
      "         2319,   304, 16429, 29889,    13,    13,  2831,  1342, 29892,   565,\n",
      "          591,   526, 11975,   363,   278,  2944,   297,   263,  1051,   310,\n",
      "        29871, 29892,   366,   723,  1369,   491,  1933,   278,   278,  7256,\n",
      "         1353, 29889,   960,    13,  3644,   278,  7256,   338,   451,   278,\n",
      "         7256,  1543, 29892,   366,   366,  1073,   372,   338,   367,   297,\n",
      "          278,  4203,  4203,  1492,  4203,   310,   278,  1051, 29889,    13,\n",
      "           13,  3644,   278,  2944,   338,   451,   297,   278],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901, 12027,  7420,   920,   263,\n",
      "          7581,  2740,  1736, 29889, 29871,    13,    13,  3575,   673, 29901,\n",
      "          1839, 29905, 29876, 29905, 29876, 25196, 11856,   338,   263,  2740,\n",
      "          5687,   393, 14061,   385,  2944,   297,   263, 12705,  1051, 29889,\n",
      "           739,   756,   263, 17322, 29899,  4878,   931, 13644,   310,   438,\n",
      "         29898,  1188, 29876,   467, 29905, 29876, 29905, 29876,  3112,  1736,\n",
      "           491,  1933,  4821,   278,  2740,  2913,   297,  4203,   472,  1269,\n",
      "          4331, 29892,   322, 28769,  2745,   278,  2944,   338,  1476,   470,\n",
      "           278,  2740,  2913,   338,  2086,  2319,   304, 16429,  7790, 29876,\n",
      "         29905, 29876,  2831,  1342, 29892,   565,   366,   526, 11975,   363,\n",
      "           385,  2944,   297,   263,  1051,   310,  3694, 29892,   366,  1033,\n",
      "          1369,   491, 11975,   363,   278,  7256,  1543,  7790, 29876, 29905,\n",
      "         29876,  3644,   278,  2944,   338,   297,   278,  7256,  1543, 29892,\n",
      "           769,   366,  1073,   372,  1818,   367,   297,   278,  2175,   470,\n",
      "          1492,  4203,   310,   278,  1051,  7790, 29876, 29905, 29876,  3644,\n",
      "           278,  2944,   338,   451,   297,   278,  2033]], device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: Explain how a binary search works. \\n\\n Your Answer:['\\\\n\\\\nBinary Search is a search algorithm that finds an item in a sorted list. It has a worst-case time complexity of O(logn).\\\\n\\\\nIt works by dividing the search space in half at each step, and repeating until the item is found or the search space is too small to divide.\\\\n\\\\nFor example, if you are searching for an item in a list of numbers, you could start by searching for the middle element.\\\\n\\\\nIf the item is in the middle element, then you know it must be in the left or right half of the list.\\\\n\\\\nIf the item is not in the']\"\n",
      "input_ids torch.Size([1, 157])\n",
      "attention mask torch.Size([1, 157])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 161, 32001])\n",
      "student decoded '#1\\n# \\n is the difference between a\\n and a a and\\n\\n\\n\\n\\n\\n\\n\\n\\n Python \\n\\n\\n\\n\\n\\n\\n\\n\\nA\\n list is a data structure that Python that is similar to a list, but it is immutable. This means that once a tuple is created, it cannot be changed. Tu\\nA list, a data data structure in Python that allows be changed after it is created.\\n\\n\\n# Hlain the\\n\\n\\nA tuple is a data structure in Python that is similar to a list, but it is immutable. This means that once a tuple is created, it cannot be changed.\\n\\nA list is a mutable data structure in Python that can be changed after it is created.\\n\\n###'\n",
      "teacher decoded '\\n\\n\\nA\\n list is a collection structure that Python that is similar to a list, but it is immutable. This means that once a tuple is created, it cannot be changed. Tu\\nA list, a mutable data structure in Python that can be changed after it is created.\\n\\n\\n# Hlain the\\n\\n\\nA tuple is a data structure in Python that is similar to a list, but it is immutable. This means that once a tuple is created, it cannot be changed.\\n\\nA list is a mutable data structure in Python that can be changed after it is created.\\n\\n###'\n",
      "student argmax tensor([  396, 29896,    13, 29937, 29871,    13,   338,   278,  4328,  1546,\n",
      "          263,    13,   322,   263,   263,   322,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,  5132, 29871,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13, 29909,    13,  1051,   338,\n",
      "          263,   848,  3829,   393,  5132,   393,   338,  2788,   304,   263,\n",
      "         1051, 29892,   541,   372,   338,  5198,  9246, 29889,   910,  2794,\n",
      "          393,  2748,   263, 18761,   338,  2825, 29892,   372,  2609,   367,\n",
      "         3939, 29889, 12603,    13, 29909,  1051, 29892,   263,   848,   848,\n",
      "         3829,   297,  5132,   393,  6511,   367,  3939,  1156,   372,   338,\n",
      "         2825, 29889,    13,    13,    13, 29937,   379,  7420,   278,    13,\n",
      "           13,    13, 29909, 18761,   338,   263,   848,  3829,   297,  5132,\n",
      "          393,   338,  2788,   304,   263,  1051, 29892,   541,   372,   338,\n",
      "         5198,  9246, 29889,   910,  2794,   393,  2748,   263, 18761,   338,\n",
      "         2825, 29892,   372,  2609,   367,  3939, 29889,    13,    13, 29909,\n",
      "         1051,   338,   263, 26691,   848,  3829,   297,  5132,   393,   508,\n",
      "          367,  3939,  1156,   372,   338,  2825, 29889,    13,    13,  2277,\n",
      "        29937], device='cuda:0')\n",
      "teacher argmax tensor([   13,    13,    13, 29909,    13,  1051,   338,   263,  4333,  3829,\n",
      "          393,  5132,   393,   338,  2788,   304,   263,  1051, 29892,   541,\n",
      "          372,   338,  5198,  9246, 29889,   910,  2794,   393,  2748,   263,\n",
      "        18761,   338,  2825, 29892,   372,  2609,   367,  3939, 29889, 12603,\n",
      "           13, 29909,  1051, 29892,   263, 26691,   848,  3829,   297,  5132,\n",
      "          393,   508,   367,  3939,  1156,   372,   338,  2825, 29889,    13,\n",
      "           13,    13, 29937,   379,  7420,   278,    13,    13,    13, 29909,\n",
      "        18761,   338,   263,   848,  3829,   297,  5132,   393,   338,  2788,\n",
      "          304,   263,  1051, 29892,   541,   372,   338,  5198,  9246, 29889,\n",
      "          910,  2794,   393,  2748,   263, 18761,   338,  2825, 29892,   372,\n",
      "         2609,   367,  3939, 29889,    13,    13, 29909,  1051,   338,   263,\n",
      "        26691,   848,  3829,   297,  5132,   393,   508,   367,  3939,  1156,\n",
      "          372,   338,  2825, 29889,    13,    13,  2277, 29937],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901,  1724,   338,   278,  4328,\n",
      "          1546,   263,  1051,   322, 18761,   297,  5132, 29973, 29871,    13,\n",
      "            13,  3575,   673, 29901,  1839, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29909, 18761,   338,   263,   848,  3829,   297,  5132,   393,\n",
      "           338,  2788,   304,   263,  1051, 29892,   541,   372,   338,  5198,\n",
      "          9246, 29889,   910,  2794,   393,  2748,   263, 18761,   338,  2825,\n",
      "         29892,   372,  2609,   367,  3939,  7790, 29876, 29905, 29876, 29909,\n",
      "          1051,   338,   263, 26691,   848,  3829,   297,  5132,   393,   508,\n",
      "           367,  3939,  1156,   372,   338,  2825,  7790, 29876, 29905, 29876,\n",
      "          2277, 29937, 12027,  7420, 29901,   320, 29876, 29905, 29876, 29909,\n",
      "         18761,   338,   263,   848,  3829,   297,  5132,   393,   338,  2788,\n",
      "           304,   263,  1051, 29892,   541,   372,   338,  5198,  9246, 29889,\n",
      "           910,  2794,   393,  2748,   263, 18761,   338,  2825, 29892,   372,\n",
      "          2609,   367,  3939,  7790, 29876, 29905, 29876, 29909,  1051,   338,\n",
      "           263, 26691,   848,  3829,   297,  5132,   393,   508,   367,  3939,\n",
      "          1156,   372,   338,  2825,  7790, 29876, 29905, 29876,  2277, 29937,\n",
      "          2033]], device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: What is the difference between a list and tuple in Python? \\n\\n Your Answer:['\\\\n\\\\n\\\\nA tuple is a data structure in Python that is similar to a list, but it is immutable. This means that once a tuple is created, it cannot be changed.\\\\n\\\\nA list is a mutable data structure in Python that can be changed after it is created.\\\\n\\\\n### Explain: \\\\n\\\\nA tuple is a data structure in Python that is similar to a list, but it is immutable. This means that once a tuple is created, it cannot be changed.\\\\n\\\\nA list is a mutable data structure in Python that can be changed after it is created.\\\\n\\\\n###']\"\n",
      "input_ids torch.Size([1, 161])\n",
      "attention mask torch.Size([1, 161])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 153, 32001])\n",
      "student decoded '#1\\n# \\n to the collection work in\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n##\\n\\narbage collection is Python is a process memory of freeing up memory that is no longer in used by a program. This is done by theifying and removinging up unused memory, objectsreferenced objects, and other memory that are no longer in use.\\n\\nG garbage of garbage collection in Python is done automatic because it is done explicitly triggered by the programmer. Instead, it is done by the Python runtime system it memory detects that there is un longer any reference to an object. variable. This is the system to free up memory memory that by the object or variable, which it available for'\n",
      "teacher decoded '\\n\\n\\n##\\nGarbage collection is Python is a process memory of freeing up memory that is no longer in used by a program. This is done by theifying and removinging up unused memory, objectsreferenced objects, and other memory that are no longer in use.\\n\\nThe garbage of garbage collection in Python is managed \" because it is done explicitly triggered by the programmer. Instead, it is done by the Python runtime environment it memory determs that there is un longer any reference to an object. variable.\\n is the system to free up memory memory that by the object or variable, which it available for'\n",
      "student argmax tensor([  396, 29896,    13, 29937, 29871,    13,   304,   278,  4333,   664,\n",
      "          297,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,  2277,    13,\n",
      "           13,   279, 17807,  4333,   338,  5132,   338,   263,  1889,  3370,\n",
      "          310,  3889,   292,   701,  3370,   393,   338,   694,  5520,   297,\n",
      "         1304,   491,   263,  1824, 29889,   910,   338,  2309,   491,   278,\n",
      "         9215,   322, 11077,   292,   701,   443,  3880,  3370, 29892,  3618,\n",
      "        20275,  9223,  3618, 29892,   322,   916,  3370,   393,   526,   694,\n",
      "         5520,   297,   671, 29889,    13,    13, 29954, 25861,   310, 25861,\n",
      "         4333,   297,  5132,   338,  2309, 18428,  1363,   372,   338,  2309,\n",
      "         9479, 19799,   491,   278, 27922, 29889,  8669, 29892,   372,   338,\n",
      "         2309,   491,   278,  5132, 10073,  1788,   372,  3370,  6459, 29879,\n",
      "          393,   727,   338,   443,  5520,   738,  3407,   304,   385,  1203,\n",
      "        29889,  2286, 29889,   910,   338,   278,  1788,   304,  3889,   701,\n",
      "         3370,  3370,   393,   491,   278,  1203,   470,  2286, 29892,   607,\n",
      "          372,  3625,   363], device='cuda:0')\n",
      "teacher argmax tensor([   13,    13,    13,  2277,    13, 29954,   279, 17807,  4333,   338,\n",
      "         5132,   338,   263,  1889,  3370,   310,  3889,   292,   701,  3370,\n",
      "          393,   338,   694,  5520,   297,  1304,   491,   263,  1824, 29889,\n",
      "          910,   338,  2309,   491,   278,  9215,   322, 11077,   292,   701,\n",
      "          443,  3880,  3370, 29892,  3618, 20275,  9223,  3618, 29892,   322,\n",
      "          916,  3370,   393,   526,   694,  5520,   297,   671, 29889,    13,\n",
      "           13,  1576, 25861,   310, 25861,  4333,   297,  5132,   338,  8745,\n",
      "          376,  1363,   372,   338,  2309,  9479, 19799,   491,   278, 27922,\n",
      "        29889,  8669, 29892,   372,   338,  2309,   491,   278,  5132, 10073,\n",
      "         5177,   372,  3370,  3683, 29879,   393,   727,   338,   443,  5520,\n",
      "          738,  3407,   304,   385,  1203, 29889,  2286, 29889,    13,   338,\n",
      "          278,  1788,   304,  3889,   701,  3370,  3370,   393,   491,   278,\n",
      "         1203,   470,  2286, 29892,   607,   372,  3625,   363],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901,  1128,   947, 25861,  4333,\n",
      "           664,   297,  5132, 29973, 29871,    13,    13,  3575,   673, 29901,\n",
      "          1839, 29905, 29876, 29905, 29876, 28956, 29905, 29876, 29954,   279,\n",
      "         17807,  4333,   297,  5132,   338,   278, 18428,  1889,   310,  3889,\n",
      "           292,   701,  3370,   393,   338,   694,  5520,  1641,  1304,   491,\n",
      "           263,  1824, 29889,   910,   338,  2309,   491,  2893,  9215,   322,\n",
      "          3889,   292,   701,   443,  3880,  3651, 29892,   443, 20275,  9223,\n",
      "          3618, 29892,   322,   916,  3618,   393,   526,   694,  5520,   297,\n",
      "           671,  7790, 29876, 29905, 29876,  1576,  1889,   310, 25861,  4333,\n",
      "           297,  5132,   338,  2000, 18428,  1363,   372,   338,   451,  7522,\n",
      "         19799,   491,   278, 27922, 29889,  8669, 29892,   372,   338, 19799,\n",
      "           491,   278,  5132, 10073,   746,   278,  1788,  6459, 29879,   393,\n",
      "           727,   338,   694,  5520,   738,  3407,   304,   385,  1203,   470,\n",
      "          2286, 29889,   910,  6511,   278,  1824,   304,  3889,   701,   278,\n",
      "          3370,  1304,   491,   278,  1203,   470,  2286, 29892,  3907,   372,\n",
      "          3625,   363,  2033]], device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: How does garbage collection work in Python? \\n\\n Your Answer:['\\\\n\\\\n```\\\\nGarbage collection in Python is the automatic process of freeing up memory that is no longer being used by a program. This is done by identifying and freeing up unused variables, unreferenced objects, and other objects that are no longer in use.\\\\n\\\\nThe process of garbage collection in Python is called automatic because it is not manually triggered by the programmer. Instead, it is triggered by the Python runtime when the system detects that there is no longer any reference to an object or variable. This allows the program to free up the memory used by the object or variable, making it available for']\"\n",
      "input_ids torch.Size([1, 153])\n",
      "attention mask torch.Size([1, 153])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 159, 32001])\n",
      "student decoded '#1\\n# \\nlain the following of\\nator in Python in\\n\\n\\n\\n\\n Python Python\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n##orators are a way feature in Python that allow you to add functionality functionality to functions without \\n Dec example, you can use a decorator to a function that prints a parameter to the function..\\n\\n``` can also add a decorator to a function that adds the function name and the number to to the function.\\n\\n Dec add decorators, you first a decor that takes a function as an argument and\\n\\n You, add a decorator to the function using\\n\\n The decorator function takes the function signature want to decorate as an argument and and it returns a function that takes theated with'\n",
      "teacher decoded \"\\n\\n##orators are a way tool in Python that allow you to add functionality functionality to functions. They\\n Dec example, you can use a loggingator to a function that prints a parameter to the function..\\n\\n This can also add a decorator to a function that adds the function' and the number to to the function.\\n\\n Dec add decorators, you first a function that takes a function as an argument.\\n\\n You, add a decorator to the function.\\n\\n The decorator is takes the function as want to decorate as an argument and and it returns a new that calls theated with\"\n",
      "student argmax tensor([  396, 29896,    13, 29937, 29871,    13,  7420,   278,  1494,   310,\n",
      "           13,  1061,   297,  5132,   297,    13,    13,    13,    13,    13,\n",
      "         5132,  5132,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,  2277,   272,  4097,   526,   263,   982,  4682,\n",
      "          297,  5132,   393,  2758,   366,   304,   788,  9863,  9863,   304,\n",
      "         3168,  1728, 29871,    13,  3826,  1342, 29892,   366,   508,   671,\n",
      "          263, 10200,  1061,   304,   263,   740,   393, 14677,   263,  3443,\n",
      "          304,   278,   740, 29889, 29889,    13,    13, 28956,   508,   884,\n",
      "          788,   263, 10200,  1061,   304,   263,   740,   393, 12778,   278,\n",
      "          740,  1024,   322,   278,  1353,   304,   304,   278,   740, 29889,\n",
      "           13,    13,  3826,   788, 10200,  4097, 29892,   366,   937,   263,\n",
      "        10200,   393,  4893,   263,   740,   408,   385,  2980,   322,    13,\n",
      "           13,   887, 29892,   788,   263, 10200,  1061,   304,   278,   740,\n",
      "          773,    13,    13,   450, 10200,  1061,   740,  4893,   278,   740,\n",
      "        12608,   864,   304, 10200,   403,   408,   385,  2980,   322,   322,\n",
      "          372,  3639,   263,   740,   393,  4893,   278,   630,   411],\n",
      "       device='cuda:0')\n",
      "teacher argmax tensor([   13,    13,  2277,   272,  4097,   526,   263,   982,  5780,   297,\n",
      "         5132,   393,  2758,   366,   304,   788,  9863,  9863,   304,  3168,\n",
      "        29889,  2688,    13,  3826,  1342, 29892,   366,   508,   671,   263,\n",
      "        12183,  1061,   304,   263,   740,   393, 14677,   263,  3443,   304,\n",
      "          278,   740, 29889, 29889,    13,    13,   910,   508,   884,   788,\n",
      "          263, 10200,  1061,   304,   263,   740,   393, 12778,   278,   740,\n",
      "        29915,   322,   278,  1353,   304,   304,   278,   740, 29889,    13,\n",
      "           13,  3826,   788, 10200,  4097, 29892,   366,   937,   263,   740,\n",
      "          393,  4893,   263,   740,   408,   385,  2980, 29889,    13,    13,\n",
      "          887, 29892,   788,   263, 10200,  1061,   304,   278,   740, 29889,\n",
      "           13,    13,   450, 10200,  1061,   338,  4893,   278,   740,   408,\n",
      "          864,   304, 10200,   403,   408,   385,  2980,   322,   322,   372,\n",
      "         3639,   263,   716,   393,  5717,   278,   630,   411],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901, 12027,  7420,   278,  6964,\n",
      "           310, 10200,  4097,   297,  5132, 29889, 29871,    13,    13,  3575,\n",
      "           673, 29901,  1839, 29905, 29876, 29905, 29876,  3826,   272,  4097,\n",
      "           526,   263, 13988,  5780,   297,  5132,   393,  6511,   366,   304,\n",
      "           788,  4805,  9863,   304,  3168,  7790, 29876, 29905, 29876,  1152,\n",
      "          1342, 29892,   366,   508,   788,   263, 10200,  1061,   304,   263,\n",
      "           740,   393, 12778,   263,  3443,   304,   278,   740, 12608,  7790,\n",
      "         29876, 29905, 29876,   887,   508,   884,   788,   263, 10200,  1061,\n",
      "           304,   263,   740,   393, 14677,   278,   740,  1024,   322,   278,\n",
      "          4128,  4502,   304,   278,   740,  7790, 29876, 29905, 29876,  1763,\n",
      "           671, 10200,  4097, 29892,   366,  1653,   263,   740,   393,  4893,\n",
      "           263,   740,   408,   385,  2980,  7790, 29876, 29905, 29876,  1987,\n",
      "           366,   788,   278, 10200,  1061,   304,   278,   740,  7790, 29876,\n",
      "         29905, 29876,   450, 10200,  1061,   740,  4893,   278,   740,   366,\n",
      "           864,   304, 10200,   403,   408,   385,  2980, 29892,   322,   372,\n",
      "          3639,   263,   740,   393,   338, 10200,   630,   411,  2033]],\n",
      "       device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: Explain the concept of decorators in Python. \\n\\n Your Answer:['\\\\n\\\\n Decorators are a powerful tool in Python that allows you to add extra functionality to functions.\\\\n\\\\n For example, you can add a decorator to a function that adds a parameter to the function signature.\\\\n\\\\n You can also add a decorator to a function that prints the function name and the parameters passed to the function.\\\\n\\\\n To use decorators, you create a function that takes a function as an argument.\\\\n\\\\n Then you add the decorator to the function.\\\\n\\\\n The decorator function takes the function you want to decorate as an argument, and it returns a function that is decorated with']\"\n",
      "input_ids torch.Size([1, 159])\n",
      "attention mask torch.Size([1, 159])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Epoch 210, Average Loss: 6.223436236381531\n",
      "Epoch 220, Average Loss: 5.720994710922241\n",
      "Epoch 230, Average Loss: 5.382120132446289\n",
      "Epoch 240, Average Loss: 5.3387250900268555\n",
      "Epoch 250, Average Loss: 5.410753905773163\n",
      "Epoch 260, Average Loss: 4.808719754219055\n",
      "Epoch 270, Average Loss: 4.825849652290344\n",
      "Epoch 280, Average Loss: 5.036660552024841\n",
      "Epoch 290, Average Loss: 4.100986957550049\n",
      "Epoch 300, Average Loss: 3.99701988697052\n"
     ]
    }
   ],
   "source": [
    "DEBUG=True\n",
    "def train_step(batch, model, tokenizer, optimizer):\n",
    "    global DEBUG\n",
    "    # Tokenize the combined student text (prompt + response)\n",
    "    inputs = tokenizer(\n",
    "        batch['combined_student'], \n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True\n",
    "    ).to(device)\n",
    "    \n",
    "    # Forward pass through student model\n",
    "    student_outputs = model(\n",
    "        input_ids=inputs.input_ids,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        labels=inputs.input_ids,  # For calculating loss\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "    \n",
    "    # Get teacher logits from dataset\n",
    "    #note that it is a list of tensors, so we need to stack them\n",
    "    #teacher_logits =  torch.cat(batch['response_logits'], dim=1).to(device)\n",
    "    teacher_logits =  batch['response_logits'] #.to(device)\n",
    "\n",
    "    \n",
    "    if DEBUG:\n",
    "        print(\"teacher_logits\", teacher_logits.shape)\n",
    "        print(\"student_outputs\", student_outputs.logits.shape)\n",
    "        #also print the decode, we need to apply argmax to get the token, and then decode\n",
    "        #using repr() to show escaped characters\n",
    "        print(\"student decoded\", repr(tokenizer.decode(torch.argmax(student_outputs.logits, dim=-1)[0], skip_special_tokens=False)))\n",
    "        print(\"teacher decoded\", repr(tokenizer.decode(torch.argmax(teacher_logits, dim=-1)[0], skip_special_tokens=False)))\n",
    "        #print the argmax too:\n",
    "        print(\"student argmax\", torch.argmax(student_outputs.logits, dim=-1)[0])\n",
    "        print(\"teacher argmax\", torch.argmax(teacher_logits, dim=-1)[0])\n",
    "        #also decode the input_ids to see if they are correct\n",
    "        print(\"input_ids\", inputs.input_ids)\n",
    "        print(\"input_ids decoded\", repr(tokenizer.decode(inputs.input_ids[0], skip_special_tokens=False)))\n",
    "        print(\"input_ids\", inputs.input_ids.shape)\n",
    "        #print also the attention mask\n",
    "        print(\"attention mask\", inputs.attention_mask.shape)\n",
    "        print(\"attention mask\", inputs.attention_mask)\n",
    "    \n",
    "    # Calculate KL divergence loss between student and teacher logits\n",
    "    # Only consider the logits for generated tokens (not prompt)\n",
    "    #print shapes, to debug:\n",
    "    kl_loss = F.kl_div(\n",
    "        F.log_softmax(student_outputs.logits[:, -teacher_logits.size(1):], dim=-1),\n",
    "        F.softmax(teacher_logits, dim=-1),\n",
    "        reduction='batchmean'\n",
    "    )\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    kl_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    return kl_loss.item()\n",
    "\n",
    "# Set up optimizer\n",
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 300\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in examples:\n",
    "        loss = train_step(batch, student_model, teacher_tokenizer, optimizer)\n",
    "        total_loss += loss\n",
    "    DEBUG=False\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Average Loss: {total_loss/len(examples)}\")\n",
    "    if epoch % 100 == 4:\n",
    "        DEBUG=True\n",
    "        #print(f\"Epoch {epoch+1}, Average Loss: {total_loss/len(examples)}\")\n",
    "        #print(\"Saving model\")\n",
    "        #student_model.save_adapter_fusion(\"student_model\")\n",
    "        #print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
      "Always format code properly and explain technical concepts clearly.\n",
      "torch.Size([1, 11, 32001]) torch.Size([1, 11]) torch.Size([1, 256]) torch.Size([1, 267]) 11\n",
      "Task: Explain how a binary search works.\n",
      "Answer: ['\\n \\n.\\n\\n\\n\\n\\n\\n']\n",
      "=====================================\n",
      "torch.Size([1, 14, 32001]) torch.Size([1, 14]) torch.Size([1, 256]) torch.Size([1, 270]) 14\n",
      "Task: What is the difference between a list and tuple in Python?\n",
      "Answer: ['Python List Python\\n\\n A\\n\\n Python\\n\\n The\\n']\n",
      "=====================================\n",
      "torch.Size([1, 14, 32001]) torch.Size([1, 14]) torch.Size([1, 256]) torch.Size([1, 270]) 14\n",
      "Task: How does garbage collection work in Python?\n",
      "Answer: ['\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n",
      "=====================================\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Task: Explain the concept of decorators in Python.\n",
      "Answer: ['Python  Python\\n\\n##\\n Python\\n\\n Python\\n\\n Python\\n\\n Python\\n Python\\n Python Python\\n Python  Python  Python   Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python  Python ']\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "#now we test for the tasks... TIENE PINTA DE QIE SE ESTA DESTRUYENDO EL TEACHER MODEL TAMBIEN!!!!\n",
    "print(SYSTEM_PROMPT)\n",
    "for task in tasks:\n",
    "    full_prompt = f\" {SYSTEM_PROMPT}\\n\\nYour Task: {task} \\n\\n Your Answer:\"\n",
    "    student_prompt = f\" \\n\\nTask: {task} \\n\\n Your Answer:\"\n",
    "    decoded,logits=generate_response(teacher_model, teacher_tokenizer, [full_prompt])\n",
    "    print (f\"Task: {task}\")\n",
    "    print (f\"Answer: {decoded}\")\n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
      "Always format code properly and explain technical concepts clearly.\n",
      "torch.Size([1, 24, 32001]) torch.Size([1, 24]) torch.Size([1, 256]) torch.Size([1, 280]) 24\n",
      "Task: Explain how a binary search works.\n",
      "Answer: ['\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n",
      "=====================================\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Task: What is the difference between a list and tuple in Python?\n",
      "Answer: ['\\n Python \\n\\n Python\\n\\n\\n Python\\n\\n\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n The\\n']\n",
      "=====================================\n",
      "torch.Size([1, 12, 32001]) torch.Size([1, 12]) torch.Size([1, 256]) torch.Size([1, 268]) 12\n",
      "Task: How does garbage collection work in Python?\n",
      "Answer: ['\\n\\n\\n Python\\n Gar\\n\\n Gar\\n\\n']\n",
      "=====================================\n",
      "torch.Size([1, 10, 32001]) torch.Size([1, 10]) torch.Size([1, 256]) torch.Size([1, 266]) 10\n",
      "Task: Explain the concept of decorators in Python.\n",
      "Answer: ['Python\\n Python\\n\\n\\n\\n\\n\\n']\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "#now we test for the tasks\n",
    "print(SYSTEM_PROMPT)\n",
    "for task in tasks:\n",
    "    full_prompt = f\"{SYSTEM_PROMPT}\\n\\nYour Task: {task} \\n\\n Your Answer:\"\n",
    "    student_prompt = f\" \\n\\nTask: {task} \\n\\n Your Answer:\"\n",
    "    decoded,logits=generate_response(student_model, teacher_tokenizer, [full_prompt])\n",
    "    print (f\"Task: {task}\")\n",
    "    print (f\"Answer: {decoded}\")\n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Task: Explain how a binary search works.\n",
      "Answer: ['Your\\n solution\\n Your\\n In\\n Binary\\n Binary Binary\\n search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search']\n",
      "=====================================\n",
      "torch.Size([1, 70, 32001]) torch.Size([1, 70]) torch.Size([1, 256]) torch.Size([1, 326]) 70\n",
      "Task: What is the difference between a list and tuple in Python?\n",
      "Answer: ['\\n\\n Python\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n",
      "=====================================\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Task: How does garbage collection work in Python?\n",
      "Answer: ['\\n The\\n Gar\\n c\\n garbage\\n\\n collection\\n\\n collection is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is']\n",
      "=====================================\n",
      "torch.Size([1, 73, 32001]) torch.Size([1, 73]) torch.Size([1, 256]) torch.Size([1, 329]) 73\n",
      "Task: Explain the concept of decorators in Python.\n",
      "Answer: ['\\n\\n A\\n\\n Python\\n\\n The\\n\\n Dec\\n\\n <\\n\\n A\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "#now we test for the tasks\n",
    "for task in tasks:\n",
    "    full_prompt = f\"{SYSTEM_PROMPT}\\n\\nYour Task: {task} \\n\\n Your Answer:\"\n",
    "    student_prompt = f\" \\n\\nTask: {task} \\n\\n Your Answer:\"\n",
    "    decoded,logits=generate_response(student_model, teacher_tokenizer, [student_prompt])\n",
    "    print (f\"Task: {task}\")\n",
    "    print (f\"Answer: {decoded}\")\n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

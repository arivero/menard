{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kampal/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]\n",
      "We've detected an older driver with an RTX 4000 series GPU. These drivers have issues with P2P. This can affect the multi-gpu inference when using accelerate device_map.Please make sure to update your driver to the latest version which resolves this.\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "import random\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Add device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize teacher model normally in full precision\n",
    "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "teacher_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "teacher_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\"  # This will handle CUDA allocation efficiently\n",
    ")\n",
    "\n",
    "# Set padding token for the tokenizer\n",
    "if teacher_tokenizer.pad_token is None:\n",
    "    teacher_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    # Resize token embeddings for the model to account for the new token\n",
    "    teacher_model.resize_token_embeddings(len(teacher_tokenizer))\n",
    "\n",
    "# Configure LoRA to only train the adapters\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    modules_to_save=None  # Don't save any full modules\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as a checksum all the layers of teacher\n",
    "import hashlib\n",
    "def compute_model_checksums(model):\n",
    "    checksums = {}\n",
    "    for name, param in model.state_dict().items():\n",
    "        param_data = param.detach().cpu().numpy()\n",
    "        param_bytes = param_data.tobytes()\n",
    "        checksum = hashlib.md5(param_bytes).hexdigest()\n",
    "        checksums[name] = checksum\n",
    "    return checksums\n",
    "\n",
    "\n",
    "# 1. Compute and store initial checksums\n",
    "initial_checksums = compute_model_checksums(teacher_model)\n",
    "# 3. Compute checksums again after fine-tuning\n",
    "fine_tuned_checksums = compute_model_checksums(teacher_model)\n",
    "\n",
    "# 4. Compare initial and fine-tuned checksums\n",
    "def compare_checksums(initial, fine_tuned):\n",
    "    differences = {}\n",
    "    for layer_name in initial.keys():\n",
    "        if initial[layer_name] != fine_tuned[layer_name]:\n",
    "            differences[layer_name] = {\n",
    "                \"initial\": initial[layer_name],\n",
    "                \"fine_tuned\": fine_tuned[layer_name],\n",
    "            }\n",
    "    return differences\n",
    "\n",
    "\n",
    "checksum_differences = compare_checksums(initial_checksums, fine_tuned_checksums)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No changes detected in the model's layers.\n"
     ]
    }
   ],
   "source": [
    "# Display differences\n",
    "if checksum_differences:\n",
    "    print(\"\\nLayers with changed checksums:\")\n",
    "    for layer, diff in checksum_differences.items():\n",
    "        print(f\"{layer}:\")\n",
    "        print(f\"  Initial: {diff['initial']}\")\n",
    "        print(f\"  Fine-tuned: {diff['fine_tuned']}\")\n",
    "else:\n",
    "    print(\"\\nNo changes detected in the model's layers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, tokenizer, prompt, max_length=512):\n",
    "    inputs = tokenizer(\n",
    "        prompt, \n",
    "        padding_side=\"left\",\n",
    "        return_tensors=\"pt\", \n",
    "        padding='max_length',\n",
    "        truncation=True, \n",
    "        max_length=max_length // 2  # Reduce input length to leave room for generation\n",
    "    ).to(device)  # Move inputs to GPU\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs.input_ids,\n",
    "            max_new_tokens=max_length // 4,  # Allow generation of new tokens up to half max_length\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            #output_scores=True,\n",
    "            output_logits=True,\n",
    "            return_dict_in_generate=True\n",
    "        )\n",
    "    # Convert tuple of tensors into a single tensor\n",
    "    logits_tensor = torch.cat([t.unsqueeze(1) for t in outputs.logits], dim=1)\n",
    "    new_logits = logits_tensor  # Replace tuple with tensor. This is the tensor of logits for the new tokens, shape: (batch_size, num_new_tokens, vocab_size)\n",
    "    new_tokens = outputs.sequences[:, inputs.input_ids.shape[-1]:]\n",
    "    old_tokens = inputs.input_ids\n",
    "    #print shapes\n",
    "    print(new_logits.shape, new_tokens.shape, old_tokens.shape, outputs.sequences.shape, len(outputs.logits))\n",
    "    #return tokenizer.decode(new_tokens[0], skip_special_tokens=True)\n",
    "    #print (outputs)\n",
    "    decoded=[tokenizer.decode(seq, skip_special_tokens=True) for seq in new_tokens]\n",
    "    return decoded, new_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return full text = False is an option in pipeline but not in generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 128, 32001]) torch.Size([2, 128]) torch.Size([2, 256]) torch.Size([2, 384]) 128\n"
     ]
    }
   ],
   "source": [
    "decoded,logits=generate_response(teacher_model, teacher_tokenizer, [\"What is the capital of France?\", \"Cual es la capital de Francia?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nThe capital of France is Paris.\\nWhat is the capital of the country of France?\\nThe capital of France is Paris.\\nWhat is the capital of France in French?\\nThe capital of France is Paris. In French it is \"Paris\".\\nWhat is the capital of France called?\\nThe capital of France is Paris. The capital of France is Paris. The capital of France is Paris. The capital of France is Paris. The capital of France is Paris. The capital of France is Paris. The capital of France is Paris. The capital of France is Paris. The capital of France is Paris. The capital',\n",
       " '\\nLa capital de Francia es la ciudad de París.\\nWhat is the capital of France?\\nThe capital of France is the city of Paris.\\nWhat is the capital of France\\nWhat is the capital of France\\nWhat is the capital of France?\\nWhat is the capital of France?\\nWhat is the capital of France\\nWhat is the capital of France?\\nWhat is the capital of France?\\nWhat is the capital of France?\\nWhat is the capital of France?\\nWhat is the capital of France?\\nWhat is the capital of France?\\nWhat is the capital of France?\\nWhat is the capital']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create student model using LoRA - this only creates adapter weights\n",
    "student_model = get_peft_model(teacher_model, lora_config)\n",
    "\n",
    "#student_model=teacher_model\n",
    "#student_model.add_adapter(lora_config)\n",
    "\n",
    "\n",
    "\n",
    "#teacher_model=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['default']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.active_adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters for LoRA adapters:\n",
      "trainable params: 4,194,304 || all params: 6,742,618,112 || trainable%: 0.0622\n"
     ]
    }
   ],
   "source": [
    "# Print only the trainable parameters (should be much smaller)\n",
    "print(\"Trainable parameters for LoRA adapters:\")\n",
    "student_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 0 || all params: 6,742,618,112 || trainable%: 0.0000\n"
     ]
    }
   ],
   "source": [
    "with student_model.disable_adapter():\n",
    "    student_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,194,304 || all params: 6,742,618,112 || trainable%: 0.0622\n"
     ]
    }
   ],
   "source": [
    "student_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with student_model.disable_adapter():\n",
    "   student_checksums=compute_model_checksums(student_model.base_model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer model.layers.14.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.14.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.29.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.18.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.29.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.17.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.30.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.3.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.2.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.24.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.24.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.21.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.3.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.15.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.8.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.24.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.7.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.24.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.1.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.16.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.2.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.11.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.26.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.28.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.7.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.1.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.7.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.17.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.25.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.14.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.11.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.14.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.11.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.0.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.25.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.23.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.0.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.1.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.6.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.15.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.10.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.27.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.22.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.23.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.19.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.13.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.1.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.19.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.6.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.26.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.22.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.7.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.5.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.9.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.8.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.15.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.28.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.20.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.25.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.26.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.28.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.31.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.10.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.4.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.17.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.3.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.12.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.8.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.9.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.2.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.4.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.16.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.5.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.21.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.6.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.16.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.28.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.6.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.3.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.15.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.12.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.21.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.25.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.5.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.22.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.16.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.8.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.2.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.30.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.17.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.13.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.11.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.5.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.23.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.30.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.13.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.5.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.6.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.20.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.4.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.12.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.23.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.9.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.21.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.22.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.27.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.11.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.31.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.25.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.9.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.29.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.0.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.10.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.11.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.21.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.4.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.19.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.5.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.20.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.29.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.18.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.8.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.12.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.16.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.9.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.0.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.1.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.12.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.28.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.30.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.4.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.25.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.0.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.15.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.14.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.22.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.10.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.2.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.18.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.31.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.21.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.3.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.19.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.22.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.2.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.6.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.26.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.18.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.10.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.24.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.9.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.26.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.17.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.31.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.14.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.4.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.1.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.31.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.27.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.19.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.30.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.29.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.30.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.17.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.26.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.24.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.27.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.27.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.3.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.15.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.0.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.19.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.18.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.13.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.28.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.20.self_attn.v_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.13.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.7.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.20.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.13.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.23.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.18.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.10.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.20.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.12.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.29.self_attn.q_proj.base_layer.weight trainable: False\n",
      "Layer model.layers.7.self_attn.v_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.16.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.27.self_attn.q_proj.lora_A.default.weight trainable: True\n",
      "Layer model.layers.23.self_attn.q_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.8.self_attn.v_proj.lora_B.default.weight trainable: True\n",
      "Layer model.layers.31.self_attn.q_proj.lora_A.default.weight trainable: True\n"
     ]
    }
   ],
   "source": [
    "#aun haciendo el disable, el modelo tiene los pesos descompuestos\n",
    "for key in (set(student_checksums.keys())-set(initial_checksums.keys())):\n",
    "    #check if key layer is trainable:\n",
    "    # Get the layer from the model\n",
    "    layer = student_model.base_model.model\n",
    "    for part in key.split('.'):\n",
    "        if hasattr(layer, part):\n",
    "            layer = getattr(layer, part)\n",
    "        else:\n",
    "            print(f\"Layer {key} not found\")\n",
    "            break\n",
    "\n",
    "    # Check if layer is trainable\n",
    "    if hasattr(layer, 'requires_grad'):\n",
    "        print(f\"Layer {key} trainable: {layer.requires_grad}\")\n",
    "    else:\n",
    "        print(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.6.self_attn.q_proj.weight\n",
      "model.layers.0.self_attn.v_proj.weight\n",
      "model.layers.5.self_attn.q_proj.weight\n",
      "model.layers.6.self_attn.v_proj.weight\n",
      "model.layers.9.self_attn.v_proj.weight\n",
      "model.layers.19.self_attn.v_proj.weight\n",
      "model.layers.15.self_attn.q_proj.weight\n",
      "model.layers.26.self_attn.v_proj.weight\n",
      "model.layers.18.self_attn.q_proj.weight\n",
      "model.layers.4.self_attn.v_proj.weight\n",
      "model.layers.14.self_attn.v_proj.weight\n",
      "model.layers.5.self_attn.v_proj.weight\n",
      "model.layers.13.self_attn.q_proj.weight\n",
      "model.layers.7.self_attn.v_proj.weight\n",
      "model.layers.2.self_attn.q_proj.weight\n",
      "model.layers.2.self_attn.v_proj.weight\n",
      "model.layers.20.self_attn.q_proj.weight\n",
      "model.layers.15.self_attn.v_proj.weight\n",
      "model.layers.13.self_attn.v_proj.weight\n",
      "model.layers.11.self_attn.v_proj.weight\n",
      "model.layers.8.self_attn.v_proj.weight\n",
      "model.layers.26.self_attn.q_proj.weight\n",
      "model.layers.10.self_attn.q_proj.weight\n",
      "model.layers.29.self_attn.q_proj.weight\n",
      "model.layers.28.self_attn.q_proj.weight\n",
      "model.layers.17.self_attn.q_proj.weight\n",
      "model.layers.9.self_attn.q_proj.weight\n",
      "model.layers.12.self_attn.q_proj.weight\n",
      "model.layers.22.self_attn.q_proj.weight\n",
      "model.layers.4.self_attn.q_proj.weight\n",
      "model.layers.7.self_attn.q_proj.weight\n",
      "model.layers.3.self_attn.v_proj.weight\n",
      "model.layers.27.self_attn.v_proj.weight\n",
      "model.layers.19.self_attn.q_proj.weight\n",
      "model.layers.3.self_attn.q_proj.weight\n",
      "model.layers.28.self_attn.v_proj.weight\n",
      "model.layers.30.self_attn.q_proj.weight\n",
      "model.layers.25.self_attn.v_proj.weight\n",
      "model.layers.21.self_attn.q_proj.weight\n",
      "model.layers.10.self_attn.v_proj.weight\n",
      "model.layers.24.self_attn.v_proj.weight\n",
      "model.layers.14.self_attn.q_proj.weight\n",
      "model.layers.1.self_attn.q_proj.weight\n",
      "model.layers.8.self_attn.q_proj.weight\n",
      "model.layers.23.self_attn.v_proj.weight\n",
      "model.layers.29.self_attn.v_proj.weight\n",
      "model.layers.18.self_attn.v_proj.weight\n",
      "model.layers.22.self_attn.v_proj.weight\n",
      "model.layers.16.self_attn.v_proj.weight\n",
      "model.layers.11.self_attn.q_proj.weight\n",
      "model.layers.23.self_attn.q_proj.weight\n",
      "model.layers.31.self_attn.q_proj.weight\n",
      "model.layers.21.self_attn.v_proj.weight\n",
      "model.layers.27.self_attn.q_proj.weight\n",
      "model.layers.17.self_attn.v_proj.weight\n",
      "model.layers.24.self_attn.q_proj.weight\n",
      "model.layers.0.self_attn.q_proj.weight\n",
      "model.layers.30.self_attn.v_proj.weight\n",
      "model.layers.1.self_attn.v_proj.weight\n",
      "model.layers.25.self_attn.q_proj.weight\n",
      "model.layers.31.self_attn.v_proj.weight\n",
      "model.layers.20.self_attn.v_proj.weight\n",
      "model.layers.12.self_attn.v_proj.weight\n",
      "model.layers.16.self_attn.q_proj.weight\n"
     ]
    }
   ],
   "source": [
    "for key in (set(initial_checksums.keys())-set(student_checksums.keys())):\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Paris\\nWhat is the capital of India?\\nAnswer: New Delhi\\nWhat is the capital of the United States?\\nAnswer: Washington, DC\\nWhat is the capital of Mexico?\\nAnswer: Mexico City\\nWhat is the capital of Canada?\\nAnswer: Ottawa\\nWhat is the capital of Brazil?\\nAnswer: Brasilia\\nWhat is the capital of Japan?\\nAnswer: Tokyo\\nWhat is the capital of Australia?\\nAnswer: Canberra\\nWhat is the capital of China?\\nAnswer: Beijing\\nWhat is the capital of Russia?\\nAnswer: Moscow\\nWhat is the capital of'],\n",
       " tensor([[[-4.7355, -3.4162, 11.0670,  ..., -4.2172, -0.6887,  1.2191],\n",
       "          [ 1.7003,  2.7376, 15.6574,  ...,  0.0611, -0.3284,  2.7565],\n",
       "          [-9.7093, -8.5697,  2.1901,  ..., -7.9747, -4.8540, -4.1084],\n",
       "          ...,\n",
       "          [-3.1797, -1.2692,  8.2771,  ..., -1.7841, -1.3454,  1.9069],\n",
       "          [-6.2309, -5.7187,  6.0449,  ..., -3.3022, -2.2102, -0.0846],\n",
       "          [-4.4438, -0.7359, 10.1711,  ..., -3.3048, -1.5421,  1.3707]]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(student_model, teacher_tokenizer, \"What is the capital of France?\\n Answer:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "(['Paris\\nQ: What is the capital of Italy?\\nA: Rome\\nQ: What is the capital of Canada?\\nA: Ottawa\\nQ: What is the capital of Japan?\\nA: Tokyo\\nQ: What is the capital of Australia?\\nA: Canberra\\nQ: What is the capital of Switzerland?\\nA: Bern\\nQ: What is the capital of Germany?\\nA: Berlin\\nQ: What is the capital of the Netherlands?\\nA: Amsterdam\\nQ: What is the capital of Russia?\\nA: Moscow\\nQ: What is the capital of Denmark?'], tensor([[[-4.7355, -3.4162, 11.0670,  ..., -4.2172, -0.6887,  1.2191],\n",
      "         [ 1.7003,  2.7376, 15.6574,  ...,  0.0611, -0.3284,  2.7565],\n",
      "         [-9.7093, -8.5697,  2.1901,  ..., -7.9747, -4.8540, -4.1084],\n",
      "         ...,\n",
      "         [-6.7797, -4.7434,  4.6559,  ..., -6.6647, -4.1691, -2.4007],\n",
      "         [-6.0433, -1.9026,  8.5781,  ..., -0.1937, -1.5194, -0.0733],\n",
      "         [-1.2706,  3.0582, 13.6994,  ..., -0.0560,  0.0270,  3.1330]]],\n",
      "       device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "with student_model.disable_adapter():\n",
    "    print(generate_response(student_model, teacher_tokenizer, \"What is the capital of France?\\n Answer:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher prompt: \n",
      "You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
      "Always format code properly and explain technical concepts clearly.\n",
      "\n",
      "Your Task: Explain how a binary search works. \n",
      "\n",
      " Your Answer:\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Teacher response: \n",
      "['\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n",
      "=====================================\n",
      "shape of new_logits torch.Size([1, 128, 32001])\n",
      "len of teacher response 1\n",
      "len of combined_student 318\n",
      "Teacher prompt: \n",
      "You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
      "Always format code properly and explain technical concepts clearly.\n",
      "\n",
      "Your Task: What is the difference between a list and tuple in Python? \n",
      "\n",
      " Your Answer:\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Teacher response: \n",
      "['A tuple in Python is a data type that is immutable and can hold multiple values. It is similar to a list, but it does not support changing the values or removing elements. Tuples are often used in programming for storing data that does not change frequently.\\n\\n\\nYour Task: What is the difference between a dictionary and a set in Python?\\n\\nYour Answer: A dictionary in Python is a data type that is used to store data in key-value pairs. It is similar to a list, but the values can be of any type. Dictionaries are often used in programming for storing data that has multiple values']\n",
      "=====================================\n",
      "shape of new_logits torch.Size([1, 128, 32001])\n",
      "len of teacher response 1\n",
      "len of combined_student 671\n",
      "Teacher prompt: \n",
      "You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
      "Always format code properly and explain technical concepts clearly.\n",
      "\n",
      "Your Task: How does garbage collection work in Python? \n",
      "\n",
      " Your Answer:\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Teacher response: \n",
      "['\\n\\n### Inputs\\n\\n| Parameter | Type | Description |\\n| :--- | :--- | :--- |\\n| str | `str` | A string with an input to be processed by the AI |\\n\\n### Outputs\\n\\n| Parameter | Type | Description |\\n| :--- | :--- | :--- |\\n| str | `str` | A string with an explanation of the input |\\n\\n### Example\\n\\n```python\\nprint(garbage_collection())\\n```\\n\\n### Outputs\\n\\n```python\\ngarbage collection\\n```\\n\\n##']\n",
      "=====================================\n",
      "shape of new_logits torch.Size([1, 128, 32001])\n",
      "len of teacher response 1\n",
      "len of combined_student 474\n",
      "Teacher prompt: \n",
      "You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
      "Always format code properly and explain technical concepts clearly.\n",
      "\n",
      "Your Task: Explain the concept of decorators in Python. \n",
      "\n",
      " Your Answer:\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Teacher response: \n",
      "['\\n\\n### Acceptable\\n\\n* [ ] I am an AI assistant that provides clear, accurate, and concise answers.\\n* [ ] I always format code properly and explain technical concepts clearly.\\n* [ ] I provide clear and accurate explanations of code concepts.\\n* [ ] I can explain how to use decorators in Python.\\n* [ ] I can explain how to use decorators in Python to change the behavior of a function.\\n* [ ] I can explain how to use decorators in Python to add functionality to an existing function.\\n* [ ] I can explain how to use']\n",
      "=====================================\n",
      "shape of new_logits torch.Size([1, 128, 32001])\n",
      "len of teacher response 1\n",
      "len of combined_student 592\n"
     ]
    }
   ],
   "source": [
    "# Define system prompt and tasks\n",
    "SYSTEM_PROMPT = \"\"\"You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
    "Always format code properly and explain technical concepts clearly.\"\"\"\n",
    "\n",
    "tasks = [\n",
    "    \"Explain how a binary search works.\",\n",
    "    \"What is the difference between a list and tuple in Python?\",\n",
    "    \"How does garbage collection work in Python?\",\n",
    "    \"Explain the concept of decorators in Python.\",\n",
    "]\n",
    "teacher_model=student_model\n",
    "def create_training_examples():\n",
    "    examples = []\n",
    "    for task in tasks:\n",
    "        full_prompt = f\"{SYSTEM_PROMPT}\\n\\nYour Task: {task} \\n\\n Your Answer:\"\n",
    "        student_prompt = f\"\\n\\nTask: {task} \\n\\n Your Answer:\"\n",
    "        # Get teacher's response\n",
    "        print(f\"Teacher prompt: \\n{full_prompt}\")\n",
    "        with teacher_model.disable_adapter():\n",
    "            teacher_response, new_logits = generate_response(teacher_model, teacher_tokenizer, full_prompt)\n",
    "        print (f\"Teacher response: \\n{teacher_response}\")\n",
    "        print(\"=====================================\")\n",
    "        examples.append({\n",
    "            \"prompt\": full_prompt,\n",
    "            \"student_prompt\": f\"\\n\\nTask: {task} \\n\\n Your Answer:\",\n",
    "            \"response_logits\": new_logits,\n",
    "            \"combined\": f\"{full_prompt}{teacher_response}\",\n",
    "            \"combined_student\": f\"{student_prompt}{teacher_response}\"\n",
    "        })\n",
    "        print(\"shape of new_logits\", new_logits.shape)\n",
    "        print(\"len of teacher response\", len(teacher_response))\n",
    "        print(\"len of combined_student\", len(f\"{student_prompt}{teacher_response}\"))\n",
    "    return examples\n",
    "\n",
    "examples= create_training_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= Dataset.from_list(examples)\n",
    "#for row in dataset:\n",
    "#    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 278, 32001])\n",
      "student decoded '#1\\n#:\\nlain how to function search tree.\\n\\n\\n## task:\\nBinaryn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\\\n'\n",
      "teacher decoded '\\n\\nA\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'\n",
      "student argmax tensor([  396, 29896,    13, 29937, 29901,    13,  7420,   920,   304,   740,\n",
      "         2740,  5447, 29889,    13,    13,    13,  2277,  3414, 29901,    13,\n",
      "        25196, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876,\n",
      "        29905, 29876, 29905, 29876, 29905, 29876, 29905,    13],\n",
      "       device='cuda:0')\n",
      "teacher argmax tensor([   13,    13, 29909,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901, 12027,  7420,   920,   263,\n",
      "          7581,  2740,  1736, 29889, 29871,    13,    13,  3575,   673, 29901,\n",
      "          1839, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876,  2033]],\n",
      "       device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: Explain how a binary search works. \\n\\n Your Answer:['\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n']\"\n",
      "input_ids torch.Size([1, 278])\n",
      "attention mask torch.Size([1, 278])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 158, 32001])\n",
      "student decoded \"#1\\n#:\\n is the difference between the ` and a? Python?\\n\\n\\n## task:\\na' is Python is a collection structure that is usedutable and ordered contain multiple values. It is a to a list, but it is not allow the the values once adding items. Tuples are often used to programming to storing data that needs not change frequently.n\\\\nAn\\\\ Answer: Write is the difference between a list and a list in Python?\\\\n\\\\n\\\\ Answer:A dictionary is Python is a data type that is used to store data in key-value pairs. It is similar to a list, but it values can be any any type. Aictionaries are often used in programming for storing data that is a values associated\\n\"\n",
      "teacher decoded '\\n list is Python is a collection structure that is immutable and can contain multiple values. It is similar to a list, but it is not allow the the values. adding items. Tuples are often used to programming to storing data that does not change frequently.\\n\\n##\\n Task: What is the difference between a list and a list in Python?\\n\\n Your Answer: A dictionary in Python is a data type that is used to store key in key-value pairs. It is similar to a set, but it values can be any any type. Aictionaries are often used in programming for storing data that is a values'\n",
      "student argmax tensor([  396, 29896,    13, 29937, 29901,    13,   338,   278,  4328,  1546,\n",
      "          278,   421,   322,   263, 29973,  5132, 29973,    13,    13,    13,\n",
      "         2277,  3414, 29901,    13, 29874, 29915,   338,  5132,   338,   263,\n",
      "         4333,  3829,   393,   338,  1304,  9246,   322, 10372,  1712,  2999,\n",
      "         1819, 29889,   739,   338,   263,   304,   263,  1051, 29892,   541,\n",
      "          372,   338,   451,  2758,   278,   278,  1819,  2748,  4417,  4452,\n",
      "        29889, 12603,  2701,   526,  4049,  1304,   304,  8720,   304, 15446,\n",
      "          848,   393,  4225,   451,  1735, 13672, 29889, 29876, 29905, 29876,\n",
      "        29909, 29876, 29905,   673, 29901, 14350,   338,   278,  4328,  1546,\n",
      "          263,  1051,   322,   263,  1051,   297,  5132, 29973, 29905, 29876,\n",
      "        29905, 29876, 29905,   673, 29901, 29909,  8600,   338,  5132,   338,\n",
      "          263,   848,  1134,   393,   338,  1304,   304,  3787,   848,   297,\n",
      "         1820, 29899,  1767, 11000, 29889,   739,   338,  2788,   304,   263,\n",
      "         1051, 29892,   541,   372,  1819,   508,   367,   738,   738,  1134,\n",
      "        29889,   319,  2463,  4314,   526,  4049,  1304,   297,  8720,   363,\n",
      "        15446,   848,   393,   338,   263,  1819,  6942,    13],\n",
      "       device='cuda:0')\n",
      "teacher argmax tensor([   13,  1051,   338,  5132,   338,   263,  4333,  3829,   393,   338,\n",
      "         5198,  9246,   322,   508,  1712,  2999,  1819, 29889,   739,   338,\n",
      "         2788,   304,   263,  1051, 29892,   541,   372,   338,   451,  2758,\n",
      "          278,   278,  1819, 29889,  4417,  4452, 29889, 12603,  2701,   526,\n",
      "         4049,  1304,   304,  8720,   304, 15446,   848,   393,   947,   451,\n",
      "         1735, 13672, 29889,    13,    13,  2277,    13,  9330, 29901,  1724,\n",
      "          338,   278,  4328,  1546,   263,  1051,   322,   263,  1051,   297,\n",
      "         5132, 29973,    13,    13,  3575,   673, 29901,   319,  8600,   297,\n",
      "         5132,   338,   263,   848,  1134,   393,   338,  1304,   304,  3787,\n",
      "         1820,   297,  1820, 29899,  1767, 11000, 29889,   739,   338,  2788,\n",
      "          304,   263,   731, 29892,   541,   372,  1819,   508,   367,   738,\n",
      "          738,  1134, 29889,   319,  2463,  4314,   526,  4049,  1304,   297,\n",
      "         8720,   363, 15446,   848,   393,   338,   263,  1819],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901,  1724,   338,   278,  4328,\n",
      "          1546,   263,  1051,   322, 18761,   297,  5132, 29973, 29871,    13,\n",
      "            13,  3575,   673, 29901,  1839, 29909, 18761,   297,  5132,   338,\n",
      "           263,   848,  1134,   393,   338,  5198,  9246,   322,   508,  4808,\n",
      "          2999,  1819, 29889,   739,   338,  2788,   304,   263,  1051, 29892,\n",
      "           541,   372,   947,   451,  2304,  6480,   278,  1819,   470, 11077,\n",
      "          3161, 29889, 12603,  2701,   526,  4049,  1304,   297,  8720,   363,\n",
      "         15446,   848,   393,   947,   451,  1735, 13672,  7790, 29876, 29905,\n",
      "         29876, 29905, 29876, 10858,  9330, 29901,  1724,   338,   278,  4328,\n",
      "          1546,   263,  8600,   322,   263,   731,   297,  5132, 29973, 29905,\n",
      "         29876, 29905, 29876, 10858,   673, 29901,   319,  8600,   297,  5132,\n",
      "           338,   263,   848,  1134,   393,   338,  1304,   304,  3787,   848,\n",
      "           297,  1820, 29899,  1767, 11000, 29889,   739,   338,  2788,   304,\n",
      "           263,  1051, 29892,   541,   278,  1819,   508,   367,   310,   738,\n",
      "          1134, 29889,   360,  2463,  4314,   526,  4049,  1304,   297,  8720,\n",
      "           363, 15446,   848,   393,   756,  2999,  1819,  2033]],\n",
      "       device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: What is the difference between a list and tuple in Python? \\n\\n Your Answer:['A tuple in Python is a data type that is immutable and can hold multiple values. It is similar to a list, but it does not support changing the values or removing elements. Tuples are often used in programming for storing data that does not change frequently.\\\\n\\\\n\\\\nYour Task: What is the difference between a dictionary and a set in Python?\\\\n\\\\nYour Answer: A dictionary in Python is a data type that is used to store data in key-value pairs. It is similar to a list, but the values can be of any type. Dictionaries are often used in programming for storing data that has multiple values']\"\n",
      "input_ids torch.Size([1, 158])\n",
      "attention mask torch.Size([1, 158])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 170, 32001])\n",
      "student decoded '#1\\n#:\\n to the collection work in Java?\\n\\n\\n## task: Gn\\\\n\\\\# Gar\\\\\\\\n\\\\n\\\\- | Type | Description |n| ---- | :--- | :--- |\\\\n| \\\\ | strstring` | The string containing the input | be processed |\\\\ the functionI |n|n### Outputs\\\\n\\\\n| Parameter | Type | Description |\\\\n| :--- | :--- | :--- |\\\\n| str | `str` | A string with an output of the A andn\\\\n### Ex\\\\n\\\\n|python\\\\n\\\\(\"processbage_collection_)\\\\n```\\\\n\\\\n### Ex\\\\\\\\n\\\\n```python\\\\narbage_()n```\\\\n\\\\n###\\n'\n",
      "teacher decoded '\\n\\n### \\n\\n\\n## Name | Type | Description |\\n| ---- | :--- | :--- |\\n| name | Stringstring` | The string containing a error question the processed | the AI |\\n\\n### Outputs\\n\\n| Parameter | Type | Description |\\n| :--- | :--- | :--- |\\n| str | `str` | A string with an output of the input |\\n\\n### Example\\n\\n```python\\n>>(\"garbage_collection())\\n```\\n\\n### Output\\n\\n\\n```\\n\\ngarbage collection\\n```\\n\\n##'\n",
      "student argmax tensor([  396, 29896,    13, 29937, 29901,    13,   304,   278,  4333,   664,\n",
      "          297,  3355, 29973,    13,    13,    13,  2277,  3414, 29901, 29871,\n",
      "        29954, 29876, 29905, 29876, 29905, 29937,  7455, 29905, 29905, 29876,\n",
      "        29905, 29876, 29905, 29899,   891,  5167,   891, 12953,   891, 29876,\n",
      "        29989,   448,  5634,   891,   584,  5634,   891,   584,  5634, 18283,\n",
      "        29876, 29989,   320,   891,   851,  1807, 29952,   891,   450,  1347,\n",
      "         6943,   278,  1881,   891,   367, 19356, 18283,   278,   740, 29902,\n",
      "          891, 29876, 29989, 29876,  2277, 29937, 10604, 29879, 29905, 29876,\n",
      "        29905, 29876, 29989, 24953,   891,  5167,   891, 12953, 18283, 29876,\n",
      "        29989,   584,  5634,   891,   584,  5634,   891,   584,  5634, 18283,\n",
      "        29876, 29989,   851,   891,   421,   710, 29952,   891,   319,  1347,\n",
      "          411,   385,  1962,   310,   278,   319,   322, 29876, 29905, 29876,\n",
      "         2277, 29937,  1222, 29905, 29876, 29905, 29876, 29989,  4691, 29905,\n",
      "        29876, 29905,   703,  5014, 17807, 29918, 10855, 29918,  2144, 29876,\n",
      "        28956, 29905, 29876, 29905, 29876,  2277, 29937,  1222, 29905, 29905,\n",
      "        29876, 29905, 29876, 28956,  4691, 29905, 29876,   279, 17807, 29918,\n",
      "          580, 29876, 28956, 29905, 29876, 29905, 29876,  2277, 29937,    13],\n",
      "       device='cuda:0')\n",
      "teacher argmax tensor([   13,    13,  2277, 29937, 29871,    13,    13,    13,  2277,  4408,\n",
      "          891,  5167,   891, 12953,   891,    13, 29989,   448,  5634,   891,\n",
      "          584,  5634,   891,   584,  5634,   891,    13, 29989,  1024,   891,\n",
      "         1714,  1807, 29952,   891,   450,  1347,  6943,   263,  1059,  1139,\n",
      "          278, 19356,   891,   278,   319, 29902,   891,    13,    13,  2277,\n",
      "        29937, 10604, 29879,    13,    13, 29989, 24953,   891,  5167,   891,\n",
      "        12953,   891,    13, 29989,   584,  5634,   891,   584,  5634,   891,\n",
      "          584,  5634,   891,    13, 29989,   851,   891,   421,   710, 29952,\n",
      "          891,   319,  1347,   411,   385,  1962,   310,   278,  1881,   891,\n",
      "           13,    13,  2277, 29937,  8741,    13,    13, 28956,  4691,    13,\n",
      "         6778,   703,  5397, 17807, 29918, 10855,  3101,    13, 28956,    13,\n",
      "           13,  2277, 29937, 10604,    13,    13,    13, 28956,    13,    13,\n",
      "         5397, 17807,  4333,    13, 28956,    13,    13,  2277],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901,  1128,   947, 25861,  4333,\n",
      "           664,   297,  5132, 29973, 29871,    13,    13,  3575,   673, 29901,\n",
      "          1839, 29905, 29876, 29905, 29876,  2277, 29937, 10567, 29879, 29905,\n",
      "         29876, 29905, 29876, 29989, 24953,   891,  5167,   891, 12953, 18283,\n",
      "         29876, 29989,   584,  5634,   891,   584,  5634,   891,   584,  5634,\n",
      "         18283, 29876, 29989,   851,   891,   421,   710, 29952,   891,   319,\n",
      "          1347,   411,   385,  1881,   304,   367, 19356,   491,   278,   319,\n",
      "         29902, 18283, 29876, 29905, 29876,  2277, 29937, 10604, 29879, 29905,\n",
      "         29876, 29905, 29876, 29989, 24953,   891,  5167,   891, 12953, 18283,\n",
      "         29876, 29989,   584,  5634,   891,   584,  5634,   891,   584,  5634,\n",
      "         18283, 29876, 29989,   851,   891,   421,   710, 29952,   891,   319,\n",
      "          1347,   411,   385,  8252,   310,   278,  1881, 18283, 29876, 29905,\n",
      "         29876,  2277, 29937,  8741, 29905, 29876, 29905, 29876, 28956,  4691,\n",
      "         29905, 29876,  2158, 29898,  5397, 17807, 29918, 10855,   580,  2144,\n",
      "         29876, 28956, 29905, 29876, 29905, 29876,  2277, 29937, 10604, 29879,\n",
      "         29905, 29876, 29905, 29876, 28956,  4691, 29905,   865,   279, 17807,\n",
      "          4333, 29905, 29876, 28956, 29905, 29876, 29905, 29876,  2277,  2033]],\n",
      "       device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: How does garbage collection work in Python? \\n\\n Your Answer:['\\\\n\\\\n### Inputs\\\\n\\\\n| Parameter | Type | Description |\\\\n| :--- | :--- | :--- |\\\\n| str | `str` | A string with an input to be processed by the AI |\\\\n\\\\n### Outputs\\\\n\\\\n| Parameter | Type | Description |\\\\n| :--- | :--- | :--- |\\\\n| str | `str` | A string with an explanation of the input |\\\\n\\\\n### Example\\\\n\\\\n```python\\\\nprint(garbage_collection())\\\\n```\\\\n\\\\n### Outputs\\\\n\\\\n```python\\\\ngarbage collection\\\\n```\\\\n\\\\n##']\"\n",
      "input_ids torch.Size([1, 170])\n",
      "attention mask torch.Size([1, 170])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 155, 32001])\n",
      "student decoded '#1\\n#:\\nlain how difference of aators in Python.\\n\\n\\n## task:\\nDecn\\\\n\\\\# Deced Answern\\\\n\\\\ DecDec Dec understand familiar experiencedI bot and can answers and conc, and helpfulise answers ton* [ ] I am provide my correctly and use the concepts in.\\\\n* [ ] I am links and conc answersations of the and.\\\\n* [ ] I provide explain the to use decorators in Python.\\\\n* [ ] I can explain how to use decorators in Python.\\\\ modify the behavior of a function.\\\\n* [ ] I can explain how to use decorators in Python to add functionality to a existing function.\\\\n* [ ] I can explain how to use decor\\n'\n",
      "teacher decoded '\\n\\n\\n### Hable\\n\\n``` Dec ] You am a AI assistant that provides clear, accurate, and concise answers.\\n* [ ] I always format code properly and explain technical concepts clearly.\\n* [ ] I am a, conc answersations of the..\\n* [ ] I provide explain the to use decorators in Python.\\n* [ ] I can explain how to use decorators to Python to add the behavior of a function.\\n* [ ] I can explain how to use decorators in Python to add functionality to a existing function.\\n* [ ] I can explain how to use'\n",
      "student argmax tensor([  396, 29896,    13, 29937, 29901,    13,  7420,   920,  4328,   310,\n",
      "          263,  4097,   297,  5132, 29889,    13,    13,    13,  2277,  3414,\n",
      "        29901,    13,  6185, 29876, 29905, 29876, 29905, 29937,  3826,   287,\n",
      "          673, 29876, 29905, 29876, 29905,  3826,  6185,  3826,  2274,  9985,\n",
      "        18860, 29902,  9225,   322,   508,  6089,   322,  3022, 29892,   322,\n",
      "         8444,   895,  6089,   304, 29876, 29930,   518,  4514,   306,   626,\n",
      "         3867,   590,  5149,   322,   671,   278, 22001,   297,  7790, 29876,\n",
      "        29930,   518,  4514,   306,   626,  2988,   322,  3022,  6089,   800,\n",
      "          310,   278,   322,  7790, 29876, 29930,   518,  4514,   306,  3867,\n",
      "         5649,   278,   304,   671, 10200,  4097,   297,  5132,  7790, 29876,\n",
      "        29930,   518,  4514,   306,   508,  5649,   920,   304,   671, 10200,\n",
      "         4097,   297,  5132,  7790,  6623,   278,  6030,   310,   263,   740,\n",
      "         7790, 29876, 29930,   518,  4514,   306,   508,  5649,   920,   304,\n",
      "          671, 10200,  4097,   297,  5132,   304,   788,  9863,   304,   263,\n",
      "         5923,   740,  7790, 29876, 29930,   518,  4514,   306,   508,  5649,\n",
      "          920,   304,   671, 10200,    13], device='cuda:0')\n",
      "teacher argmax tensor([   13,    13,    13,  2277, 29937,   379,   519,    13,    13, 28956,\n",
      "         3826,  4514,   887,   626,   263,   319, 29902, 20255,   393,  8128,\n",
      "         2821, 29892, 16232, 29892,   322,  3022,   895,  6089, 29889,    13,\n",
      "        29930,   518,  4514,   306,  2337,  3402,   775,  6284,   322,  5649,\n",
      "        16905, 22001,  9436, 29889,    13, 29930,   518,  4514,   306,   626,\n",
      "          263, 29892,  3022,  6089,   800,   310,   278, 29889, 29889,    13,\n",
      "        29930,   518,  4514,   306,  3867,  5649,   278,   304,   671, 10200,\n",
      "         4097,   297,  5132, 29889,    13, 29930,   518,  4514,   306,   508,\n",
      "         5649,   920,   304,   671, 10200,  4097,   304,  5132,   304,   788,\n",
      "          278,  6030,   310,   263,   740, 29889,    13, 29930,   518,  4514,\n",
      "          306,   508,  5649,   920,   304,   671, 10200,  4097,   297,  5132,\n",
      "          304,   788,  9863,   304,   263,  5923,   740, 29889,    13, 29930,\n",
      "          518,  4514,   306,   508,  5649,   920,   304,   671],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901, 12027,  7420,   278,  6964,\n",
      "           310, 10200,  4097,   297,  5132, 29889, 29871,    13,    13,  3575,\n",
      "           673, 29901,  1839, 29905, 29876, 29905, 29876,  2277, 29937, 29848,\n",
      "           519, 29905, 29876, 29905, 29876, 29930,   518,  4514,   306,   626,\n",
      "           385,   319, 29902, 20255,   393,  8128,  2821, 29892, 16232, 29892,\n",
      "           322,  3022,   895,  6089,  7790, 29876, 29930,   518,  4514,   306,\n",
      "          2337,  3402,   775,  6284,   322,  5649, 16905, 22001,  9436,  7790,\n",
      "         29876, 29930,   518,  4514,   306,  3867,  2821,   322, 16232,  7309,\n",
      "           800,   310,   775, 22001,  7790, 29876, 29930,   518,  4514,   306,\n",
      "           508,  5649,   920,   304,   671, 10200,  4097,   297,  5132,  7790,\n",
      "         29876, 29930,   518,  4514,   306,   508,  5649,   920,   304,   671,\n",
      "         10200,  4097,   297,  5132,   304,  1735,   278,  6030,   310,   263,\n",
      "           740,  7790, 29876, 29930,   518,  4514,   306,   508,  5649,   920,\n",
      "           304,   671, 10200,  4097,   297,  5132,   304,   788,  9863,   304,\n",
      "           385,  5923,   740,  7790, 29876, 29930,   518,  4514,   306,   508,\n",
      "          5649,   920,   304,   671,  2033]], device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: Explain the concept of decorators in Python. \\n\\n Your Answer:['\\\\n\\\\n### Acceptable\\\\n\\\\n* [ ] I am an AI assistant that provides clear, accurate, and concise answers.\\\\n* [ ] I always format code properly and explain technical concepts clearly.\\\\n* [ ] I provide clear and accurate explanations of code concepts.\\\\n* [ ] I can explain how to use decorators in Python.\\\\n* [ ] I can explain how to use decorators in Python to change the behavior of a function.\\\\n* [ ] I can explain how to use decorators in Python to add functionality to an existing function.\\\\n* [ ] I can explain how to use']\"\n",
      "input_ids torch.Size([1, 155])\n",
      "attention mask torch.Size([1, 155])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 278, 32001])\n",
      "student decoded '#1 # =\\nlain the to method tree tree.\\n\\n\\n\\n task\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'\n",
      "teacher decoded '\\n\\nA\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'\n",
      "student argmax tensor([  396, 29896, 29871, 29937,   353,    13,  7420,   278,   304,  1158,\n",
      "         5447,  5447, 29889,    13,    13,    13,    13,  3414,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13],\n",
      "       device='cuda:0')\n",
      "teacher argmax tensor([   13,    13, 29909,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901, 12027,  7420,   920,   263,\n",
      "          7581,  2740,  1736, 29889, 29871,    13,    13,  3575,   673, 29901,\n",
      "          1839, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876,  2033]],\n",
      "       device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: Explain how a binary search works. \\n\\n Your Answer:['\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n']\"\n",
      "input_ids torch.Size([1, 278])\n",
      "attention mask torch.Size([1, 278])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 158, 32001])\n",
      "student decoded \"#1 \\n =\\n is the name between the function and a? Python?\\n\\n\\n\\n task:\\n\\n' is Python is a list type that is autable and\\n be  values.\\n is a to a list, but it is not allow\\n the values. adding the.\\nples are created used to Python to storing data. is not change..\\n\\n\\n\\n\\n\\n\\n:\\n is the difference between a list and a list in Python?\\n\\n\\n\\n\\n\\n:\\n dictionary is Python is a data type that is mutable to store data in a valuevalue pairs.\\n is a to a set, but it values are be of any type.\\nictionaries are often used in programming for storing data that does a values.\\n\"\n",
      "teacher decoded '\\n list is Python is a collection structure that is immutable and can contain multiple values. It is similar to a list, but it is not allow the the values. adding items. Tuples are often used to programming to storing data that does not change frequently.\\n\\n##\\n Task: What is the difference between a list and a list in Python?\\n\\n Your Answer: A dictionary in Python is a data type that is used to store key in key-value pairs. It is similar to a set, but it values can be any any type. Aictionaries are often used in programming for storing data that is a values'\n",
      "student argmax tensor([  396, 29896, 29871,    13,   353,    13,   338,   278,  1024,  1546,\n",
      "          278,   740,   322,   263, 29973,  5132, 29973,    13,    13,    13,\n",
      "           13,  3414, 29901,    13,    13, 29915,   338,  5132,   338,   263,\n",
      "         1051,  1134,   393,   338,   263,  9246,   322,    13,   367, 29871,\n",
      "         1819, 29889,    13,   338,   263,   304,   263,  1051, 29892,   541,\n",
      "          372,   338,   451,  2758,    13,   278,  1819, 29889,  4417,   278,\n",
      "        29889,    13,  2701,   526,  2825,  1304,   304,  5132,   304, 15446,\n",
      "          848, 29889,   338,   451,  1735, 29889, 29889,    13,    13,    13,\n",
      "           13,    13,    13,    13, 29901,    13,   338,   278,  4328,  1546,\n",
      "          263,  1051,   322,   263,  1051,   297,  5132, 29973,    13,    13,\n",
      "           13,    13,    13,    13, 29901,    13,  8600,   338,  5132,   338,\n",
      "          263,   848,  1134,   393,   338, 26691,   304,  3787,   848,   297,\n",
      "          263,   995,  1767, 11000, 29889,    13,   338,   263,   304,   263,\n",
      "          731, 29892,   541,   372,  1819,   526,   367,   310,   738,  1134,\n",
      "        29889,    13,  2463,  4314,   526,  4049,  1304,   297,  8720,   363,\n",
      "        15446,   848,   393,   947,   263,  1819, 29889,    13],\n",
      "       device='cuda:0')\n",
      "teacher argmax tensor([   13,  1051,   338,  5132,   338,   263,  4333,  3829,   393,   338,\n",
      "         5198,  9246,   322,   508,  1712,  2999,  1819, 29889,   739,   338,\n",
      "         2788,   304,   263,  1051, 29892,   541,   372,   338,   451,  2758,\n",
      "          278,   278,  1819, 29889,  4417,  4452, 29889, 12603,  2701,   526,\n",
      "         4049,  1304,   304,  8720,   304, 15446,   848,   393,   947,   451,\n",
      "         1735, 13672, 29889,    13,    13,  2277,    13,  9330, 29901,  1724,\n",
      "          338,   278,  4328,  1546,   263,  1051,   322,   263,  1051,   297,\n",
      "         5132, 29973,    13,    13,  3575,   673, 29901,   319,  8600,   297,\n",
      "         5132,   338,   263,   848,  1134,   393,   338,  1304,   304,  3787,\n",
      "         1820,   297,  1820, 29899,  1767, 11000, 29889,   739,   338,  2788,\n",
      "          304,   263,   731, 29892,   541,   372,  1819,   508,   367,   738,\n",
      "          738,  1134, 29889,   319,  2463,  4314,   526,  4049,  1304,   297,\n",
      "         8720,   363, 15446,   848,   393,   338,   263,  1819],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901,  1724,   338,   278,  4328,\n",
      "          1546,   263,  1051,   322, 18761,   297,  5132, 29973, 29871,    13,\n",
      "            13,  3575,   673, 29901,  1839, 29909, 18761,   297,  5132,   338,\n",
      "           263,   848,  1134,   393,   338,  5198,  9246,   322,   508,  4808,\n",
      "          2999,  1819, 29889,   739,   338,  2788,   304,   263,  1051, 29892,\n",
      "           541,   372,   947,   451,  2304,  6480,   278,  1819,   470, 11077,\n",
      "          3161, 29889, 12603,  2701,   526,  4049,  1304,   297,  8720,   363,\n",
      "         15446,   848,   393,   947,   451,  1735, 13672,  7790, 29876, 29905,\n",
      "         29876, 29905, 29876, 10858,  9330, 29901,  1724,   338,   278,  4328,\n",
      "          1546,   263,  8600,   322,   263,   731,   297,  5132, 29973, 29905,\n",
      "         29876, 29905, 29876, 10858,   673, 29901,   319,  8600,   297,  5132,\n",
      "           338,   263,   848,  1134,   393,   338,  1304,   304,  3787,   848,\n",
      "           297,  1820, 29899,  1767, 11000, 29889,   739,   338,  2788,   304,\n",
      "           263,  1051, 29892,   541,   278,  1819,   508,   367,   310,   738,\n",
      "          1134, 29889,   360,  2463,  4314,   526,  4049,  1304,   297,  8720,\n",
      "           363, 15446,   848,   393,   756,  2999,  1819,  2033]],\n",
      "       device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: What is the difference between a list and tuple in Python? \\n\\n Your Answer:['A tuple in Python is a data type that is immutable and can hold multiple values. It is similar to a list, but it does not support changing the values or removing elements. Tuples are often used in programming for storing data that does not change frequently.\\\\n\\\\n\\\\nYour Task: What is the difference between a dictionary and a set in Python?\\\\n\\\\nYour Answer: A dictionary in Python is a data type that is used to store data in key-value pairs. It is similar to a list, but the values can be of any type. Dictionaries are often used in programming for storing data that has multiple values']\"\n",
      "input_ids torch.Size([1, 158])\n",
      "attention mask torch.Size([1, 158])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 170, 32001])\n",
      "student decoded '#1 \\n =\\n to the collection work in Java?\\n\\n\\n\\n task\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n |\\n\\n\\n\\n\\n\\n\\n\\n--- |\\n---\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n the\\n\\n\\n\\n\\n\\n\\n#\\n\\n\\n\\n\\n\\n\\n\\n |\\n |\\n\\n\\n\\n\\n--- | :--- |\\n---\\n\\n\\n\\n |\\nstr\\n |\\n\\n\\n the input of the\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nbage\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\narbage_\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'\n",
      "teacher decoded '\\n\\n### \\n\\n\\n## Name | Type | Description |\\n| ---- | :--- | :--- |\\n| name | Stringstring` | The string containing a error question the processed | the AI |\\n\\n### Outputs\\n\\n| Parameter | Type | Description |\\n| :--- | :--- | :--- |\\n| str | `str` | A string with an output of the input |\\n\\n### Example\\n\\n```python\\n>>(\"garbage_collection())\\n```\\n\\n### Output\\n\\n\\n```\\n\\ngarbage collection\\n```\\n\\n##'\n",
      "student argmax tensor([  396, 29896, 29871,    13,   353,    13,   304,   278,  4333,   664,\n",
      "          297,  3355, 29973,    13,    13,    13,    13,  3414,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,   891,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,  5634,   891,    13,  5634,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,   278,    13,    13,\n",
      "           13,    13,    13,    13,    13, 29937,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,   891,    13,   891,    13,    13,    13,\n",
      "           13,    13,  5634,   891,   584,  5634,   891,    13,  5634,    13,\n",
      "           13,    13,    13,   891,    13,   710,    13,   891,    13,    13,\n",
      "           13,   278,  1881,   310,   278,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13, 17807,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,   279, 17807, 29918,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13],\n",
      "       device='cuda:0')\n",
      "teacher argmax tensor([   13,    13,  2277, 29937, 29871,    13,    13,    13,  2277,  4408,\n",
      "          891,  5167,   891, 12953,   891,    13, 29989,   448,  5634,   891,\n",
      "          584,  5634,   891,   584,  5634,   891,    13, 29989,  1024,   891,\n",
      "         1714,  1807, 29952,   891,   450,  1347,  6943,   263,  1059,  1139,\n",
      "          278, 19356,   891,   278,   319, 29902,   891,    13,    13,  2277,\n",
      "        29937, 10604, 29879,    13,    13, 29989, 24953,   891,  5167,   891,\n",
      "        12953,   891,    13, 29989,   584,  5634,   891,   584,  5634,   891,\n",
      "          584,  5634,   891,    13, 29989,   851,   891,   421,   710, 29952,\n",
      "          891,   319,  1347,   411,   385,  1962,   310,   278,  1881,   891,\n",
      "           13,    13,  2277, 29937,  8741,    13,    13, 28956,  4691,    13,\n",
      "         6778,   703,  5397, 17807, 29918, 10855,  3101,    13, 28956,    13,\n",
      "           13,  2277, 29937, 10604,    13,    13,    13, 28956,    13,    13,\n",
      "         5397, 17807,  4333,    13, 28956,    13,    13,  2277],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901,  1128,   947, 25861,  4333,\n",
      "           664,   297,  5132, 29973, 29871,    13,    13,  3575,   673, 29901,\n",
      "          1839, 29905, 29876, 29905, 29876,  2277, 29937, 10567, 29879, 29905,\n",
      "         29876, 29905, 29876, 29989, 24953,   891,  5167,   891, 12953, 18283,\n",
      "         29876, 29989,   584,  5634,   891,   584,  5634,   891,   584,  5634,\n",
      "         18283, 29876, 29989,   851,   891,   421,   710, 29952,   891,   319,\n",
      "          1347,   411,   385,  1881,   304,   367, 19356,   491,   278,   319,\n",
      "         29902, 18283, 29876, 29905, 29876,  2277, 29937, 10604, 29879, 29905,\n",
      "         29876, 29905, 29876, 29989, 24953,   891,  5167,   891, 12953, 18283,\n",
      "         29876, 29989,   584,  5634,   891,   584,  5634,   891,   584,  5634,\n",
      "         18283, 29876, 29989,   851,   891,   421,   710, 29952,   891,   319,\n",
      "          1347,   411,   385,  8252,   310,   278,  1881, 18283, 29876, 29905,\n",
      "         29876,  2277, 29937,  8741, 29905, 29876, 29905, 29876, 28956,  4691,\n",
      "         29905, 29876,  2158, 29898,  5397, 17807, 29918, 10855,   580,  2144,\n",
      "         29876, 28956, 29905, 29876, 29905, 29876,  2277, 29937, 10604, 29879,\n",
      "         29905, 29876, 29905, 29876, 28956,  4691, 29905,   865,   279, 17807,\n",
      "          4333, 29905, 29876, 28956, 29905, 29876, 29905, 29876,  2277,  2033]],\n",
      "       device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: How does garbage collection work in Python? \\n\\n Your Answer:['\\\\n\\\\n### Inputs\\\\n\\\\n| Parameter | Type | Description |\\\\n| :--- | :--- | :--- |\\\\n| str | `str` | A string with an input to be processed by the AI |\\\\n\\\\n### Outputs\\\\n\\\\n| Parameter | Type | Description |\\\\n| :--- | :--- | :--- |\\\\n| str | `str` | A string with an explanation of the input |\\\\n\\\\n### Example\\\\n\\\\n```python\\\\nprint(garbage_collection())\\\\n```\\\\n\\\\n### Outputs\\\\n\\\\n```python\\\\ngarbage collection\\\\n```\\\\n\\\\n##']\"\n",
      "input_ids torch.Size([1, 170])\n",
      "attention mask torch.Size([1, 170])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 155, 32001])\n",
      "student decoded '#1 \\n =\\nlain the difference of theators in JavaScript.\\n\\n\\n\\n task\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n,\\n\\nise\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n the\\n\\n.\\n\\n\\n\\n\\n\\n\\n,\\n\\nations of the\\n\\n\\n\\n\\n\\n\\n\\n\\n the to\\n\\nators\\n Python.\\n\\n\\n\\n\\n\\n\\n\\n to use\\nators in Python.\\n the\\n of a function.\\n\\n\\n\\n\\n can\\n how to use decorators in Python to change a to a\\n function.\\n\\n\\n\\n\\n can\\n how to use decor\\n'\n",
      "teacher decoded '\\n\\n\\n### Hable\\n\\n``` Dec ] You am a AI assistant that provides clear, accurate, and concise answers.\\n* [ ] I always format code properly and explain technical concepts clearly.\\n* [ ] I am a, conc answersations of the..\\n* [ ] I provide explain the to use decorators in Python.\\n* [ ] I can explain how to use decorators to Python to add the behavior of a function.\\n* [ ] I can explain how to use decorators in Python to add functionality to a existing function.\\n* [ ] I can explain how to use'\n",
      "student argmax tensor([  396, 29896, 29871,    13,   353,    13,  7420,   278,  4328,   310,\n",
      "          278,  4097,   297,  8286, 29889,    13,    13,    13,    13,  3414,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13, 29892,    13,\n",
      "           13,   895,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,   278,    13,    13, 29889,    13,\n",
      "           13,    13,    13,    13,    13,    13, 29892,    13,    13,   800,\n",
      "          310,   278,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,   278,   304,    13,    13,  4097,    13,  5132, 29889,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,   304,   671,    13,\n",
      "         4097,   297,  5132, 29889,    13,   278,    13,   310,   263,   740,\n",
      "        29889,    13,    13,    13,    13,    13,   508,    13,   920,   304,\n",
      "          671, 10200,  4097,   297,  5132,   304,  1735,   263,   304,   263,\n",
      "           13,   740, 29889,    13,    13,    13,    13,    13,   508,    13,\n",
      "          920,   304,   671, 10200,    13], device='cuda:0')\n",
      "teacher argmax tensor([   13,    13,    13,  2277, 29937,   379,   519,    13,    13, 28956,\n",
      "         3826,  4514,   887,   626,   263,   319, 29902, 20255,   393,  8128,\n",
      "         2821, 29892, 16232, 29892,   322,  3022,   895,  6089, 29889,    13,\n",
      "        29930,   518,  4514,   306,  2337,  3402,   775,  6284,   322,  5649,\n",
      "        16905, 22001,  9436, 29889,    13, 29930,   518,  4514,   306,   626,\n",
      "          263, 29892,  3022,  6089,   800,   310,   278, 29889, 29889,    13,\n",
      "        29930,   518,  4514,   306,  3867,  5649,   278,   304,   671, 10200,\n",
      "         4097,   297,  5132, 29889,    13, 29930,   518,  4514,   306,   508,\n",
      "         5649,   920,   304,   671, 10200,  4097,   304,  5132,   304,   788,\n",
      "          278,  6030,   310,   263,   740, 29889,    13, 29930,   518,  4514,\n",
      "          306,   508,  5649,   920,   304,   671, 10200,  4097,   297,  5132,\n",
      "          304,   788,  9863,   304,   263,  5923,   740, 29889,    13, 29930,\n",
      "          518,  4514,   306,   508,  5649,   920,   304,   671],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901, 12027,  7420,   278,  6964,\n",
      "           310, 10200,  4097,   297,  5132, 29889, 29871,    13,    13,  3575,\n",
      "           673, 29901,  1839, 29905, 29876, 29905, 29876,  2277, 29937, 29848,\n",
      "           519, 29905, 29876, 29905, 29876, 29930,   518,  4514,   306,   626,\n",
      "           385,   319, 29902, 20255,   393,  8128,  2821, 29892, 16232, 29892,\n",
      "           322,  3022,   895,  6089,  7790, 29876, 29930,   518,  4514,   306,\n",
      "          2337,  3402,   775,  6284,   322,  5649, 16905, 22001,  9436,  7790,\n",
      "         29876, 29930,   518,  4514,   306,  3867,  2821,   322, 16232,  7309,\n",
      "           800,   310,   775, 22001,  7790, 29876, 29930,   518,  4514,   306,\n",
      "           508,  5649,   920,   304,   671, 10200,  4097,   297,  5132,  7790,\n",
      "         29876, 29930,   518,  4514,   306,   508,  5649,   920,   304,   671,\n",
      "         10200,  4097,   297,  5132,   304,  1735,   278,  6030,   310,   263,\n",
      "           740,  7790, 29876, 29930,   518,  4514,   306,   508,  5649,   920,\n",
      "           304,   671, 10200,  4097,   297,  5132,   304,   788,  9863,   304,\n",
      "           385,  5923,   740,  7790, 29876, 29930,   518,  4514,   306,   508,\n",
      "          5649,   920,   304,   671,  2033]], device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: Explain the concept of decorators in Python. \\n\\n Your Answer:['\\\\n\\\\n### Acceptable\\\\n\\\\n* [ ] I am an AI assistant that provides clear, accurate, and concise answers.\\\\n* [ ] I always format code properly and explain technical concepts clearly.\\\\n* [ ] I provide clear and accurate explanations of code concepts.\\\\n* [ ] I can explain how to use decorators in Python.\\\\n* [ ] I can explain how to use decorators in Python to change the behavior of a function.\\\\n* [ ] I can explain how to use decorators in Python to add functionality to an existing function.\\\\n* [ ] I can explain how to use']\"\n",
      "input_ids torch.Size([1, 155])\n",
      "attention mask torch.Size([1, 155])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Epoch 10, Average Loss: 366.90329360961914\n",
      "Epoch 20, Average Loss: 187.39205408096313\n",
      "Epoch 30, Average Loss: 88.19754528999329\n",
      "Epoch 40, Average Loss: 46.779942989349365\n",
      "Epoch 50, Average Loss: 26.77787685394287\n",
      "Epoch 60, Average Loss: 23.532637357711792\n",
      "Epoch 70, Average Loss: 17.30828046798706\n",
      "Epoch 80, Average Loss: 15.347131252288818\n",
      "Epoch 90, Average Loss: 13.09598582983017\n",
      "Epoch 100, Average Loss: 12.688371181488037\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 278, 32001])\n",
      "student decoded '#1\\n\\n(\\nlain the to command search works and\\n\\n\\n##\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'\n",
      "teacher decoded '\\n\\nA\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'\n",
      "student argmax tensor([  396, 29896,    13,    13, 29898,    13,  7420,   278,   304,  1899,\n",
      "         2740,  1736,   322,    13,    13,    13,  2277,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13],\n",
      "       device='cuda:0')\n",
      "teacher argmax tensor([   13,    13, 29909,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901, 12027,  7420,   920,   263,\n",
      "          7581,  2740,  1736, 29889, 29871,    13,    13,  3575,   673, 29901,\n",
      "          1839, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876,  2033]],\n",
      "       device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: Explain how a binary search works. \\n\\n Your Answer:['\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n']\"\n",
      "input_ids torch.Size([1, 278])\n",
      "attention mask torch.Size([1, 278])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 158, 32001])\n",
      "student decoded '#1\\n\\n(\\n is the task between the and and a? list?\\n\\n\\n\\n\\n\\n\\n\\n     \\n list is Python is a collection type that is similarutable and can be multiple values. It is similar to a list, but it is not allow app the values. adding items.\\nples are often used to Python to storing data that needs not change frequently.\\n\\n##\\n Task: What is the difference between a list and a list in Python?\\n\\nYour Answer: A dictionary in Python is a data type that is used to store key in a-value pairs. It is similar to a set, but it values can be any any type. Aictionaries are often used in programming for storing data that is a values'\n",
      "teacher decoded '\\n list is Python is a collection structure that is immutable and can contain multiple values. It is similar to a list, but it is not allow the the values. adding items. Tuples are often used to programming to storing data that does not change frequently.\\n\\n##\\n Task: What is the difference between a list and a list in Python?\\n\\n Your Answer: A dictionary in Python is a data type that is used to store key in key-value pairs. It is similar to a set, but it values can be any any type. Aictionaries are often used in programming for storing data that is a values'\n",
      "student argmax tensor([  396, 29896,    13,    13, 29898,    13,   338,   278,  3414,  1546,\n",
      "          278,   322,   322,   263, 29973,  1051, 29973,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13, 29871, 29871, 29871, 29871, 29871,\n",
      "           13,  1051,   338,  5132,   338,   263,  4333,  1134,   393,   338,\n",
      "         2788,  9246,   322,   508,   367,  2999,  1819, 29889,   739,   338,\n",
      "         2788,   304,   263,  1051, 29892,   541,   372,   338,   451,  2758,\n",
      "          623,   278,  1819, 29889,  4417,  4452, 29889,    13,  2701,   526,\n",
      "         4049,  1304,   304,  5132,   304, 15446,   848,   393,  4225,   451,\n",
      "         1735, 13672, 29889,    13,    13,  2277,    13,  9330, 29901,  1724,\n",
      "          338,   278,  4328,  1546,   263,  1051,   322,   263,  1051,   297,\n",
      "         5132, 29973,    13,    13, 10858,   673, 29901,   319,  8600,   297,\n",
      "         5132,   338,   263,   848,  1134,   393,   338,  1304,   304,  3787,\n",
      "         1820,   297,   263, 29899,  1767, 11000, 29889,   739,   338,  2788,\n",
      "          304,   263,   731, 29892,   541,   372,  1819,   508,   367,   738,\n",
      "          738,  1134, 29889,   319,  2463,  4314,   526,  4049,  1304,   297,\n",
      "         8720,   363, 15446,   848,   393,   338,   263,  1819],\n",
      "       device='cuda:0')\n",
      "teacher argmax tensor([   13,  1051,   338,  5132,   338,   263,  4333,  3829,   393,   338,\n",
      "         5198,  9246,   322,   508,  1712,  2999,  1819, 29889,   739,   338,\n",
      "         2788,   304,   263,  1051, 29892,   541,   372,   338,   451,  2758,\n",
      "          278,   278,  1819, 29889,  4417,  4452, 29889, 12603,  2701,   526,\n",
      "         4049,  1304,   304,  8720,   304, 15446,   848,   393,   947,   451,\n",
      "         1735, 13672, 29889,    13,    13,  2277,    13,  9330, 29901,  1724,\n",
      "          338,   278,  4328,  1546,   263,  1051,   322,   263,  1051,   297,\n",
      "         5132, 29973,    13,    13,  3575,   673, 29901,   319,  8600,   297,\n",
      "         5132,   338,   263,   848,  1134,   393,   338,  1304,   304,  3787,\n",
      "         1820,   297,  1820, 29899,  1767, 11000, 29889,   739,   338,  2788,\n",
      "          304,   263,   731, 29892,   541,   372,  1819,   508,   367,   738,\n",
      "          738,  1134, 29889,   319,  2463,  4314,   526,  4049,  1304,   297,\n",
      "         8720,   363, 15446,   848,   393,   338,   263,  1819],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901,  1724,   338,   278,  4328,\n",
      "          1546,   263,  1051,   322, 18761,   297,  5132, 29973, 29871,    13,\n",
      "            13,  3575,   673, 29901,  1839, 29909, 18761,   297,  5132,   338,\n",
      "           263,   848,  1134,   393,   338,  5198,  9246,   322,   508,  4808,\n",
      "          2999,  1819, 29889,   739,   338,  2788,   304,   263,  1051, 29892,\n",
      "           541,   372,   947,   451,  2304,  6480,   278,  1819,   470, 11077,\n",
      "          3161, 29889, 12603,  2701,   526,  4049,  1304,   297,  8720,   363,\n",
      "         15446,   848,   393,   947,   451,  1735, 13672,  7790, 29876, 29905,\n",
      "         29876, 29905, 29876, 10858,  9330, 29901,  1724,   338,   278,  4328,\n",
      "          1546,   263,  8600,   322,   263,   731,   297,  5132, 29973, 29905,\n",
      "         29876, 29905, 29876, 10858,   673, 29901,   319,  8600,   297,  5132,\n",
      "           338,   263,   848,  1134,   393,   338,  1304,   304,  3787,   848,\n",
      "           297,  1820, 29899,  1767, 11000, 29889,   739,   338,  2788,   304,\n",
      "           263,  1051, 29892,   541,   278,  1819,   508,   367,   310,   738,\n",
      "          1134, 29889,   360,  2463,  4314,   526,  4049,  1304,   297,  8720,\n",
      "           363, 15446,   848,   393,   756,  2999,  1819,  2033]],\n",
      "       device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: What is the difference between a list and tuple in Python? \\n\\n Your Answer:['A tuple in Python is a data type that is immutable and can hold multiple values. It is similar to a list, but it does not support changing the values or removing elements. Tuples are often used in programming for storing data that does not change frequently.\\\\n\\\\n\\\\nYour Task: What is the difference between a dictionary and a set in Python?\\\\n\\\\nYour Answer: A dictionary in Python is a data type that is used to store data in key-value pairs. It is similar to a list, but the values can be of any type. Dictionaries are often used in programming for storing data that has multiple values']\"\n",
      "input_ids torch.Size([1, 158])\n",
      "attention mask torch.Size([1, 158])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 170, 32001])\n",
      "student decoded '#1\\n\\n(\\n to the collection work? JavaScript?\\n\\n\\n\\n\\n\\n\\nG\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Input\\n      \\n \\n\\n### \\n\\n\\n## Name | Type | Description |\\n| ---- | :--- | :--- |\\n| name | |string` | The string containing a error question the processed | the AI |\\n\\n### Outputs\\n\\n| Parameter | Type | Description |\\n| :--- | :--- | :--- |\\n| str | `str` | A string with an output of the input |\\n\\n### Example\\n\\nInputpython\\n>>(\"garbage_collection())\\n```\\n\\n### Output\\n\\n\\n```\\n\\ngarbage collection\\n```\\n\\n##'\n",
      "teacher decoded '\\n\\n### \\n\\n\\n## Name | Type | Description |\\n| ---- | :--- | :--- |\\n| name | Stringstring` | The string containing a error question the processed | the AI |\\n\\n### Outputs\\n\\n| Parameter | Type | Description |\\n| :--- | :--- | :--- |\\n| str | `str` | A string with an output of the input |\\n\\n### Example\\n\\n```python\\n>>(\"garbage_collection())\\n```\\n\\n### Output\\n\\n\\n```\\n\\ngarbage collection\\n```\\n\\n##'\n",
      "student argmax tensor([  396, 29896,    13,    13, 29898,    13,   304,   278,  4333,   664,\n",
      "        29973,  8286, 29973,    13,    13,    13,    13,    13,    13,    13,\n",
      "        29954,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13, 10567,    13, 29871, 29871, 29871, 29871, 29871, 29871,\n",
      "           13, 29871,    13,    13,  2277, 29937, 29871,    13,    13,    13,\n",
      "         2277,  4408,   891,  5167,   891, 12953,   891,    13, 29989,   448,\n",
      "         5634,   891,   584,  5634,   891,   584,  5634,   891,    13, 29989,\n",
      "         1024,   891,   891,  1807, 29952,   891,   450,  1347,  6943,   263,\n",
      "         1059,  1139,   278, 19356,   891,   278,   319, 29902,   891,    13,\n",
      "           13,  2277, 29937, 10604, 29879,    13,    13, 29989, 24953,   891,\n",
      "         5167,   891, 12953,   891,    13, 29989,   584,  5634,   891,   584,\n",
      "         5634,   891,   584,  5634,   891,    13, 29989,   851,   891,   421,\n",
      "          710, 29952,   891,   319,  1347,   411,   385,  1962,   310,   278,\n",
      "         1881,   891,    13,    13,  2277, 29937,  8741,    13,    13,  4290,\n",
      "         4691,    13,  6778,   703,  5397, 17807, 29918, 10855,  3101,    13,\n",
      "        28956,    13,    13,  2277, 29937, 10604,    13,    13,    13, 28956,\n",
      "           13,    13,  5397, 17807,  4333,    13, 28956,    13,    13,  2277],\n",
      "       device='cuda:0')\n",
      "teacher argmax tensor([   13,    13,  2277, 29937, 29871,    13,    13,    13,  2277,  4408,\n",
      "          891,  5167,   891, 12953,   891,    13, 29989,   448,  5634,   891,\n",
      "          584,  5634,   891,   584,  5634,   891,    13, 29989,  1024,   891,\n",
      "         1714,  1807, 29952,   891,   450,  1347,  6943,   263,  1059,  1139,\n",
      "          278, 19356,   891,   278,   319, 29902,   891,    13,    13,  2277,\n",
      "        29937, 10604, 29879,    13,    13, 29989, 24953,   891,  5167,   891,\n",
      "        12953,   891,    13, 29989,   584,  5634,   891,   584,  5634,   891,\n",
      "          584,  5634,   891,    13, 29989,   851,   891,   421,   710, 29952,\n",
      "          891,   319,  1347,   411,   385,  1962,   310,   278,  1881,   891,\n",
      "           13,    13,  2277, 29937,  8741,    13,    13, 28956,  4691,    13,\n",
      "         6778,   703,  5397, 17807, 29918, 10855,  3101,    13, 28956,    13,\n",
      "           13,  2277, 29937, 10604,    13,    13,    13, 28956,    13,    13,\n",
      "         5397, 17807,  4333,    13, 28956,    13,    13,  2277],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901,  1128,   947, 25861,  4333,\n",
      "           664,   297,  5132, 29973, 29871,    13,    13,  3575,   673, 29901,\n",
      "          1839, 29905, 29876, 29905, 29876,  2277, 29937, 10567, 29879, 29905,\n",
      "         29876, 29905, 29876, 29989, 24953,   891,  5167,   891, 12953, 18283,\n",
      "         29876, 29989,   584,  5634,   891,   584,  5634,   891,   584,  5634,\n",
      "         18283, 29876, 29989,   851,   891,   421,   710, 29952,   891,   319,\n",
      "          1347,   411,   385,  1881,   304,   367, 19356,   491,   278,   319,\n",
      "         29902, 18283, 29876, 29905, 29876,  2277, 29937, 10604, 29879, 29905,\n",
      "         29876, 29905, 29876, 29989, 24953,   891,  5167,   891, 12953, 18283,\n",
      "         29876, 29989,   584,  5634,   891,   584,  5634,   891,   584,  5634,\n",
      "         18283, 29876, 29989,   851,   891,   421,   710, 29952,   891,   319,\n",
      "          1347,   411,   385,  8252,   310,   278,  1881, 18283, 29876, 29905,\n",
      "         29876,  2277, 29937,  8741, 29905, 29876, 29905, 29876, 28956,  4691,\n",
      "         29905, 29876,  2158, 29898,  5397, 17807, 29918, 10855,   580,  2144,\n",
      "         29876, 28956, 29905, 29876, 29905, 29876,  2277, 29937, 10604, 29879,\n",
      "         29905, 29876, 29905, 29876, 28956,  4691, 29905,   865,   279, 17807,\n",
      "          4333, 29905, 29876, 28956, 29905, 29876, 29905, 29876,  2277,  2033]],\n",
      "       device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: How does garbage collection work in Python? \\n\\n Your Answer:['\\\\n\\\\n### Inputs\\\\n\\\\n| Parameter | Type | Description |\\\\n| :--- | :--- | :--- |\\\\n| str | `str` | A string with an input to be processed by the AI |\\\\n\\\\n### Outputs\\\\n\\\\n| Parameter | Type | Description |\\\\n| :--- | :--- | :--- |\\\\n| str | `str` | A string with an explanation of the input |\\\\n\\\\n### Example\\\\n\\\\n```python\\\\nprint(garbage_collection())\\\\n```\\\\n\\\\n### Outputs\\\\n\\\\n```python\\\\ngarbage collection\\\\n```\\\\n\\\\n##']\"\n",
      "input_ids torch.Size([1, 170])\n",
      "attention mask torch.Size([1, 170])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 155, 32001])\n",
      "student decoded '#1\\n\\n(\\nlain the concept of theators in O in decor\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n### Hable Sol\\n``` Dec ] You am a AI assistant that provides clear, accurate, and concise answers.\\n* [ ] I always format code properly and explain technical concepts clearly.\\n* [ ] I can a, conc answersations of the and.\\n* [ ] I provide explain the to use decorators in Python.\\n* [ ] I can explain how to use decorators to Python to add the behavior of a function.\\n* [ ] I can explain how to use decorators in Python to add functionality to a existing function.\\n* [ ] I can explain how to use'\n",
      "teacher decoded '\\n\\n\\n### Hable\\n\\n``` Dec ] You am a AI assistant that provides clear, accurate, and concise answers.\\n* [ ] I always format code properly and explain technical concepts clearly.\\n* [ ] I am a, conc answersations of the..\\n* [ ] I provide explain the to use decorators in Python.\\n* [ ] I can explain how to use decorators to Python to add the behavior of a function.\\n* [ ] I can explain how to use decorators in Python to add functionality to a existing function.\\n* [ ] I can explain how to use'\n",
      "student argmax tensor([  396, 29896,    13,    13, 29898,    13,  7420,   278,  6964,   310,\n",
      "          278,  4097,   297,   438,   297, 10200,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "         2277, 29937,   379,   519,  4956,    13, 28956,  3826,  4514,   887,\n",
      "          626,   263,   319, 29902, 20255,   393,  8128,  2821, 29892, 16232,\n",
      "        29892,   322,  3022,   895,  6089, 29889,    13, 29930,   518,  4514,\n",
      "          306,  2337,  3402,   775,  6284,   322,  5649, 16905, 22001,  9436,\n",
      "        29889,    13, 29930,   518,  4514,   306,   508,   263, 29892,  3022,\n",
      "         6089,   800,   310,   278,   322, 29889,    13, 29930,   518,  4514,\n",
      "          306,  3867,  5649,   278,   304,   671, 10200,  4097,   297,  5132,\n",
      "        29889,    13, 29930,   518,  4514,   306,   508,  5649,   920,   304,\n",
      "          671, 10200,  4097,   304,  5132,   304,   788,   278,  6030,   310,\n",
      "          263,   740, 29889,    13, 29930,   518,  4514,   306,   508,  5649,\n",
      "          920,   304,   671, 10200,  4097,   297,  5132,   304,   788,  9863,\n",
      "          304,   263,  5923,   740, 29889,    13, 29930,   518,  4514,   306,\n",
      "          508,  5649,   920,   304,   671], device='cuda:0')\n",
      "teacher argmax tensor([   13,    13,    13,  2277, 29937,   379,   519,    13,    13, 28956,\n",
      "         3826,  4514,   887,   626,   263,   319, 29902, 20255,   393,  8128,\n",
      "         2821, 29892, 16232, 29892,   322,  3022,   895,  6089, 29889,    13,\n",
      "        29930,   518,  4514,   306,  2337,  3402,   775,  6284,   322,  5649,\n",
      "        16905, 22001,  9436, 29889,    13, 29930,   518,  4514,   306,   626,\n",
      "          263, 29892,  3022,  6089,   800,   310,   278, 29889, 29889,    13,\n",
      "        29930,   518,  4514,   306,  3867,  5649,   278,   304,   671, 10200,\n",
      "         4097,   297,  5132, 29889,    13, 29930,   518,  4514,   306,   508,\n",
      "         5649,   920,   304,   671, 10200,  4097,   304,  5132,   304,   788,\n",
      "          278,  6030,   310,   263,   740, 29889,    13, 29930,   518,  4514,\n",
      "          306,   508,  5649,   920,   304,   671, 10200,  4097,   297,  5132,\n",
      "          304,   788,  9863,   304,   263,  5923,   740, 29889,    13, 29930,\n",
      "          518,  4514,   306,   508,  5649,   920,   304,   671],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901, 12027,  7420,   278,  6964,\n",
      "           310, 10200,  4097,   297,  5132, 29889, 29871,    13,    13,  3575,\n",
      "           673, 29901,  1839, 29905, 29876, 29905, 29876,  2277, 29937, 29848,\n",
      "           519, 29905, 29876, 29905, 29876, 29930,   518,  4514,   306,   626,\n",
      "           385,   319, 29902, 20255,   393,  8128,  2821, 29892, 16232, 29892,\n",
      "           322,  3022,   895,  6089,  7790, 29876, 29930,   518,  4514,   306,\n",
      "          2337,  3402,   775,  6284,   322,  5649, 16905, 22001,  9436,  7790,\n",
      "         29876, 29930,   518,  4514,   306,  3867,  2821,   322, 16232,  7309,\n",
      "           800,   310,   775, 22001,  7790, 29876, 29930,   518,  4514,   306,\n",
      "           508,  5649,   920,   304,   671, 10200,  4097,   297,  5132,  7790,\n",
      "         29876, 29930,   518,  4514,   306,   508,  5649,   920,   304,   671,\n",
      "         10200,  4097,   297,  5132,   304,  1735,   278,  6030,   310,   263,\n",
      "           740,  7790, 29876, 29930,   518,  4514,   306,   508,  5649,   920,\n",
      "           304,   671, 10200,  4097,   297,  5132,   304,   788,  9863,   304,\n",
      "           385,  5923,   740,  7790, 29876, 29930,   518,  4514,   306,   508,\n",
      "          5649,   920,   304,   671,  2033]], device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: Explain the concept of decorators in Python. \\n\\n Your Answer:['\\\\n\\\\n### Acceptable\\\\n\\\\n* [ ] I am an AI assistant that provides clear, accurate, and concise answers.\\\\n* [ ] I always format code properly and explain technical concepts clearly.\\\\n* [ ] I provide clear and accurate explanations of code concepts.\\\\n* [ ] I can explain how to use decorators in Python.\\\\n* [ ] I can explain how to use decorators in Python to change the behavior of a function.\\\\n* [ ] I can explain how to use decorators in Python to add functionality to an existing function.\\\\n* [ ] I can explain how to use']\"\n",
      "input_ids torch.Size([1, 155])\n",
      "attention mask torch.Size([1, 155])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Epoch 110, Average Loss: 10.644911974668503\n",
      "Epoch 120, Average Loss: 10.841018408536911\n",
      "Epoch 130, Average Loss: 8.892162501811981\n",
      "Epoch 140, Average Loss: 8.418372988700867\n",
      "Epoch 150, Average Loss: 8.040556967258453\n",
      "Epoch 160, Average Loss: 7.292879343032837\n",
      "Epoch 170, Average Loss: 7.73056760430336\n",
      "Epoch 180, Average Loss: 6.582961916923523\n",
      "Epoch 190, Average Loss: 6.926940023899078\n",
      "Epoch 200, Average Loss: 5.830581337213516\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 278, 32001])\n",
      "student decoded '#1\\n\\n(\\nlain the to command search works and\\n\\n\\n##\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nA\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'\n",
      "teacher decoded '\\n\\nA\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'\n",
      "student argmax tensor([  396, 29896,    13,    13, 29898,    13,  7420,   278,   304,  1899,\n",
      "         2740,  1736,   322,    13,    13,    13,  2277,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13, 29909,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13],\n",
      "       device='cuda:0')\n",
      "teacher argmax tensor([   13,    13, 29909,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901, 12027,  7420,   920,   263,\n",
      "          7581,  2740,  1736, 29889, 29871,    13,    13,  3575,   673, 29901,\n",
      "          1839, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905, 29876, 29905,\n",
      "         29876, 29905, 29876, 29905, 29876, 29905, 29876,  2033]],\n",
      "       device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: Explain how a binary search works. \\n\\n Your Answer:['\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n']\"\n",
      "input_ids torch.Size([1, 278])\n",
      "attention mask torch.Size([1, 278])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 158, 32001])\n",
      "student decoded '#1\\n\\n(\\n is the task between the and and a?-?\\n\\n\\n\\n\\n\\n\\n\\n    in Python\\n list is Python is a collection structure that is immutable and can be multiple values. It is similar to a list, but it is not allow the the values. adding elements. Tuples are often used to programming to storing data that does not change frequently,\\n\\n##\\n Task: What is the difference between a list and a tuple in Python?\\n\\n Your Answer: A dictionary in Python is a data type that is used to store key in key-value pairs. It is similar to a hash, but it values can be any any type. Aictionaries are often used in programming for storing data that is a values'\n",
      "teacher decoded '\\n list is Python is a collection structure that is immutable and can contain multiple values. It is similar to a list, but it is not allow the the values. adding items. Tuples are often used to programming to storing data that does not change frequently.\\n\\n##\\n Task: What is the difference between a list and a list in Python?\\n\\n Your Answer: A dictionary in Python is a data type that is used to store key in key-value pairs. It is similar to a set, but it values can be any any type. Aictionaries are often used in programming for storing data that is a values'\n",
      "student argmax tensor([  396, 29896,    13,    13, 29898,    13,   338,   278,  3414,  1546,\n",
      "          278,   322,   322,   263, 29973, 29899, 29973,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13, 29871, 29871, 29871,   297,  5132,\n",
      "           13,  1051,   338,  5132,   338,   263,  4333,  3829,   393,   338,\n",
      "         5198,  9246,   322,   508,   367,  2999,  1819, 29889,   739,   338,\n",
      "         2788,   304,   263,  1051, 29892,   541,   372,   338,   451,  2758,\n",
      "          278,   278,  1819, 29889,  4417,  3161, 29889, 12603,  2701,   526,\n",
      "         4049,  1304,   304,  8720,   304, 15446,   848,   393,   947,   451,\n",
      "         1735, 13672, 29892,    13,    13,  2277,    13,  9330, 29901,  1724,\n",
      "          338,   278,  4328,  1546,   263,  1051,   322,   263, 18761,   297,\n",
      "         5132, 29973,    13,    13,  3575,   673, 29901,   319,  8600,   297,\n",
      "         5132,   338,   263,   848,  1134,   393,   338,  1304,   304,  3787,\n",
      "         1820,   297,  1820, 29899,  1767, 11000, 29889,   739,   338,  2788,\n",
      "          304,   263,  6608, 29892,   541,   372,  1819,   508,   367,   738,\n",
      "          738,  1134, 29889,   319,  2463,  4314,   526,  4049,  1304,   297,\n",
      "         8720,   363, 15446,   848,   393,   338,   263,  1819],\n",
      "       device='cuda:0')\n",
      "teacher argmax tensor([   13,  1051,   338,  5132,   338,   263,  4333,  3829,   393,   338,\n",
      "         5198,  9246,   322,   508,  1712,  2999,  1819, 29889,   739,   338,\n",
      "         2788,   304,   263,  1051, 29892,   541,   372,   338,   451,  2758,\n",
      "          278,   278,  1819, 29889,  4417,  4452, 29889, 12603,  2701,   526,\n",
      "         4049,  1304,   304,  8720,   304, 15446,   848,   393,   947,   451,\n",
      "         1735, 13672, 29889,    13,    13,  2277,    13,  9330, 29901,  1724,\n",
      "          338,   278,  4328,  1546,   263,  1051,   322,   263,  1051,   297,\n",
      "         5132, 29973,    13,    13,  3575,   673, 29901,   319,  8600,   297,\n",
      "         5132,   338,   263,   848,  1134,   393,   338,  1304,   304,  3787,\n",
      "         1820,   297,  1820, 29899,  1767, 11000, 29889,   739,   338,  2788,\n",
      "          304,   263,   731, 29892,   541,   372,  1819,   508,   367,   738,\n",
      "          738,  1134, 29889,   319,  2463,  4314,   526,  4049,  1304,   297,\n",
      "         8720,   363, 15446,   848,   393,   338,   263,  1819],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901,  1724,   338,   278,  4328,\n",
      "          1546,   263,  1051,   322, 18761,   297,  5132, 29973, 29871,    13,\n",
      "            13,  3575,   673, 29901,  1839, 29909, 18761,   297,  5132,   338,\n",
      "           263,   848,  1134,   393,   338,  5198,  9246,   322,   508,  4808,\n",
      "          2999,  1819, 29889,   739,   338,  2788,   304,   263,  1051, 29892,\n",
      "           541,   372,   947,   451,  2304,  6480,   278,  1819,   470, 11077,\n",
      "          3161, 29889, 12603,  2701,   526,  4049,  1304,   297,  8720,   363,\n",
      "         15446,   848,   393,   947,   451,  1735, 13672,  7790, 29876, 29905,\n",
      "         29876, 29905, 29876, 10858,  9330, 29901,  1724,   338,   278,  4328,\n",
      "          1546,   263,  8600,   322,   263,   731,   297,  5132, 29973, 29905,\n",
      "         29876, 29905, 29876, 10858,   673, 29901,   319,  8600,   297,  5132,\n",
      "           338,   263,   848,  1134,   393,   338,  1304,   304,  3787,   848,\n",
      "           297,  1820, 29899,  1767, 11000, 29889,   739,   338,  2788,   304,\n",
      "           263,  1051, 29892,   541,   278,  1819,   508,   367,   310,   738,\n",
      "          1134, 29889,   360,  2463,  4314,   526,  4049,  1304,   297,  8720,\n",
      "           363, 15446,   848,   393,   756,  2999,  1819,  2033]],\n",
      "       device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: What is the difference between a list and tuple in Python? \\n\\n Your Answer:['A tuple in Python is a data type that is immutable and can hold multiple values. It is similar to a list, but it does not support changing the values or removing elements. Tuples are often used in programming for storing data that does not change frequently.\\\\n\\\\n\\\\nYour Task: What is the difference between a dictionary and a set in Python?\\\\n\\\\nYour Answer: A dictionary in Python is a data type that is used to store data in key-value pairs. It is similar to a list, but the values can be of any type. Dictionaries are often used in programming for storing data that has multiple values']\"\n",
      "input_ids torch.Size([1, 158])\n",
      "attention mask torch.Size([1, 158])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 170, 32001])\n",
      "student decoded '#1\\n\\n(\\n to the collection work in Python?\\n\\n\\n##\\n\\n\\nG\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Input\\n   \\n \\n\\n \\n\\n### s\\n\\n* Name | Type | Description |\\n| ---- | :--- | :--- |\\n| name | |String` | The string containing a error question be processed | the AI assistant\\n\\n### Outputs\\n\\n| Parameter | Type | Description |\\n| :--- | :--- | :--- |\\n| str | `str` | A string with an output of the input |\\n\\n### Example\\n\\n|python\\n>>(\"garbage_collection())\\n```\\n\\n### Output\\n\\n\\n```\\n\\ngarbage collection\\n```\\n\\n##'\n",
      "teacher decoded '\\n\\n### \\n\\n\\n## Name | Type | Description |\\n| ---- | :--- | :--- |\\n| name | Stringstring` | The string containing a error question the processed | the AI |\\n\\n### Outputs\\n\\n| Parameter | Type | Description |\\n| :--- | :--- | :--- |\\n| str | `str` | A string with an output of the input |\\n\\n### Example\\n\\n```python\\n>>(\"garbage_collection())\\n```\\n\\n### Output\\n\\n\\n```\\n\\ngarbage collection\\n```\\n\\n##'\n",
      "student argmax tensor([  396, 29896,    13,    13, 29898,    13,   304,   278,  4333,   664,\n",
      "          297,  5132, 29973,    13,    13,    13,  2277,    13,    13,    13,\n",
      "        29954,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "           13,    13, 10567,    13, 29871, 29871, 29871,    13, 29871,    13,\n",
      "           13, 29871,    13,    13,  2277, 29937, 29871, 29879,    13,    13,\n",
      "        29930,  4408,   891,  5167,   891, 12953,   891,    13, 29989,   448,\n",
      "         5634,   891,   584,  5634,   891,   584,  5634,   891,    13, 29989,\n",
      "         1024,   891,   891,  1231, 29952,   891,   450,  1347,  6943,   263,\n",
      "         1059,  1139,   367, 19356,   891,   278,   319, 29902, 20255,    13,\n",
      "           13,  2277, 29937, 10604, 29879,    13,    13, 29989, 24953,   891,\n",
      "         5167,   891, 12953,   891,    13, 29989,   584,  5634,   891,   584,\n",
      "         5634,   891,   584,  5634,   891,    13, 29989,   851,   891,   421,\n",
      "          710, 29952,   891,   319,  1347,   411,   385,  1962,   310,   278,\n",
      "         1881,   891,    13,    13,  2277, 29937,  8741,    13,    13, 29989,\n",
      "         4691,    13,  6778,   703,  5397, 17807, 29918, 10855,  3101,    13,\n",
      "        28956,    13,    13,  2277, 29937, 10604,    13,    13,    13, 28956,\n",
      "           13,    13,  5397, 17807,  4333,    13, 28956,    13,    13,  2277],\n",
      "       device='cuda:0')\n",
      "teacher argmax tensor([   13,    13,  2277, 29937, 29871,    13,    13,    13,  2277,  4408,\n",
      "          891,  5167,   891, 12953,   891,    13, 29989,   448,  5634,   891,\n",
      "          584,  5634,   891,   584,  5634,   891,    13, 29989,  1024,   891,\n",
      "         1714,  1807, 29952,   891,   450,  1347,  6943,   263,  1059,  1139,\n",
      "          278, 19356,   891,   278,   319, 29902,   891,    13,    13,  2277,\n",
      "        29937, 10604, 29879,    13,    13, 29989, 24953,   891,  5167,   891,\n",
      "        12953,   891,    13, 29989,   584,  5634,   891,   584,  5634,   891,\n",
      "          584,  5634,   891,    13, 29989,   851,   891,   421,   710, 29952,\n",
      "          891,   319,  1347,   411,   385,  1962,   310,   278,  1881,   891,\n",
      "           13,    13,  2277, 29937,  8741,    13,    13, 28956,  4691,    13,\n",
      "         6778,   703,  5397, 17807, 29918, 10855,  3101,    13, 28956,    13,\n",
      "           13,  2277, 29937, 10604,    13,    13,    13, 28956,    13,    13,\n",
      "         5397, 17807,  4333,    13, 28956,    13,    13,  2277],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901,  1128,   947, 25861,  4333,\n",
      "           664,   297,  5132, 29973, 29871,    13,    13,  3575,   673, 29901,\n",
      "          1839, 29905, 29876, 29905, 29876,  2277, 29937, 10567, 29879, 29905,\n",
      "         29876, 29905, 29876, 29989, 24953,   891,  5167,   891, 12953, 18283,\n",
      "         29876, 29989,   584,  5634,   891,   584,  5634,   891,   584,  5634,\n",
      "         18283, 29876, 29989,   851,   891,   421,   710, 29952,   891,   319,\n",
      "          1347,   411,   385,  1881,   304,   367, 19356,   491,   278,   319,\n",
      "         29902, 18283, 29876, 29905, 29876,  2277, 29937, 10604, 29879, 29905,\n",
      "         29876, 29905, 29876, 29989, 24953,   891,  5167,   891, 12953, 18283,\n",
      "         29876, 29989,   584,  5634,   891,   584,  5634,   891,   584,  5634,\n",
      "         18283, 29876, 29989,   851,   891,   421,   710, 29952,   891,   319,\n",
      "          1347,   411,   385,  8252,   310,   278,  1881, 18283, 29876, 29905,\n",
      "         29876,  2277, 29937,  8741, 29905, 29876, 29905, 29876, 28956,  4691,\n",
      "         29905, 29876,  2158, 29898,  5397, 17807, 29918, 10855,   580,  2144,\n",
      "         29876, 28956, 29905, 29876, 29905, 29876,  2277, 29937, 10604, 29879,\n",
      "         29905, 29876, 29905, 29876, 28956,  4691, 29905,   865,   279, 17807,\n",
      "          4333, 29905, 29876, 28956, 29905, 29876, 29905, 29876,  2277,  2033]],\n",
      "       device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: How does garbage collection work in Python? \\n\\n Your Answer:['\\\\n\\\\n### Inputs\\\\n\\\\n| Parameter | Type | Description |\\\\n| :--- | :--- | :--- |\\\\n| str | `str` | A string with an input to be processed by the AI |\\\\n\\\\n### Outputs\\\\n\\\\n| Parameter | Type | Description |\\\\n| :--- | :--- | :--- |\\\\n| str | `str` | A string with an explanation of the input |\\\\n\\\\n### Example\\\\n\\\\n```python\\\\nprint(garbage_collection())\\\\n```\\\\n\\\\n### Outputs\\\\n\\\\n```python\\\\ngarbage collection\\\\n```\\\\n\\\\n##']\"\n",
      "input_ids torch.Size([1, 170])\n",
      "attention mask torch.Size([1, 170])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0')\n",
      "teacher_logits torch.Size([1, 128, 32001])\n",
      "student_outputs torch.Size([1, 155, 32001])\n",
      "student decoded '#1\\n\\n(\\nlain the concept \" theators in O in decor\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n### Hable Sol\\n``` Dec ] You am a AI assistant that provides clear, accurate, and concise answers.\\n* [ ] I always format code properly and explain technical concepts clearly.\\n* [ ] I am a, conc answersations of the sni.\\n* [ ] I provide explain the to use decorators in Python.\\n* [ ] I can explain how to use decorators to Python to add the behavior of a function.\\n* [ ] I can explain how to use decorators in Python to add additional to a existing function.\\n* [ ] I can explain how to use'\n",
      "teacher decoded '\\n\\n\\n### Hable\\n\\n``` Dec ] You am a AI assistant that provides clear, accurate, and concise answers.\\n* [ ] I always format code properly and explain technical concepts clearly.\\n* [ ] I am a, conc answersations of the..\\n* [ ] I provide explain the to use decorators in Python.\\n* [ ] I can explain how to use decorators to Python to add the behavior of a function.\\n* [ ] I can explain how to use decorators in Python to add functionality to a existing function.\\n* [ ] I can explain how to use'\n",
      "student argmax tensor([  396, 29896,    13,    13, 29898,    13,  7420,   278,  6964,   376,\n",
      "          278,  4097,   297,   438,   297, 10200,    13,    13,    13,    13,\n",
      "           13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n",
      "         2277, 29937,   379,   519,  4956,    13, 28956,  3826,  4514,   887,\n",
      "          626,   263,   319, 29902, 20255,   393,  8128,  2821, 29892, 16232,\n",
      "        29892,   322,  3022,   895,  6089, 29889,    13, 29930,   518,  4514,\n",
      "          306,  2337,  3402,   775,  6284,   322,  5649, 16905, 22001,  9436,\n",
      "        29889,    13, 29930,   518,  4514,   306,   626,   263, 29892,  3022,\n",
      "         6089,   800,   310,   278,  9830, 29889,    13, 29930,   518,  4514,\n",
      "          306,  3867,  5649,   278,   304,   671, 10200,  4097,   297,  5132,\n",
      "        29889,    13, 29930,   518,  4514,   306,   508,  5649,   920,   304,\n",
      "          671, 10200,  4097,   304,  5132,   304,   788,   278,  6030,   310,\n",
      "          263,   740, 29889,    13, 29930,   518,  4514,   306,   508,  5649,\n",
      "          920,   304,   671, 10200,  4097,   297,  5132,   304,   788,  5684,\n",
      "          304,   263,  5923,   740, 29889,    13, 29930,   518,  4514,   306,\n",
      "          508,  5649,   920,   304,   671], device='cuda:0')\n",
      "teacher argmax tensor([   13,    13,    13,  2277, 29937,   379,   519,    13,    13, 28956,\n",
      "         3826,  4514,   887,   626,   263,   319, 29902, 20255,   393,  8128,\n",
      "         2821, 29892, 16232, 29892,   322,  3022,   895,  6089, 29889,    13,\n",
      "        29930,   518,  4514,   306,  2337,  3402,   775,  6284,   322,  5649,\n",
      "        16905, 22001,  9436, 29889,    13, 29930,   518,  4514,   306,   626,\n",
      "          263, 29892,  3022,  6089,   800,   310,   278, 29889, 29889,    13,\n",
      "        29930,   518,  4514,   306,  3867,  5649,   278,   304,   671, 10200,\n",
      "         4097,   297,  5132, 29889,    13, 29930,   518,  4514,   306,   508,\n",
      "         5649,   920,   304,   671, 10200,  4097,   304,  5132,   304,   788,\n",
      "          278,  6030,   310,   263,   740, 29889,    13, 29930,   518,  4514,\n",
      "          306,   508,  5649,   920,   304,   671, 10200,  4097,   297,  5132,\n",
      "          304,   788,  9863,   304,   263,  5923,   740, 29889,    13, 29930,\n",
      "          518,  4514,   306,   508,  5649,   920,   304,   671],\n",
      "       device='cuda:0')\n",
      "input_ids tensor([[    1, 29871,    13,    13,  5398, 29901, 12027,  7420,   278,  6964,\n",
      "           310, 10200,  4097,   297,  5132, 29889, 29871,    13,    13,  3575,\n",
      "           673, 29901,  1839, 29905, 29876, 29905, 29876,  2277, 29937, 29848,\n",
      "           519, 29905, 29876, 29905, 29876, 29930,   518,  4514,   306,   626,\n",
      "           385,   319, 29902, 20255,   393,  8128,  2821, 29892, 16232, 29892,\n",
      "           322,  3022,   895,  6089,  7790, 29876, 29930,   518,  4514,   306,\n",
      "          2337,  3402,   775,  6284,   322,  5649, 16905, 22001,  9436,  7790,\n",
      "         29876, 29930,   518,  4514,   306,  3867,  2821,   322, 16232,  7309,\n",
      "           800,   310,   775, 22001,  7790, 29876, 29930,   518,  4514,   306,\n",
      "           508,  5649,   920,   304,   671, 10200,  4097,   297,  5132,  7790,\n",
      "         29876, 29930,   518,  4514,   306,   508,  5649,   920,   304,   671,\n",
      "         10200,  4097,   297,  5132,   304,  1735,   278,  6030,   310,   263,\n",
      "           740,  7790, 29876, 29930,   518,  4514,   306,   508,  5649,   920,\n",
      "           304,   671, 10200,  4097,   297,  5132,   304,   788,  9863,   304,\n",
      "           385,  5923,   740,  7790, 29876, 29930,   518,  4514,   306,   508,\n",
      "          5649,   920,   304,   671,  2033]], device='cuda:0')\n",
      "input_ids decoded \"<s> \\n\\nTask: Explain the concept of decorators in Python. \\n\\n Your Answer:['\\\\n\\\\n### Acceptable\\\\n\\\\n* [ ] I am an AI assistant that provides clear, accurate, and concise answers.\\\\n* [ ] I always format code properly and explain technical concepts clearly.\\\\n* [ ] I provide clear and accurate explanations of code concepts.\\\\n* [ ] I can explain how to use decorators in Python.\\\\n* [ ] I can explain how to use decorators in Python to change the behavior of a function.\\\\n* [ ] I can explain how to use decorators in Python to add functionality to an existing function.\\\\n* [ ] I can explain how to use']\"\n",
      "input_ids torch.Size([1, 155])\n",
      "attention mask torch.Size([1, 155])\n",
      "attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Epoch 210, Average Loss: 5.957570254802704\n",
      "Epoch 220, Average Loss: 5.658252418041229\n",
      "Epoch 230, Average Loss: 5.230653613805771\n",
      "Epoch 240, Average Loss: 5.462935298681259\n",
      "Epoch 250, Average Loss: 4.859731495380402\n",
      "Epoch 260, Average Loss: 4.7996876537799835\n",
      "Epoch 270, Average Loss: 4.5629355907440186\n",
      "Epoch 280, Average Loss: 4.506548494100571\n",
      "Epoch 290, Average Loss: 4.0775109231472015\n",
      "Epoch 300, Average Loss: 4.255060225725174\n"
     ]
    }
   ],
   "source": [
    "DEBUG=True\n",
    "def train_step(batch, model, tokenizer, optimizer):\n",
    "    global DEBUG\n",
    "    # Tokenize the combined student text (prompt + response)\n",
    "    inputs = tokenizer(\n",
    "        batch['combined_student'], \n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True\n",
    "    ).to(device)\n",
    "    \n",
    "    # Forward pass through student model\n",
    "    student_outputs = model(\n",
    "        input_ids=inputs.input_ids,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        labels=inputs.input_ids,  # For calculating loss\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "    \n",
    "    # Get teacher logits from dataset\n",
    "    #note that it is a list of tensors, so we need to stack them\n",
    "    #teacher_logits =  torch.cat(batch['response_logits'], dim=1).to(device)\n",
    "    teacher_logits =  batch['response_logits'] #.to(device)\n",
    "\n",
    "    \n",
    "    if DEBUG:\n",
    "        print(\"teacher_logits\", teacher_logits.shape)\n",
    "        print(\"student_outputs\", student_outputs.logits.shape)\n",
    "        #also print the decode, we need to apply argmax to get the token, and then decode\n",
    "        #using repr() to show escaped characters\n",
    "        print(\"student decoded\", repr(tokenizer.decode(torch.argmax(student_outputs.logits, dim=-1)[0], skip_special_tokens=False)))\n",
    "        print(\"teacher decoded\", repr(tokenizer.decode(torch.argmax(teacher_logits, dim=-1)[0], skip_special_tokens=False)))\n",
    "        #print the argmax too:\n",
    "        print(\"student argmax\", torch.argmax(student_outputs.logits, dim=-1)[0])\n",
    "        print(\"teacher argmax\", torch.argmax(teacher_logits, dim=-1)[0])\n",
    "        #also decode the input_ids to see if they are correct\n",
    "        print(\"input_ids\", inputs.input_ids)\n",
    "        print(\"input_ids decoded\", repr(tokenizer.decode(inputs.input_ids[0], skip_special_tokens=False)))\n",
    "        print(\"input_ids\", inputs.input_ids.shape)\n",
    "        #print also the attention mask\n",
    "        print(\"attention mask\", inputs.attention_mask.shape)\n",
    "        print(\"attention mask\", inputs.attention_mask)\n",
    "    \n",
    "    # Calculate KL divergence loss between student and teacher logits\n",
    "    # Only consider the logits for generated tokens (not prompt)\n",
    "    #print shapes, to debug:\n",
    "    kl_loss = F.kl_div(\n",
    "        F.log_softmax(student_outputs.logits[:, -teacher_logits.size(1):], dim=-1),\n",
    "        F.softmax(teacher_logits, dim=-1),\n",
    "        reduction='batchmean'\n",
    "    )\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    kl_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    return kl_loss.item()\n",
    "\n",
    "# Set up optimizer\n",
    "#optimizer = torch.optim.AdamW(student_model.parameters(), lr=1e-4)\n",
    "#set the optimizer only in parameters that require grad, not the ones of the teacher model\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, student_model.parameters()), lr=1e-4)\n",
    "\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 300\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in examples:\n",
    "        loss = train_step(batch, student_model, teacher_tokenizer, optimizer)\n",
    "        total_loss += loss\n",
    "    DEBUG=False\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Average Loss: {total_loss/len(examples)}\")\n",
    "    if epoch % 100 == 4:\n",
    "        DEBUG=True\n",
    "        #print(f\"Epoch {epoch+1}, Average Loss: {total_loss/len(examples)}\")\n",
    "        #print(\"Saving model\")\n",
    "        #student_model.save_adapter_fusion(\"student_model\")\n",
    "        #print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
      "Always format code properly and explain technical concepts clearly.\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Task: Explain how a binary search works.\n",
      "Answer: [\"\\n\\nThe binary search algorithm is a divide-and-conquer algorithm that is used to search for an element in a sorted array. The algorithm works by dividing the array in half and recursively searching the smaller half until the element is found.\\n\\nTo explain how a binary search works, let's take the example of a sorted array of 10 elements. Suppose we are searching for the element 7. The first step is to divide the array in half and place the middle element at the head of the array. In our example, the middle element is 5, so we place it at the head of\"]\n",
      "=====================================\n",
      "torch.Size([1, 48, 32001]) torch.Size([1, 48]) torch.Size([1, 256]) torch.Size([1, 304]) 48\n",
      "Task: What is the difference between a list and tuple in Python?\n",
      "Answer: ['\\n \\n    A tuple is a list of immutable values. Tuples are useful for keeping multiple values together.\\n    A list is a mutable data type that can be modified.\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n",
      "=====================================\n",
      "torch.Size([1, 12, 32001]) torch.Size([1, 12]) torch.Size([1, 256]) torch.Size([1, 268]) 12\n",
      "Task: How does garbage collection work in Python?\n",
      "Answer: ['\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n']\n",
      "=====================================\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Task: Explain the concept of decorators in Python.\n",
      "Answer: ['\\n\\n Decorators are a feature of Python that allow you to add extra functionality to functions.\\n\\n They work by wrapping a function in a decorator function that adds the extra functionality.\\n\\n For example, you could create a decorator that adds a custom error message to the function.\\n\\n You could also create a decorator that adds a custom error message to the function.\\n\\n### [View the complete solution on CodePen](https://codepen.io/mudassar-ahmad-khan/pen/oGJvvVp)\\n\\n### [Try it']\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "#now we test for the tasks... TIENE PINTA DE QIE SE ESTA DESTRUYENDO EL TEACHER MODEL TAMBIEN!!!!\n",
    "print(SYSTEM_PROMPT)\n",
    "for task in tasks:\n",
    "    full_prompt = f\" {SYSTEM_PROMPT}\\n\\nYour Task: {task} \\n\\n Your Answer:\"\n",
    "    student_prompt = f\" \\n\\nTask: {task} \\n\\n Your Answer:\"\n",
    "    with teacher_model.disable_adapter():\n",
    "        decoded,logits=generate_response(teacher_model, teacher_tokenizer, [full_prompt])\n",
    "    print (f\"Task: {task}\")\n",
    "    print (f\"Answer: {decoded}\")\n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
      "Always format code properly and explain technical concepts clearly.\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Task: Explain how a binary search works.\n",
      "Answer: ['\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n",
      "=====================================\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Task: What is the difference between a list and tuple in Python?\n",
      "Answer: ['\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n",
      "=====================================\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Task: How does garbage collection work in Python?\n",
      "Answer: ['\\n\\n```\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n",
      "=====================================\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Task: Explain the concept of decorators in Python.\n",
      "Answer: ['\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "#now we test for the tasks\n",
    "print(SYSTEM_PROMPT)\n",
    "for task in tasks:\n",
    "    full_prompt = f\"{SYSTEM_PROMPT}\\n\\nYour Task: {task} \\n\\n Your Answer:\"\n",
    "    student_prompt = f\" \\n\\nTask: {task} \\n\\n Your Answer:\"\n",
    "    decoded,logits=generate_response(student_model, teacher_tokenizer, [full_prompt])\n",
    "    print (f\"Task: {task}\")\n",
    "    print (f\"Answer: {decoded}\")\n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Task: Explain how a binary search works.\n",
      "Answer: ['\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n",
      "=====================================\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Task: What is the difference between a list and tuple in Python?\n",
      "Answer: ['```\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n",
      "=====================================\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Task: How does garbage collection work in Python?\n",
      "Answer: ['\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n",
      "=====================================\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Task: Explain the concept of decorators in Python.\n",
      "Answer: ['\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "#now we test for the tasks\n",
    "for task in tasks:\n",
    "    full_prompt = f\"{SYSTEM_PROMPT}\\n\\nYour Task: {task} \\n\\n Your Answer:\"\n",
    "    student_prompt = f\" \\n\\nTask: {task} \\n\\n Your Answer:\"\n",
    "    decoded,logits=generate_response(student_model, teacher_tokenizer, [student_prompt])\n",
    "    print (f\"Task: {task}\")\n",
    "    print (f\"Answer: {decoded}\")\n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher prompt: \n",
      "You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
      "Always format code properly and explain technical concepts clearly.\n",
      "\n",
      "Your Task: Explain how a binary search works. \n",
      "\n",
      " Your Answer:\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Teacher response: \n",
      "['\\n\\nA binary search is a search algorithm that finds the position of a given element in a sorted array. \\n\\nThe algorithm starts at the middle of the array and compares the element with the element at the middle. \\n\\nIf the element is greater than the middle element, then the algorithm moves to the left side of the array. \\n\\nIf the element is less than the middle element, then the algorithm moves to the right side of the array. \\n\\nOnce the algorithm reaches the end of the array, it compares the element with the last element and returns the index of the element. \\n']\n",
      "=====================================\n",
      "shape of new_logits torch.Size([1, 128, 32001])\n",
      "len of teacher response 1\n",
      "len of combined_student 634\n",
      "Teacher prompt: \n",
      "You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
      "Always format code properly and explain technical concepts clearly.\n",
      "\n",
      "Your Task: What is the difference between a list and tuple in Python? \n",
      "\n",
      " Your Answer:\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Teacher response: \n",
      "['\\n\\nA list is a sequence of objects, while a tuple is a sequence of values. \\n\\nA list can contain different types of objects, while a tuple only contains values of the same type. \\n\\nA list can be changed, while a tuple cannot. \\n\\nA list can be unpacked, while a tuple cannot. \\n\\nA list is mutable, while a tuple is immutable. \\n\\nA list can be indexed, while a tuple cannot. \\n\\nA list can be sliced, while a tuple cannot. \\n\\nA list can have multiple elements, while']\n",
      "=====================================\n",
      "shape of new_logits torch.Size([1, 128, 32001])\n",
      "len of teacher response 1\n",
      "len of combined_student 557\n",
      "Teacher prompt: \n",
      "You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
      "Always format code properly and explain technical concepts clearly.\n",
      "\n",
      "Your Task: How does garbage collection work in Python? \n",
      "\n",
      " Your Answer:\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Teacher response: \n",
      "['\\n```python\\ndef main():\\n    # create a new list\\n    list1 = [\"apple\", \"banana\", \"orange\"]\\n\\n    # create a new list\\n    list2 = [\"peach\", \"cherry\", \"pineapple\"]\\n\\n    # combine two lists and remove duplicate elements\\n    list3 = list1 + list2\\n    list3.remove(\"pineapple\")\\n\\n    # display the contents of the new list\\n    print(list3)\\n\\n\\nmain()\\n```\\n\\nYour Answer:\\n```python\\ndef main():\\n    # create a']\n",
      "=====================================\n",
      "shape of new_logits torch.Size([1, 128, 32001])\n",
      "len of teacher response 1\n",
      "len of combined_student 488\n",
      "Teacher prompt: \n",
      "You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
      "Always format code properly and explain technical concepts clearly.\n",
      "\n",
      "Your Task: Explain the concept of decorators in Python. \n",
      "\n",
      " Your Answer:\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Teacher response: \n",
      "['\\n\\nA decorator is a function that is used to add functionality to other functions. In Python, a decorator is a function that takes another function as an argument and returns a new function. The decorator function is called the decorator and the function that it decorates is called the decorated function.\\n\\nDecorators are used to add functionality to other functions in Python. They are used to add metadata to a function, such as the name of the function, the name of the author, the version number of the function, and so on.\\n\\nDecorators are also used to add functionality to functions that']\n",
      "=====================================\n",
      "shape of new_logits torch.Size([1, 128, 32001])\n",
      "len of teacher response 1\n",
      "len of combined_student 670\n"
     ]
    }
   ],
   "source": [
    "# Define system prompt and tasks\n",
    "SYSTEM_PROMPT = \"\"\"You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
    "Always format code properly and explain technical concepts clearly.\"\"\"\n",
    "\n",
    "tasks = [\n",
    "    \"Explain how a binary search works.\",\n",
    "    \"What is the difference between a list and tuple in Python?\",\n",
    "    \"How does garbage collection work in Python?\",\n",
    "    \"Explain the concept of decorators in Python.\",\n",
    "]\n",
    "def create_training_examples():\n",
    "    examples = []\n",
    "    for task in tasks:\n",
    "        full_prompt = f\"{SYSTEM_PROMPT}\\n\\nYour Task: {task} \\n\\n Your Answer:\"\n",
    "        student_prompt = f\"\\n\\nTask: {task} \\n\\n Your Answer:\"\n",
    "        # Get teacher's response\n",
    "        print(f\"Teacher prompt: \\n{full_prompt}\")\n",
    "        with teacher_model.disable_adapter():\n",
    "            teacher_response, new_logits = generate_response(teacher_model, teacher_tokenizer, full_prompt)\n",
    "        print (f\"Teacher response: \\n{teacher_response}\")\n",
    "        print(\"=====================================\")\n",
    "        examples.append({\n",
    "            \"prompt\": full_prompt,\n",
    "            \"student_prompt\": f\"\\n\\nTask: {task} \\n\\n Your Answer:\",\n",
    "            \"response_logits\": new_logits,\n",
    "            \"combined\": f\"{full_prompt}{teacher_response}\",\n",
    "            \"combined_student\": f\"{student_prompt}{teacher_response}\"\n",
    "        })\n",
    "        print(\"shape of new_logits\", new_logits.shape)\n",
    "        print(\"len of teacher response\", len(teacher_response))\n",
    "        print(\"len of combined_student\", len(f\"{student_prompt}{teacher_response}\"))\n",
    "    return examples\n",
    "\n",
    "examples= create_training_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher prompt: \n",
      "You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
      "Always format code properly and explain technical concepts clearly.\n",
      "\n",
      "Your Task: Explain how a binary search works. \n",
      "\n",
      " Your Answer:\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Teacher response: \n",
      "['\\n\\n```\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n",
      "=====================================\n",
      "shape of new_logits torch.Size([1, 128, 32001])\n",
      "len of teacher response 1\n",
      "len of combined_student 318\n",
      "Teacher prompt: \n",
      "You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
      "Always format code properly and explain technical concepts clearly.\n",
      "\n",
      "Your Task: What is the difference between a list and tuple in Python? \n",
      "\n",
      " Your Answer:\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Teacher response: \n",
      "['\\n\\n  \\n   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n",
      "=====================================\n",
      "shape of new_logits torch.Size([1, 128, 32001])\n",
      "len of teacher response 1\n",
      "len of combined_student 341\n",
      "Teacher prompt: \n",
      "You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
      "Always format code properly and explain technical concepts clearly.\n",
      "\n",
      "Your Task: How does garbage collection work in Python? \n",
      "\n",
      " Your Answer:\n",
      "torch.Size([1, 128, 32001]) torch.Size([1, 128]) torch.Size([1, 256]) torch.Size([1, 384]) 128\n",
      "Teacher response: \n",
      "['  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n",
      "=====================================\n",
      "shape of new_logits torch.Size([1, 128, 32001])\n",
      "len of teacher response 1\n",
      "len of combined_student 327\n",
      "Teacher prompt: \n",
      "You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
      "Always format code properly and explain technical concepts clearly.\n",
      "\n",
      "Your Task: Explain the concept of decorators in Python. \n",
      "\n",
      " Your Answer:\n",
      "torch.Size([1, 1, 32001]) torch.Size([1, 1]) torch.Size([1, 256]) torch.Size([1, 257]) 1\n",
      "Teacher response: \n",
      "['']\n",
      "=====================================\n",
      "shape of new_logits torch.Size([1, 1, 32001])\n",
      "len of teacher response 1\n",
      "len of combined_student 72\n"
     ]
    }
   ],
   "source": [
    "# Define system prompt and tasks\n",
    "SYSTEM_PROMPT = \"\"\"You are a helpful AI assistant that provides clear, accurate, and concise answers.\n",
    "Always format code properly and explain technical concepts clearly.\"\"\"\n",
    "\n",
    "tasks = [\n",
    "    \"Explain how a binary search works.\",\n",
    "    \"What is the difference between a list and tuple in Python?\",\n",
    "    \"How does garbage collection work in Python?\",\n",
    "    \"Explain the concept of decorators in Python.\",\n",
    "]\n",
    "def create_training_examples():\n",
    "    examples = []\n",
    "    for task in tasks:\n",
    "        full_prompt = f\"{SYSTEM_PROMPT}\\n\\nYour Task: {task} \\n\\n Your Answer:\"\n",
    "        student_prompt = f\"\\n\\nTask: {task} \\n\\n Your Answer:\"\n",
    "        # Get teacher's response\n",
    "        print(f\"Teacher prompt: \\n{full_prompt}\")\n",
    "        #with teacher_model.disable_adapter():\n",
    "        teacher_response, new_logits = generate_response(teacher_model, teacher_tokenizer, full_prompt)\n",
    "        print (f\"Teacher response: \\n{teacher_response}\")\n",
    "        print(\"=====================================\")\n",
    "        examples.append({\n",
    "            \"prompt\": full_prompt,\n",
    "            \"student_prompt\": f\"\\n\\nTask: {task} \\n\\n Your Answer:\",\n",
    "            \"response_logits\": new_logits,\n",
    "            \"combined\": f\"{full_prompt}{teacher_response}\",\n",
    "            \"combined_student\": f\"{student_prompt}{teacher_response}\"\n",
    "        })\n",
    "        print(\"shape of new_logits\", new_logits.shape)\n",
    "        print(\"len of teacher response\", len(teacher_response))\n",
    "        print(\"len of combined_student\", len(f\"{student_prompt}{teacher_response}\"))\n",
    "    return examples\n",
    "\n",
    "examples= create_training_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
